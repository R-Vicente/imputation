{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ISCA-k Diagnostic Tests\n",
    "\n",
    "Este notebook contém testes diagnósticos controlados para verificar o comportamento interno do ISCA-k.\n",
    "\n",
    "**Objectivo**: Criar cenários sintéticos onde sabemos exactamente o que deveria acontecer e verificar se o algoritmo se comporta como esperado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports do ISCA-k\n",
    "from iscak_core import ISCAkCore\n",
    "from core.adaptive_k import adaptive_k_hybrid\n",
    "from core.mi_calculator import calculate_mi_mixed\n",
    "from core.distances import (\n",
    "    weighted_euclidean_batch, \n",
    "    mixed_distance_pds,\n",
    "    range_normalized_mixed_distance\n",
    ")\n",
    "from preprocessing.type_detection import MixedDataHandler\n",
    "from preprocessing.scaling import get_scaled_data, compute_range_factors\n",
    "\n",
    "np.random.seed(42)\n",
    "print(\"Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Funções Auxiliares de Diagnóstico\n",
    "\n",
    "Funções para ver \"debaixo do capot\" o que o ISCA-k está a fazer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diagnose_imputation(imputer, data, target_col, row_idx, true_value=None):\n",
    "    \"\"\"\n",
    "    Diagnóstico detalhado de uma imputação específica.\n",
    "    \n",
    "    Mostra: pesos MI, candidatos a donor, distâncias, k escolhido, vizinhos finais.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"DIAGNÓSTICO: Linha {row_idx}, Coluna '{target_col}'\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Dados da linha a imputar\n",
    "    row_data = data.loc[row_idx]\n",
    "    print(f\"\\nDados da linha {row_idx}:\")\n",
    "    print(row_data.to_string())\n",
    "    \n",
    "    if true_value is not None:\n",
    "        print(f\"\\nValor REAL (ground truth): {true_value}\")\n",
    "    \n",
    "    # Features disponíveis (não-missing)\n",
    "    feature_cols = [c for c in data.columns if c != target_col]\n",
    "    avail_features = [c for c in feature_cols if not pd.isna(row_data[c])]\n",
    "    missing_features = [c for c in feature_cols if pd.isna(row_data[c])]\n",
    "    \n",
    "    print(f\"\\nFeatures disponíveis ({len(avail_features)}): {avail_features}\")\n",
    "    print(f\"Features em falta ({len(missing_features)}): {missing_features}\")\n",
    "    \n",
    "    # Pesos MI\n",
    "    if imputer.mi_matrix is not None:\n",
    "        print(f\"\\n--- PESOS MI para prever '{target_col}' ---\")\n",
    "        mi_scores = imputer.mi_matrix.loc[feature_cols, target_col]\n",
    "        weights = mi_scores.values / mi_scores.sum() if mi_scores.sum() > 0 else np.ones(len(mi_scores)) / len(mi_scores)\n",
    "        \n",
    "        for col, mi, w in sorted(zip(feature_cols, mi_scores.values, weights), key=lambda x: -x[2]):\n",
    "            avail_marker = \"✓\" if col in avail_features else \"✗\"\n",
    "            print(f\"  {avail_marker} {col}: MI={mi:.4f}, peso={w:.4f}\")\n",
    "    \n",
    "    # Donors potenciais\n",
    "    complete_mask = ~data[target_col].isna()\n",
    "    donors = data[complete_mask]\n",
    "    print(f\"\\n--- DONORS POTENCIAIS ({len(donors)} linhas com target preenchido) ---\")\n",
    "    \n",
    "    # Calcular distâncias manualmente para diagnóstico\n",
    "    scaled_data = imputer._get_scaled_data(data)\n",
    "    range_factors = imputer._compute_range_factors(data, scaled_data)\n",
    "    \n",
    "    print(f\"\\n--- RANGE FACTORS ---\")\n",
    "    for i, col in enumerate(data.columns):\n",
    "        if col != target_col:\n",
    "            print(f\"  {col}: {range_factors[i]:.4f}\")\n",
    "    \n",
    "    # Calcular distância para cada donor\n",
    "    distances_info = []\n",
    "    sample_scaled = scaled_data.loc[row_idx, feature_cols].values.astype(np.float64)\n",
    "    \n",
    "    for donor_idx in donors.index:\n",
    "        donor_scaled = scaled_data.loc[donor_idx, feature_cols].values.astype(np.float64)\n",
    "        donor_target = donors.loc[donor_idx, target_col]\n",
    "        \n",
    "        # Contar overlap\n",
    "        overlap = sum(1 for s, d in zip(sample_scaled, donor_scaled) if not (np.isnan(s) or np.isnan(d)))\n",
    "        \n",
    "        # Calcular distância simples (euclidiana ponderada)\n",
    "        dist = 0.0\n",
    "        n_used = 0\n",
    "        for j, (s, d, w) in enumerate(zip(sample_scaled, donor_scaled, weights)):\n",
    "            if not (np.isnan(s) or np.isnan(d)):\n",
    "                diff = abs(s - d)\n",
    "                dist += (diff * w) ** 2\n",
    "                n_used += 1\n",
    "        dist = np.sqrt(dist) if n_used > 0 else np.inf\n",
    "        \n",
    "        distances_info.append({\n",
    "            'donor_idx': donor_idx,\n",
    "            'distance': dist,\n",
    "            'overlap': overlap,\n",
    "            'target': donor_target\n",
    "        })\n",
    "    \n",
    "    # Ordenar por distância\n",
    "    distances_info.sort(key=lambda x: x['distance'])\n",
    "    \n",
    "    print(f\"\\n--- TOP 10 DONORS (por distância) ---\")\n",
    "    for i, info in enumerate(distances_info[:10]):\n",
    "        print(f\"  {i+1}. Linha {info['donor_idx']}: dist={info['distance']:.4f}, overlap={info['overlap']}/{len(feature_cols)}, target={info['target']:.2f}\")\n",
    "    \n",
    "    # Simular escolha de k\n",
    "    distances_arr = np.array([d['distance'] for d in distances_info])\n",
    "    targets_arr = np.array([d['target'] for d in distances_info])\n",
    "    \n",
    "    # Verificar se é categórico\n",
    "    is_cat = (target_col in imputer.mixed_handler.nominal_cols or \n",
    "              target_col in imputer.mixed_handler.binary_cols)\n",
    "    \n",
    "    k = adaptive_k_hybrid(\n",
    "        distances_arr, targets_arr,\n",
    "        min_k=imputer.min_friends, max_k=imputer.max_friends,\n",
    "        alpha=imputer.adaptive_k_alpha, is_categorical=is_cat\n",
    "    )\n",
    "    \n",
    "    # Calcular trust components\n",
    "    k_eval = min(imputer.max_friends, len(distances_arr))\n",
    "    closest_dist = distances_arr[:k_eval]\n",
    "    closest_vals = targets_arr[:k_eval]\n",
    "    \n",
    "    mean_dist = np.mean(closest_dist[np.isfinite(closest_dist)])\n",
    "    density_trust = 1.0 / (1.0 + mean_dist) if np.isfinite(mean_dist) else 0.5\n",
    "    \n",
    "    if is_cat:\n",
    "        unique, counts = np.unique(closest_vals, return_counts=True)\n",
    "        consistency_trust = counts.max() / len(closest_vals) if len(counts) > 0 else 0.5\n",
    "    else:\n",
    "        mean_val = np.mean(closest_vals)\n",
    "        std_val = np.std(closest_vals)\n",
    "        cv = std_val / abs(mean_val) if abs(mean_val) > 1e-10 else std_val\n",
    "        consistency_trust = 1.0 / (1.0 + cv)\n",
    "    \n",
    "    print(f\"\\n--- ADAPTIVE K ---\")\n",
    "    print(f\"  density_trust: {density_trust:.4f} (mean_dist={mean_dist:.4f})\")\n",
    "    print(f\"  consistency_trust: {consistency_trust:.4f}\")\n",
    "    print(f\"  k escolhido: {k} (range [{imputer.min_friends}, {imputer.max_friends}])\")\n",
    "    \n",
    "    # Vizinhos finais\n",
    "    final_neighbors = distances_info[:k]\n",
    "    print(f\"\\n--- VIZINHOS FINAIS (k={k}) ---\")\n",
    "    for i, info in enumerate(final_neighbors):\n",
    "        print(f\"  {i+1}. Linha {info['donor_idx']}: dist={info['distance']:.4f}, target={info['target']:.2f}\")\n",
    "    \n",
    "    # Calcular valor imputado\n",
    "    neighbor_dists = np.array([d['distance'] for d in final_neighbors])\n",
    "    neighbor_vals = np.array([d['target'] for d in final_neighbors])\n",
    "    \n",
    "    if is_cat:\n",
    "        # Votação ponderada\n",
    "        weighted_votes = {}\n",
    "        for val, dist in zip(neighbor_vals, neighbor_dists):\n",
    "            w = 1 / (dist + 1e-6)\n",
    "            weighted_votes[val] = weighted_votes.get(val, 0) + w\n",
    "        imputed = max(weighted_votes.items(), key=lambda x: x[1])[0]\n",
    "    else:\n",
    "        # Média ponderada por distância inversa\n",
    "        if np.any(neighbor_dists < 1e-10):\n",
    "            imputed = np.mean(neighbor_vals[neighbor_dists < 1e-10])\n",
    "        else:\n",
    "            w = 1 / (neighbor_dists + 1e-6)\n",
    "            w = w / w.sum()\n",
    "            imputed = np.average(neighbor_vals, weights=w)\n",
    "            print(f\"\\n  Pesos IDW: {w}\")\n",
    "    \n",
    "    print(f\"\\n--- RESULTADO ---\")\n",
    "    print(f\"  Valor imputado: {imputed:.4f}\")\n",
    "    if true_value is not None:\n",
    "        error = abs(imputed - true_value)\n",
    "        print(f\"  Valor real: {true_value:.4f}\")\n",
    "        print(f\"  Erro absoluto: {error:.4f}\")\n",
    "        print(f\"  Status: {'✓ BOM' if error < 1.0 else '✗ MAU'}\")\n",
    "    \n",
    "    return imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test_with_diagnostics(data_complete, missing_indices, target_col, test_name, use_pds=True):\n",
    "    \"\"\"\n",
    "    Executa um teste completo com diagnósticos.\n",
    "    \n",
    "    Args:\n",
    "        data_complete: DataFrame completo (ground truth)\n",
    "        missing_indices: Lista de (row_idx, col_name) para tornar missing\n",
    "        target_col: Coluna target principal para diagnóstico detalhado\n",
    "        test_name: Nome do teste\n",
    "        use_pds: Se usar PDS ou não\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'#'*70}\")\n",
    "    print(f\"# TESTE: {test_name}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    # Criar cópia com missings\n",
    "    data_missing = data_complete.copy()\n",
    "    true_values = {}\n",
    "    \n",
    "    for row_idx, col in missing_indices:\n",
    "        true_values[(row_idx, col)] = data_complete.loc[row_idx, col]\n",
    "        data_missing.loc[row_idx, col] = np.nan\n",
    "    \n",
    "    print(f\"\\nDataset: {data_missing.shape[0]} linhas x {data_missing.shape[1]} colunas\")\n",
    "    print(f\"Missings introduzidos: {len(missing_indices)}\")\n",
    "    print(f\"PDS: {use_pds}\")\n",
    "    \n",
    "    print(f\"\\n--- DADOS COMPLETOS (ground truth) ---\")\n",
    "    print(data_complete.to_string())\n",
    "    \n",
    "    print(f\"\\n--- DADOS COM MISSINGS ---\")\n",
    "    print(data_missing.to_string())\n",
    "    \n",
    "    # Executar ISCA-k\n",
    "    imputer = ISCAkCore(verbose=True, use_pds=use_pds, min_friends=2, max_friends=5)\n",
    "    result = imputer.impute(data_missing, interactive=False)\n",
    "    \n",
    "    print(f\"\\n--- RESULTADO IMPUTAÇÃO ---\")\n",
    "    print(result.to_string())\n",
    "    \n",
    "    # Verificar erros\n",
    "    print(f\"\\n--- VERIFICAÇÃO DE ERROS ---\")\n",
    "    total_error = 0\n",
    "    n_errors = 0\n",
    "    \n",
    "    for (row_idx, col), true_val in true_values.items():\n",
    "        imputed_val = result.loc[row_idx, col]\n",
    "        error = abs(imputed_val - true_val)\n",
    "        total_error += error\n",
    "        n_errors += 1\n",
    "        \n",
    "        status = \"✓\" if error < 1.0 else \"✗\"\n",
    "        print(f\"  {status} Linha {row_idx}, Col '{col}': imputado={imputed_val:.2f}, real={true_val:.2f}, erro={error:.2f}\")\n",
    "    \n",
    "    mae = total_error / n_errors if n_errors > 0 else 0\n",
    "    print(f\"\\nMAE total: {mae:.4f}\")\n",
    "    \n",
    "    # Diagnóstico detalhado para o primeiro missing\n",
    "    if missing_indices:\n",
    "        first_row, first_col = missing_indices[0]\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"DIAGNÓSTICO DETALHADO para linha {first_row}, coluna '{first_col}'\")\n",
    "        diagnose_imputation(imputer, data_missing, first_col, first_row, true_values[(first_row, first_col)])\n",
    "    \n",
    "    # Stats da execução\n",
    "    print(f\"\\n--- ESTATÍSTICAS DE EXECUÇÃO ---\")\n",
    "    stats = imputer.execution_stats\n",
    "    print(f\"  Fase 2 activada: {stats.get('phase2_activated', 'N/A')}\")\n",
    "    print(f\"  Fase 2 ciclos: {stats.get('phase2_cycles', 'N/A')}\")\n",
    "    print(f\"  Fase 2 imputados: {stats.get('phase2_imputed', 'N/A')}\")\n",
    "    \n",
    "    return result, imputer, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 1: Vizinhos Óbvios (Sanity Check)\n",
    "\n",
    "**Objectivo**: Verificar se o algoritmo escolhe os vizinhos correctos num cenário simples.\n",
    "\n",
    "Criamos dois clusters bem separados e verificamos se a imputação usa vizinhos do cluster correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1.1: Dataset pequeno (7 linhas, 3 features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# TESTE: 1.1 - Vizinhos Óbvios (7x4, 1 missing)\n",
      "######################################################################\n",
      "\n",
      "Dataset: 7 linhas x 4 colunas\n",
      "Missings introduzidos: 1\n",
      "PDS: True\n",
      "\n",
      "--- DADOS COMPLETOS (ground truth) ---\n",
      "      A     B     C  Target\n",
      "0  1.00  1.00  1.00    10.0\n",
      "1  1.10  1.10  1.10    11.0\n",
      "2  1.20  1.20  1.20    12.0\n",
      "3  5.00  5.00  5.00    50.0\n",
      "4  5.10  5.10  5.10    51.0\n",
      "5  5.20  5.20  5.20    52.0\n",
      "6  1.05  1.05  1.05    10.5\n",
      "\n",
      "--- DADOS COM MISSINGS ---\n",
      "      A     B     C  Target\n",
      "0  1.00  1.00  1.00    10.0\n",
      "1  1.10  1.10  1.10    11.0\n",
      "2  1.20  1.20  1.20    12.0\n",
      "3  5.00  5.00  5.00    50.0\n",
      "4  5.10  5.10  5.10    51.0\n",
      "5  5.20  5.20  5.20    52.0\n",
      "6  1.05  1.05  1.05     NaN\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 4\n",
      "    ['A', 'B', 'C', 'Target']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 7 x 4\n",
      "Missings: 1 (3.6%)\n",
      "Parametros: min_friends=2, max_friends=5\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 6/7 (85.7%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 1 → 0 missings\n",
      "             1 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 1 → 0 (1 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 1 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.58s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- RESULTADO IMPUTAÇÃO ---\n",
      "      A     B     C     Target\n",
      "0  1.00  1.00  1.00  10.000000\n",
      "1  1.10  1.10  1.10  11.000000\n",
      "2  1.20  1.20  1.20  12.000000\n",
      "3  5.00  5.00  5.00  50.000000\n",
      "4  5.10  5.10  5.10  51.000000\n",
      "5  5.20  5.20  5.20  52.000000\n",
      "6  1.05  1.05  1.05  10.714291\n",
      "\n",
      "--- VERIFICAÇÃO DE ERROS ---\n",
      "  ✓ Linha 6, Col 'Target': imputado=10.71, real=10.50, erro=0.21\n",
      "\n",
      "MAE total: 0.2143\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO DETALHADO para linha 6, coluna 'Target'\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO: Linha 6, Coluna 'Target'\n",
      "======================================================================\n",
      "\n",
      "Dados da linha 6:\n",
      "A         1.05\n",
      "B         1.05\n",
      "C         1.05\n",
      "Target     NaN\n",
      "\n",
      "Valor REAL (ground truth): 10.5\n",
      "\n",
      "Features disponíveis (3): ['A', 'B', 'C']\n",
      "Features em falta (0): []\n",
      "\n",
      "--- PESOS MI para prever 'Target' ---\n",
      "  ✓ A: MI=0.0000, peso=0.3333\n",
      "  ✓ B: MI=0.0000, peso=0.3333\n",
      "  ✓ C: MI=0.0000, peso=0.3333\n",
      "\n",
      "--- DONORS POTENCIAIS (6 linhas com target preenchido) ---\n",
      "\n",
      "--- RANGE FACTORS ---\n",
      "  A: 0.4731\n",
      "  B: 0.4731\n",
      "  C: 0.4731\n",
      "\n",
      "--- TOP 10 DONORS (por distância) ---\n",
      "  1. Linha 0: dist=0.0145, overlap=3/3, target=10.00\n",
      "  2. Linha 1: dist=0.0145, overlap=3/3, target=11.00\n",
      "  3. Linha 2: dist=0.0436, overlap=3/3, target=12.00\n",
      "  4. Linha 3: dist=1.1476, overlap=3/3, target=50.00\n",
      "  5. Linha 4: dist=1.1767, overlap=3/3, target=51.00\n",
      "  6. Linha 5: dist=1.2057, overlap=3/3, target=52.00\n",
      "\n",
      "--- ADAPTIVE K ---\n",
      "  density_trust: 0.6760 (mean_dist=0.4794)\n",
      "  consistency_trust: 0.5805\n",
      "  k escolhido: 3 (range [2, 5])\n",
      "\n",
      "--- VIZINHOS FINAIS (k=3) ---\n",
      "  1. Linha 0: dist=0.0145, target=10.00\n",
      "  2. Linha 1: dist=0.0145, target=11.00\n",
      "  3. Linha 2: dist=0.0436, target=12.00\n",
      "\n",
      "  Pesos IDW: [0.42856862 0.42856862 0.14286276]\n",
      "\n",
      "--- RESULTADO ---\n",
      "  Valor imputado: 10.7143\n",
      "  Valor real: 10.5000\n",
      "  Erro absoluto: 0.2143\n",
      "  Status: ✓ BOM\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "✓ TESTE 1.1 PASSOU: valor imputado 10.71 está no range esperado (9.5, 12.5)\n"
     ]
    }
   ],
   "source": [
    "# Dataset com dois clusters óbvios\n",
    "data_1_1 = pd.DataFrame({\n",
    "    'A': [1.0, 1.1, 1.2, 5.0, 5.1, 5.2, 1.05],\n",
    "    'B': [1.0, 1.1, 1.2, 5.0, 5.1, 5.2, 1.05],\n",
    "    'C': [1.0, 1.1, 1.2, 5.0, 5.1, 5.2, 1.05],\n",
    "    'Target': [10.0, 11.0, 12.0, 50.0, 51.0, 52.0, 10.5]  # Linha 6 será missing\n",
    "})\n",
    "\n",
    "# Comportamento esperado:\n",
    "# - Vizinhos de linha 6 devem ser {0, 1, 2} (não {3, 4, 5})\n",
    "# - Valor imputado deve ser ~10.5 (não ~50)\n",
    "\n",
    "result, imputer, mae = run_test_with_diagnostics(\n",
    "    data_1_1, \n",
    "    missing_indices=[(6, 'Target')],\n",
    "    target_col='Target',\n",
    "    test_name=\"1.1 - Vizinhos Óbvios (7x4, 1 missing)\"\n",
    ")\n",
    "\n",
    "# Verificação\n",
    "imputed_val = result.loc[6, 'Target']\n",
    "expected_range = (9.5, 12.5)  # Deve estar próximo de 10-12\n",
    "assert expected_range[0] <= imputed_val <= expected_range[1], f\"FALHOU: {imputed_val} não está em {expected_range}\"\n",
    "print(f\"\\n✓ TESTE 1.1 PASSOU: valor imputado {imputed_val:.2f} está no range esperado {expected_range}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1.2: Dataset médio (20 linhas, 5 features, 10% missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# TESTE: 1.2 - Dataset médio (20x5, 10% missing)\n",
      "######################################################################\n",
      "\n",
      "Dataset: 20 linhas x 5 colunas\n",
      "Missings introduzidos: 2\n",
      "PDS: True\n",
      "\n",
      "--- DADOS COMPLETOS (ground truth) ---\n",
      "           A         B         C         D     Target\n",
      "0   1.049671  0.953658  1.146565  0.939829  10.369233\n",
      "1   0.986174  0.953427  0.977422  1.185228  10.085684\n",
      "2   1.064769  1.024196  1.006753  0.998650   9.942176\n",
      "3   1.152303  0.808672  0.857525  0.894229   9.849448\n",
      "4   0.976585  0.827508  0.945562  1.082254   9.260739\n",
      "5   0.976586  0.943771  1.011092  0.877916   9.640078\n",
      "6   1.157921  0.898717  0.884901  1.020886   9.769681\n",
      "7   1.076743  1.031425  1.037570  0.804033  10.528561\n",
      "8   0.953053  0.909198  0.939936  0.867181  10.171809\n",
      "9   1.054256  0.858770  0.970831  1.019686   9.118480\n",
      "10  5.032408  4.952083  5.036140  4.978033  50.048539\n",
      "11  4.961492  4.981434  5.153804  5.035711  50.484322\n",
      "12  4.932308  4.889367  4.996417  5.147789  49.648973\n",
      "13  5.061168  4.880379  5.156464  4.948173  49.836169\n",
      "14  5.103100  5.081253  4.738025  4.919151  49.803946\n",
      "15  5.093128  5.135624  5.082190  4.949824  49.268243\n",
      "16  4.916078  4.992799  5.008705  5.091540  50.148060\n",
      "17  4.969079  5.100353  4.970099  5.032875  50.130528\n",
      "18  5.033126  5.036164  5.009176  4.947024  50.002557\n",
      "19  5.097555  4.935488  4.801243  5.051327  49.882706\n",
      "\n",
      "--- DADOS COM MISSINGS ---\n",
      "           A         B         C         D     Target\n",
      "0   1.049671  0.953658  1.146565  0.939829  10.369233\n",
      "1   0.986174  0.953427  0.977422  1.185228  10.085684\n",
      "2   1.064769  1.024196  1.006753  0.998650        NaN\n",
      "3   1.152303  0.808672  0.857525  0.894229   9.849448\n",
      "4   0.976585  0.827508  0.945562  1.082254   9.260739\n",
      "5   0.976586  0.943771  1.011092  0.877916   9.640078\n",
      "6   1.157921  0.898717  0.884901  1.020886   9.769681\n",
      "7   1.076743  1.031425  1.037570  0.804033  10.528561\n",
      "8   0.953053  0.909198  0.939936  0.867181  10.171809\n",
      "9   1.054256  0.858770  0.970831  1.019686   9.118480\n",
      "10  5.032408  4.952083  5.036140  4.978033  50.048539\n",
      "11  4.961492  4.981434  5.153804  5.035711  50.484322\n",
      "12  4.932308  4.889367  4.996417  5.147789  49.648973\n",
      "13  5.061168  4.880379  5.156464  4.948173  49.836169\n",
      "14  5.103100  5.081253  4.738025  4.919151  49.803946\n",
      "15  5.093128  5.135624  5.082190  4.949824        NaN\n",
      "16  4.916078  4.992799  5.008705  5.091540  50.148060\n",
      "17  4.969079  5.100353  4.970099  5.032875  50.130528\n",
      "18  5.033126  5.036164  5.009176  4.947024  50.002557\n",
      "19  5.097555  4.935488  4.801243  5.051327  49.882706\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 5\n",
      "    ['A', 'B', 'C', 'D', 'Target']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 20 x 5\n",
      "Missings: 2 (2.0%)\n",
      "Parametros: min_friends=2, max_friends=5\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 18/20 (90.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 2 → 0 missings\n",
      "             2 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 2 → 0 (2 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 2 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.04s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- RESULTADO IMPUTAÇÃO ---\n",
      "           A         B         C         D     Target\n",
      "0   1.049671  0.953658  1.146565  0.939829  10.369233\n",
      "1   0.986174  0.953427  0.977422  1.185228  10.085684\n",
      "2   1.064769  1.024196  1.006753  0.998650   9.736111\n",
      "3   1.152303  0.808672  0.857525  0.894229   9.849448\n",
      "4   0.976585  0.827508  0.945562  1.082254   9.260739\n",
      "5   0.976586  0.943771  1.011092  0.877916   9.640078\n",
      "6   1.157921  0.898717  0.884901  1.020886   9.769681\n",
      "7   1.076743  1.031425  1.037570  0.804033  10.528561\n",
      "8   0.953053  0.909198  0.939936  0.867181  10.171809\n",
      "9   1.054256  0.858770  0.970831  1.019686   9.118480\n",
      "10  5.032408  4.952083  5.036140  4.978033  50.048539\n",
      "11  4.961492  4.981434  5.153804  5.035711  50.484322\n",
      "12  4.932308  4.889367  4.996417  5.147789  49.648973\n",
      "13  5.061168  4.880379  5.156464  4.948173  49.836169\n",
      "14  5.103100  5.081253  4.738025  4.919151  49.803946\n",
      "15  5.093128  5.135624  5.082190  4.949824  50.138587\n",
      "16  4.916078  4.992799  5.008705  5.091540  50.148060\n",
      "17  4.969079  5.100353  4.970099  5.032875  50.130528\n",
      "18  5.033126  5.036164  5.009176  4.947024  50.002557\n",
      "19  5.097555  4.935488  4.801243  5.051327  49.882706\n",
      "\n",
      "--- VERIFICAÇÃO DE ERROS ---\n",
      "  ✓ Linha 2, Col 'Target': imputado=9.74, real=9.94, erro=0.21\n",
      "  ✓ Linha 15, Col 'Target': imputado=50.14, real=49.27, erro=0.87\n",
      "\n",
      "MAE total: 0.5382\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO DETALHADO para linha 2, coluna 'Target'\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO: Linha 2, Coluna 'Target'\n",
      "======================================================================\n",
      "\n",
      "Dados da linha 2:\n",
      "A         1.064769\n",
      "B         1.024196\n",
      "C         1.006753\n",
      "D         0.998650\n",
      "Target         NaN\n",
      "\n",
      "Valor REAL (ground truth): 9.94217585880588\n",
      "\n",
      "Features disponíveis (4): ['A', 'B', 'C', 'D']\n",
      "Features em falta (0): []\n",
      "\n",
      "--- PESOS MI para prever 'Target' ---\n",
      "  ✓ D: MI=0.7410, peso=0.2794\n",
      "  ✓ B: MI=0.7184, peso=0.2709\n",
      "  ✓ A: MI=0.6204, peso=0.2339\n",
      "  ✓ C: MI=0.5726, peso=0.2159\n",
      "\n",
      "--- DONORS POTENCIAIS (18 linhas com target preenchido) ---\n",
      "\n",
      "--- RANGE FACTORS ---\n",
      "  A: 0.4792\n",
      "  B: 0.4715\n",
      "  C: 0.4679\n",
      "  D: 0.4656\n",
      "\n",
      "--- TOP 10 DONORS (por distância) ---\n",
      "  1. Linha 0: dist=0.0195, overlap=4/4, target=10.37\n",
      "  2. Linha 5: dist=0.0224, overlap=4/4, target=9.64\n",
      "  3. Linha 9: dist=0.0225, overlap=4/4, target=9.12\n",
      "  4. Linha 6: dist=0.0240, overlap=4/4, target=9.77\n",
      "  5. Linha 7: dist=0.0271, overlap=4/4, target=10.53\n",
      "  6. Linha 8: dist=0.0281, overlap=4/4, target=10.17\n",
      "  7. Linha 1: dist=0.0291, overlap=4/4, target=10.09\n",
      "  8. Linha 4: dist=0.0311, overlap=4/4, target=9.26\n",
      "  9. Linha 3: dist=0.0373, overlap=4/4, target=9.85\n",
      "  10. Linha 14: dist=0.9845, overlap=4/4, target=49.80\n",
      "\n",
      "--- ADAPTIVE K ---\n",
      "  density_trust: 0.9774 (mean_dist=0.0231)\n",
      "  consistency_trust: 0.9508\n",
      "  k escolhido: 4 (range [2, 5])\n",
      "\n",
      "--- VIZINHOS FINAIS (k=4) ---\n",
      "  1. Linha 0: dist=0.0195, target=10.37\n",
      "  2. Linha 5: dist=0.0224, target=9.64\n",
      "  3. Linha 9: dist=0.0225, target=9.12\n",
      "  4. Linha 6: dist=0.0240, target=9.77\n",
      "\n",
      "  Pesos IDW: [0.2812797  0.24590687 0.24413366 0.22867977]\n",
      "\n",
      "--- RESULTADO ---\n",
      "  Valor imputado: 9.7475\n",
      "  Valor real: 9.9422\n",
      "  Erro absoluto: 0.1947\n",
      "  Status: ✓ BOM\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "✓ TESTE 1.2 PASSOU: cluster1=9.74, cluster2=50.14\n"
     ]
    }
   ],
   "source": [
    "# Dois clusters com mais linhas\n",
    "np.random.seed(42)\n",
    "\n",
    "# Cluster 1: valores ~1, target ~10\n",
    "cluster1 = pd.DataFrame({\n",
    "    'A': np.random.normal(1.0, 0.1, 10),\n",
    "    'B': np.random.normal(1.0, 0.1, 10),\n",
    "    'C': np.random.normal(1.0, 0.1, 10),\n",
    "    'D': np.random.normal(1.0, 0.1, 10),\n",
    "    'Target': np.random.normal(10.0, 0.5, 10)\n",
    "})\n",
    "\n",
    "# Cluster 2: valores ~5, target ~50\n",
    "cluster2 = pd.DataFrame({\n",
    "    'A': np.random.normal(5.0, 0.1, 10),\n",
    "    'B': np.random.normal(5.0, 0.1, 10),\n",
    "    'C': np.random.normal(5.0, 0.1, 10),\n",
    "    'D': np.random.normal(5.0, 0.1, 10),\n",
    "    'Target': np.random.normal(50.0, 0.5, 10)\n",
    "})\n",
    "\n",
    "data_1_2 = pd.concat([cluster1, cluster2], ignore_index=True)\n",
    "\n",
    "# Introduzir 10% missings (2 valores) - um de cada cluster\n",
    "missing_indices_1_2 = [(2, 'Target'), (15, 'Target')]  # Linha 2 cluster1, linha 15 cluster2\n",
    "\n",
    "result, imputer, mae = run_test_with_diagnostics(\n",
    "    data_1_2,\n",
    "    missing_indices=missing_indices_1_2,\n",
    "    target_col='Target',\n",
    "    test_name=\"1.2 - Dataset médio (20x5, 10% missing)\"\n",
    ")\n",
    "\n",
    "# Verificação\n",
    "val_cluster1 = result.loc[2, 'Target']\n",
    "val_cluster2 = result.loc[15, 'Target']\n",
    "\n",
    "assert 8 <= val_cluster1 <= 12, f\"FALHOU cluster1: {val_cluster1} deveria estar em [8, 12]\"\n",
    "assert 48 <= val_cluster2 <= 52, f\"FALHOU cluster2: {val_cluster2} deveria estar em [48, 52]\"\n",
    "print(f\"\\n✓ TESTE 1.2 PASSOU: cluster1={val_cluster1:.2f}, cluster2={val_cluster2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1.3: Dataset maior (100 linhas, 10 features, 20% missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# TESTE: 1.3 - Dataset maior (100x11, 20% missing)\n",
      "######################################################################\n",
      "\n",
      "Dataset: 100 linhas x 11 colunas\n",
      "Missings introduzidos: 20\n",
      "PDS: True\n",
      "\n",
      "--- DADOS COMPLETOS (ground truth) ---\n",
      "          F0        F1        F2        F3        F4        F5        F6        F7        F8        F9     Target\n",
      "0   1.099343  0.788458  0.985598  0.953083  0.787539  1.082556  1.011642  1.043292  0.949486  1.061460   9.987753\n",
      "1   0.972347  1.164509  1.200707  0.716926  1.094718  1.164412  0.771406  1.009114  0.750443  1.162572   9.102746\n",
      "2   1.129538  0.755831  1.072327  0.915871  0.816115  1.379359  1.071557  0.869680  1.326482  1.125926  10.075805\n",
      "3   1.304606  1.041773  0.870976  0.931457  1.309987  0.950922  1.112157  1.428789  0.713972  0.834201   9.322838\n",
      "4   0.953169  0.608066  1.072279  0.839545  0.843349  0.849253  1.216610  1.126784  0.911991  0.887964  10.975120\n",
      "5   0.953173  0.734363  1.307607  0.967743  0.935588  0.822097  1.210760  0.594971  1.026148  1.149459   9.852943\n",
      "6   1.315843  1.039372  0.992835  1.080810  1.162703  0.836838  0.724466  1.037291  1.288255  1.122074   9.174503\n",
      "7   1.153487  1.147693  1.312929  1.377237  0.753827  0.984580  0.812435  0.867643  0.712828  0.995820   9.678614\n",
      "8   0.906105  1.034274  0.476051  1.034916  1.045492  1.068230  1.103007  1.170487  1.232633  1.023465  10.412931\n",
      "9   1.108512  0.976870  1.164381  1.051510  1.261429  1.055338  1.102757  0.841496  1.002047  1.255533   9.436275\n",
      "10  0.907316  0.939779  1.017409  0.985111  0.678503  1.165437  1.103010  0.977053  0.803698  0.881686   9.177780\n",
      "11  0.906854  0.704296  0.940199  0.616246  1.036927  1.002600  1.770546  1.100997  1.092421  1.109419  10.243687\n",
      "12  1.048392  0.856031  1.018352  0.994697  1.051977  1.290707  1.114178  1.173151  1.039812  0.959561  10.244967\n",
      "13  0.617344  0.907872  0.602486  1.012046  1.156365  0.947069  1.227113  0.759941  0.879957  0.956464   9.493057\n",
      "14  0.655016  1.211424  0.956066  1.492648  0.752610  1.544034  1.190800  0.933100  1.013960  1.219755   9.528962\n",
      "15  0.887542  1.068724  1.071423  0.961528  0.735909  1.125133  1.130278  0.905011  0.922937  1.165083  10.232050\n",
      "16  0.797434  0.647392  1.295579  1.060309  1.104388  0.828568  0.936946  0.869334  1.022703  1.162702   8.551916\n",
      "17  1.062849  1.064817  0.896346  0.993058  1.059397  0.785822  1.151794  1.353091  1.132426  1.261096   8.592536\n",
      "18  0.818395  0.922984  0.838301  0.766264  1.050099  1.096494  0.845435  1.080996  1.317203  1.004201   9.281556\n",
      "19  0.717539  0.864616  0.899649  1.228565  1.069290  0.955307  0.952636  0.747823  0.752437  1.136391   9.786553\n",
      "20  1.293130  1.122335  1.183080  1.150387  0.863995  1.142800  0.902927  1.183572  1.426607  0.937947  10.310908\n",
      "21  0.954845  1.206200  1.065750  1.158206  1.046451  1.094648  1.016375  1.424431  0.609582  1.064833  11.475356\n",
      "22  1.013506  1.186256  0.894048  0.818123  1.058614  0.985434  1.462932  1.206493  0.969643  0.973971  10.857660\n",
      "23  0.715050  0.832156  1.102653  1.280559  0.857130  0.830641  0.626547  0.696126  1.117663  1.019399   9.840061\n",
      "24  0.891123  0.938158  1.019416  0.719630  1.373155  0.697031  1.137252  0.903153  1.056198  1.119031   9.980984\n",
      "25  1.022185  1.066253  1.193729  1.117371  1.094767  0.910697  0.677457  1.253382  0.875460  0.836356   8.997471\n",
      "26  0.769801  1.195109  0.859589  1.438091  0.761739  1.171280  0.905614  0.858466  0.958376  1.418477   9.981487\n",
      "27  1.075140  0.904165  0.934468  0.801893  1.131311  1.042819  1.217790  1.088764  0.901400  0.798797   9.711341\n",
      "28  0.879872  0.962868  0.921578  0.886740  0.805064  0.750852  1.012856  1.154927  0.882127  0.757162  10.322719\n",
      "29  0.941661  0.778733  0.707297  1.019930  1.157417  1.034636  0.784451  0.814614  1.169920  1.231622   9.172769\n",
      "30  0.879659  0.760759  1.059224  0.899305  1.231719  1.077063  0.856939  0.988095  1.071403  1.158333  10.519347\n",
      "31  1.370456  1.162505  1.052211  0.689867  0.835864  0.823229  1.135920  0.351747  0.861418  1.124824  11.532739\n",
      "32  0.997301  1.271248  1.001023  1.013713  1.192675  1.030745  0.853927  0.795122  1.179920  1.125669   9.891240\n",
      "33  5.080342  4.657373  4.648252  4.860055  5.107782  5.051945  5.415080  5.207508  4.974843  4.885268  50.615936\n",
      "34  5.138029  5.270774  4.763348  5.042796  4.792551  4.819137  5.174225  4.897997  5.011145  4.890628  50.593101\n",
      "35  4.919756  4.977092  4.592154  4.977534  4.961932  5.127718  4.934795  4.946025  5.218838  4.993449  49.690454\n",
      "36  5.044818  5.247563  4.946119  4.955806  4.824876  4.667696  5.240243  4.804247  4.661507  4.891315  50.326133\n",
      "37  5.002518  4.681114  5.143508  5.122833  4.723440  4.986784  4.918385  4.911141  5.305910  4.857431  48.748886\n",
      "38  5.019535  4.880125  5.300471  5.151502  5.185236  4.757797  4.592375  5.075460  4.968398  5.021286  50.924027\n",
      "39  4.845398  5.001049  5.014819  4.893900  5.381883  4.869633  4.798383  5.151398  4.914624  4.949005  49.815098\n",
      "40  5.004902  5.009396  5.325723  4.884836  4.720286  5.009480  4.625842  4.815567  4.797579  5.300799  49.477277\n",
      "41  5.099600  4.909987  4.723980  4.944990  5.112594  4.827917  4.929697  5.173921  4.669029  4.469806  51.049009\n",
      "42  5.290229  5.124570  4.659324  4.539616  4.869871  4.923089  5.003684  5.271128  5.164634  5.218301  49.295656\n",
      "43  5.191854  4.786476  4.988890  4.696962  4.902575  5.201259  5.335287  5.082687  5.014664  5.249217  48.591539\n",
      "44  5.430636  4.971524  5.076813  5.273375  4.881521  4.884622  5.065385  5.375359  4.742008  4.585322  48.443371\n",
      "45  4.846530  5.024059  4.993461  5.328994  4.827202  5.167138  4.956180  4.845242  4.740984  4.931462  50.606010\n",
      "46  5.174464  5.102888  4.586512  4.950193  5.009704  4.774059  5.165881  4.751069  4.932843  4.925712  48.719571\n",
      "47  5.036668  5.142323  4.982176  5.115311  4.833810  5.105961  4.557773  4.644256  5.333804  4.718498  51.754794\n",
      "48  5.437961  4.775072  4.739106  5.062250  5.054091  5.288314  5.047123  5.299209  4.948082  4.844437  47.918071\n",
      "49  4.838340  4.693177  5.133935  5.615776  4.989952  4.505671  5.154173  5.130873  4.699371  4.777885  51.696456\n",
      "50  4.832056  5.255535  5.073320  5.223915  4.952210  4.840621  4.704283  4.988883  4.950851  5.350454  50.211017\n",
      "51  4.880121  5.066463  4.812024  4.974416  4.818487  5.115414  5.228751  5.055994  4.945455  5.187136  49.903287\n",
      "52  4.575221  4.850303  4.897227  4.808892  4.884646  4.959391  5.067699  4.774902  4.460623  5.254311  49.455081\n",
      "53  4.894849  5.310230  4.788157  4.678711  5.151078  5.074229  4.916942  5.489150  4.989141  5.144334  50.399136\n",
      "54  4.848173  5.023135  4.987464  5.040693  5.100183  4.879203  5.126556  5.025844  4.953813  4.774190  49.962365\n",
      "55  5.030079  5.235859  5.191028  4.848730  4.804489  5.017318  5.454139  5.021879  5.139241  4.895096  51.103302\n",
      "56  5.068351  5.013504  4.802855  4.715549  5.019866  4.968865  5.036373  5.145153  5.369791  5.097875  50.114228\n",
      "57  5.375234  5.412150  5.100809  4.870685  5.150277  5.233556  5.049644  5.096202  5.225313  4.755574  50.150302\n",
      "58  5.190085  5.351068  4.893948  4.783690  4.666119  5.050884  4.908128  5.044777  4.946222  5.142600  49.636388\n",
      "59  4.884619  4.950207  4.841425  5.337428  5.108672  5.067521  4.830031  4.841905  4.778695  4.951935  49.943054\n",
      "60  4.820317  5.194314  4.978594  5.176328  4.867475  4.917625  5.166067  5.094294  5.514672  4.925036  50.307802\n",
      "61  5.098384  5.129075  4.792952  4.998405  5.114120  4.902479  4.828783  5.376405  5.011844  5.142192  48.289832\n",
      "62  4.735953  5.273726  4.889270  5.295989  4.847348  4.913488  5.014313  5.269084  5.002786  5.088853  48.651815\n",
      "63  5.366292  4.807015  4.760424  5.015474  4.639024  5.078890  4.904469  5.318637  4.995175  4.927807  50.743264\n",
      "64  5.235888  5.137210  5.392945  4.827743  4.674492  4.915803  5.095796  4.897757  5.039617  5.231866  50.170865\n",
      "65  4.906165  5.211685  5.007053  5.304625  5.009617  5.057955  5.066732  4.802079  4.971128  4.783787  49.816017\n",
      "66  9.003687  8.884872  8.783789  8.915963  9.309501  8.966576  8.888960  8.982053  8.885764  9.079845  88.705319\n",
      "67  9.069516  9.024402  9.210631  8.943643  9.359176  9.029343  9.376231  9.288023  9.114517  9.129439  91.160827\n",
      "68  8.892048  9.512017  8.992089  8.731110  8.877442  9.241302  8.710397  8.864722  9.279871  8.903363  89.532299\n",
      "69  8.844339  8.980788  9.136300  8.816270  8.922460  8.836613  8.560239  9.360188  9.184927  9.314797  90.346504\n",
      "70  9.039169  9.229855  9.005664  8.799172  9.057173  9.073735  9.088003  8.991968  9.011926  8.754847  89.953079\n",
      "71  8.804325  8.859365  9.005951  8.846440  9.066891  8.921332  8.899589  8.713845  8.870613  8.707125  90.477041\n",
      "72  9.081651  8.993002  9.187657  8.993063  9.131709  9.005749  8.795753  9.025621  9.139645  9.044890  90.076822\n",
      "73  8.659483  9.354160  8.896791  9.046843  9.402041  9.255690  9.141671  8.863790  9.078697  9.209420  88.717008\n",
      "74  9.205831  8.874607  9.019224  9.310100  8.964611  9.038220  9.048760  9.168129  9.179039  9.336786  90.996267\n",
      "75  9.094519  9.362490  8.907545  8.800329  8.840341  9.009287  8.887184  8.869475  9.127034  8.908223  89.506243\n",
      "76  9.051206  9.141550  8.913101  9.196864  8.724136  8.728029  8.743939  8.910763  9.209911  9.215736  88.443418\n",
      "77  9.196538  8.887507  8.938166  8.957202  8.853814  9.149251  9.174491  8.622092  8.892953  8.992298  89.571885\n",
      "78  9.333095  9.126482  9.044427  8.990107  8.993375  9.129097  9.130040  8.909539  9.263479  8.965475  91.500760\n",
      "79  9.202874  9.194511  8.904250  9.134964  9.358912  9.432651  8.980165  8.515224  9.039520  9.176732  90.850222\n",
      "80  8.631825  9.124362  9.251151  8.775456  8.896478  8.938444  9.369327  8.683219  9.415052  9.130465  89.651348\n",
      "81  8.744085  8.685955  8.821079  9.076482  9.044758  9.043830  8.785983  9.152083  8.862162  8.684722  89.650742\n",
      "82  8.875036  8.854573  8.962626  9.033290  8.996715  9.049877  8.694895  9.157160  9.347193  9.295308  89.678365\n",
      "83  9.005218  8.950496  8.912054  9.098490  9.237679  9.315491  8.861618  9.085092  9.039582  9.276018  92.076748\n",
      "84  9.103532  8.985113  9.289396  9.057834  9.505386  8.980941  8.990883  8.806605  8.869716  8.874887  90.381935\n",
      "85  8.854851  9.124134  9.039311  9.491060  8.893826  9.055804  9.048668  8.990458  8.903223  9.079161  90.430042\n",
      "86  9.037353  9.035540  9.206369  8.872452  8.902112  9.121579  8.951753  8.999279  8.935931  9.098806  91.030283\n",
      "87  8.848923  8.732931  8.702888  8.893801  9.208832  9.037322  9.070411  8.768327  9.084833  9.052135  90.238789\n",
      "88  8.877696  9.076040  9.053410  8.875372  9.136378  8.910713  8.749692  9.300680  9.104567  8.889939  89.740958\n",
      "89  8.718668  9.122117  9.177926  8.888905  9.369341  9.038818  9.288753  9.175472  8.885260  8.865675  89.803650\n",
      "90  8.815353  9.111958  9.016457  8.872523  9.116786  9.214726  8.983570  8.955807  8.995129  8.994889  89.928399\n",
      "91  8.729663  9.216156  9.213096  9.237803  8.928142  8.794697  9.223459  9.005377  9.428454  9.234546  89.962778\n",
      "92  8.804825  9.166784  8.896542  9.284101  9.118131  9.026594  9.068545  9.041677  9.345509  9.108720  90.727630\n",
      "93  9.210728  9.091836  9.281869  8.885851  9.221741  8.859976  9.091351  8.591653  9.087265  8.925877  90.051946\n",
      "94  8.810120  8.985967  9.459780  8.833529  9.164096  9.239009  9.113953  8.950565  9.007601  9.154340  90.732640\n",
      "95  9.526476  8.667808  8.927432  9.094283  9.101455  8.695363  9.089542  8.863603  9.024006  8.430291  89.919283\n",
      "96  9.098664  9.085924  8.910899  8.889555  9.213335  8.888216  9.128545  8.799676  9.122704  9.229753  90.078635\n",
      "97  9.036967  9.041538  9.290677  9.126586  9.233859  9.075442  9.265831  8.943780  8.795441  8.652057  88.001799\n",
      "98  8.828328  9.054316  9.315914  9.040585  9.276432  9.313105  9.039304  9.359537  8.948525  8.927512  90.916328\n",
      "99  9.140062  8.744650  8.895428  8.696851  9.129742  8.986850  9.141801  9.128169  8.666283  8.776066  90.346488\n",
      "\n",
      "--- DADOS COM MISSINGS ---\n",
      "          F0        F1        F2        F3        F4        F5        F6        F7        F8        F9     Target\n",
      "0   1.099343  0.788458  0.985598  0.953083  0.787539  1.082556  1.011642  1.043292  0.949486  1.061460        NaN\n",
      "1   0.972347  1.164509  1.200707  0.716926  1.094718  1.164412  0.771406  1.009114  0.750443  1.162572   9.102746\n",
      "2   1.129538  0.755831  1.072327  0.915871  0.816115  1.379359  1.071557  0.869680  1.326482  1.125926  10.075805\n",
      "3   1.304606  1.041773  0.870976  0.931457  1.309987  0.950922  1.112157  1.428789  0.713972  0.834201   9.322838\n",
      "4   0.953169  0.608066  1.072279  0.839545  0.843349  0.849253  1.216610  1.126784  0.911991  0.887964        NaN\n",
      "5   0.953173  0.734363  1.307607  0.967743  0.935588  0.822097  1.210760  0.594971  1.026148  1.149459   9.852943\n",
      "6   1.315843  1.039372  0.992835  1.080810  1.162703  0.836838  0.724466  1.037291  1.288255  1.122074   9.174503\n",
      "7   1.153487  1.147693  1.312929  1.377237  0.753827  0.984580  0.812435  0.867643  0.712828  0.995820   9.678614\n",
      "8   0.906105  1.034274  0.476051  1.034916  1.045492  1.068230  1.103007  1.170487  1.232633  1.023465  10.412931\n",
      "9   1.108512  0.976870  1.164381  1.051510  1.261429  1.055338  1.102757  0.841496  1.002047  1.255533   9.436275\n",
      "10  0.907316  0.939779  1.017409  0.985111  0.678503  1.165437  1.103010  0.977053  0.803698  0.881686        NaN\n",
      "11  0.906854  0.704296  0.940199  0.616246  1.036927  1.002600  1.770546  1.100997  1.092421  1.109419  10.243687\n",
      "12  1.048392  0.856031  1.018352  0.994697  1.051977  1.290707  1.114178  1.173151  1.039812  0.959561        NaN\n",
      "13  0.617344  0.907872  0.602486  1.012046  1.156365  0.947069  1.227113  0.759941  0.879957  0.956464   9.493057\n",
      "14  0.655016  1.211424  0.956066  1.492648  0.752610  1.544034  1.190800  0.933100  1.013960  1.219755   9.528962\n",
      "15  0.887542  1.068724  1.071423  0.961528  0.735909  1.125133  1.130278  0.905011  0.922937  1.165083  10.232050\n",
      "16  0.797434  0.647392  1.295579  1.060309  1.104388  0.828568  0.936946  0.869334  1.022703  1.162702   8.551916\n",
      "17  1.062849  1.064817  0.896346  0.993058  1.059397  0.785822  1.151794  1.353091  1.132426  1.261096   8.592536\n",
      "18  0.818395  0.922984  0.838301  0.766264  1.050099  1.096494  0.845435  1.080996  1.317203  1.004201        NaN\n",
      "19  0.717539  0.864616  0.899649  1.228565  1.069290  0.955307  0.952636  0.747823  0.752437  1.136391   9.786553\n",
      "20  1.293130  1.122335  1.183080  1.150387  0.863995  1.142800  0.902927  1.183572  1.426607  0.937947  10.310908\n",
      "21  0.954845  1.206200  1.065750  1.158206  1.046451  1.094648  1.016375  1.424431  0.609582  1.064833  11.475356\n",
      "22  1.013506  1.186256  0.894048  0.818123  1.058614  0.985434  1.462932  1.206493  0.969643  0.973971        NaN\n",
      "23  0.715050  0.832156  1.102653  1.280559  0.857130  0.830641  0.626547  0.696126  1.117663  1.019399   9.840061\n",
      "24  0.891123  0.938158  1.019416  0.719630  1.373155  0.697031  1.137252  0.903153  1.056198  1.119031   9.980984\n",
      "25  1.022185  1.066253  1.193729  1.117371  1.094767  0.910697  0.677457  1.253382  0.875460  0.836356   8.997471\n",
      "26  0.769801  1.195109  0.859589  1.438091  0.761739  1.171280  0.905614  0.858466  0.958376  1.418477   9.981487\n",
      "27  1.075140  0.904165  0.934468  0.801893  1.131311  1.042819  1.217790  1.088764  0.901400  0.798797   9.711341\n",
      "28  0.879872  0.962868  0.921578  0.886740  0.805064  0.750852  1.012856  1.154927  0.882127  0.757162  10.322719\n",
      "29  0.941661  0.778733  0.707297  1.019930  1.157417  1.034636  0.784451  0.814614  1.169920  1.231622   9.172769\n",
      "30  0.879659  0.760759  1.059224  0.899305  1.231719  1.077063  0.856939  0.988095  1.071403  1.158333        NaN\n",
      "31  1.370456  1.162505  1.052211  0.689867  0.835864  0.823229  1.135920  0.351747  0.861418  1.124824        NaN\n",
      "32  0.997301  1.271248  1.001023  1.013713  1.192675  1.030745  0.853927  0.795122  1.179920  1.125669   9.891240\n",
      "33  5.080342  4.657373  4.648252  4.860055  5.107782  5.051945  5.415080  5.207508  4.974843  4.885268        NaN\n",
      "34  5.138029  5.270774  4.763348  5.042796  4.792551  4.819137  5.174225  4.897997  5.011145  4.890628  50.593101\n",
      "35  4.919756  4.977092  4.592154  4.977534  4.961932  5.127718  4.934795  4.946025  5.218838  4.993449  49.690454\n",
      "36  5.044818  5.247563  4.946119  4.955806  4.824876  4.667696  5.240243  4.804247  4.661507  4.891315  50.326133\n",
      "37  5.002518  4.681114  5.143508  5.122833  4.723440  4.986784  4.918385  4.911141  5.305910  4.857431  48.748886\n",
      "38  5.019535  4.880125  5.300471  5.151502  5.185236  4.757797  4.592375  5.075460  4.968398  5.021286  50.924027\n",
      "39  4.845398  5.001049  5.014819  4.893900  5.381883  4.869633  4.798383  5.151398  4.914624  4.949005        NaN\n",
      "40  5.004902  5.009396  5.325723  4.884836  4.720286  5.009480  4.625842  4.815567  4.797579  5.300799  49.477277\n",
      "41  5.099600  4.909987  4.723980  4.944990  5.112594  4.827917  4.929697  5.173921  4.669029  4.469806  51.049009\n",
      "42  5.290229  5.124570  4.659324  4.539616  4.869871  4.923089  5.003684  5.271128  5.164634  5.218301  49.295656\n",
      "43  5.191854  4.786476  4.988890  4.696962  4.902575  5.201259  5.335287  5.082687  5.014664  5.249217  48.591539\n",
      "44  5.430636  4.971524  5.076813  5.273375  4.881521  4.884622  5.065385  5.375359  4.742008  4.585322        NaN\n",
      "45  4.846530  5.024059  4.993461  5.328994  4.827202  5.167138  4.956180  4.845242  4.740984  4.931462        NaN\n",
      "46  5.174464  5.102888  4.586512  4.950193  5.009704  4.774059  5.165881  4.751069  4.932843  4.925712  48.719571\n",
      "47  5.036668  5.142323  4.982176  5.115311  4.833810  5.105961  4.557773  4.644256  5.333804  4.718498  51.754794\n",
      "48  5.437961  4.775072  4.739106  5.062250  5.054091  5.288314  5.047123  5.299209  4.948082  4.844437  47.918071\n",
      "49  4.838340  4.693177  5.133935  5.615776  4.989952  4.505671  5.154173  5.130873  4.699371  4.777885  51.696456\n",
      "50  4.832056  5.255535  5.073320  5.223915  4.952210  4.840621  4.704283  4.988883  4.950851  5.350454  50.211017\n",
      "51  4.880121  5.066463  4.812024  4.974416  4.818487  5.115414  5.228751  5.055994  4.945455  5.187136  49.903287\n",
      "52  4.575221  4.850303  4.897227  4.808892  4.884646  4.959391  5.067699  4.774902  4.460623  5.254311  49.455081\n",
      "53  4.894849  5.310230  4.788157  4.678711  5.151078  5.074229  4.916942  5.489150  4.989141  5.144334        NaN\n",
      "54  4.848173  5.023135  4.987464  5.040693  5.100183  4.879203  5.126556  5.025844  4.953813  4.774190  49.962365\n",
      "55  5.030079  5.235859  5.191028  4.848730  4.804489  5.017318  5.454139  5.021879  5.139241  4.895096  51.103302\n",
      "56  5.068351  5.013504  4.802855  4.715549  5.019866  4.968865  5.036373  5.145153  5.369791  5.097875  50.114228\n",
      "57  5.375234  5.412150  5.100809  4.870685  5.150277  5.233556  5.049644  5.096202  5.225313  4.755574  50.150302\n",
      "58  5.190085  5.351068  4.893948  4.783690  4.666119  5.050884  4.908128  5.044777  4.946222  5.142600  49.636388\n",
      "59  4.884619  4.950207  4.841425  5.337428  5.108672  5.067521  4.830031  4.841905  4.778695  4.951935  49.943054\n",
      "60  4.820317  5.194314  4.978594  5.176328  4.867475  4.917625  5.166067  5.094294  5.514672  4.925036  50.307802\n",
      "61  5.098384  5.129075  4.792952  4.998405  5.114120  4.902479  4.828783  5.376405  5.011844  5.142192  48.289832\n",
      "62  4.735953  5.273726  4.889270  5.295989  4.847348  4.913488  5.014313  5.269084  5.002786  5.088853  48.651815\n",
      "63  5.366292  4.807015  4.760424  5.015474  4.639024  5.078890  4.904469  5.318637  4.995175  4.927807  50.743264\n",
      "64  5.235888  5.137210  5.392945  4.827743  4.674492  4.915803  5.095796  4.897757  5.039617  5.231866  50.170865\n",
      "65  4.906165  5.211685  5.007053  5.304625  5.009617  5.057955  5.066732  4.802079  4.971128  4.783787  49.816017\n",
      "66  9.003687  8.884872  8.783789  8.915963  9.309501  8.966576  8.888960  8.982053  8.885764  9.079845  88.705319\n",
      "67  9.069516  9.024402  9.210631  8.943643  9.359176  9.029343  9.376231  9.288023  9.114517  9.129439  91.160827\n",
      "68  8.892048  9.512017  8.992089  8.731110  8.877442  9.241302  8.710397  8.864722  9.279871  8.903363  89.532299\n",
      "69  8.844339  8.980788  9.136300  8.816270  8.922460  8.836613  8.560239  9.360188  9.184927  9.314797  90.346504\n",
      "70  9.039169  9.229855  9.005664  8.799172  9.057173  9.073735  9.088003  8.991968  9.011926  8.754847        NaN\n",
      "71  8.804325  8.859365  9.005951  8.846440  9.066891  8.921332  8.899589  8.713845  8.870613  8.707125  90.477041\n",
      "72  9.081651  8.993002  9.187657  8.993063  9.131709  9.005749  8.795753  9.025621  9.139645  9.044890  90.076822\n",
      "73  8.659483  9.354160  8.896791  9.046843  9.402041  9.255690  9.141671  8.863790  9.078697  9.209420        NaN\n",
      "74  9.205831  8.874607  9.019224  9.310100  8.964611  9.038220  9.048760  9.168129  9.179039  9.336786  90.996267\n",
      "75  9.094519  9.362490  8.907545  8.800329  8.840341  9.009287  8.887184  8.869475  9.127034  8.908223  89.506243\n",
      "76  9.051206  9.141550  8.913101  9.196864  8.724136  8.728029  8.743939  8.910763  9.209911  9.215736        NaN\n",
      "77  9.196538  8.887507  8.938166  8.957202  8.853814  9.149251  9.174491  8.622092  8.892953  8.992298        NaN\n",
      "78  9.333095  9.126482  9.044427  8.990107  8.993375  9.129097  9.130040  8.909539  9.263479  8.965475  91.500760\n",
      "79  9.202874  9.194511  8.904250  9.134964  9.358912  9.432651  8.980165  8.515224  9.039520  9.176732  90.850222\n",
      "80  8.631825  9.124362  9.251151  8.775456  8.896478  8.938444  9.369327  8.683219  9.415052  9.130465        NaN\n",
      "81  8.744085  8.685955  8.821079  9.076482  9.044758  9.043830  8.785983  9.152083  8.862162  8.684722  89.650742\n",
      "82  8.875036  8.854573  8.962626  9.033290  8.996715  9.049877  8.694895  9.157160  9.347193  9.295308  89.678365\n",
      "83  9.005218  8.950496  8.912054  9.098490  9.237679  9.315491  8.861618  9.085092  9.039582  9.276018        NaN\n",
      "84  9.103532  8.985113  9.289396  9.057834  9.505386  8.980941  8.990883  8.806605  8.869716  8.874887  90.381935\n",
      "85  8.854851  9.124134  9.039311  9.491060  8.893826  9.055804  9.048668  8.990458  8.903223  9.079161  90.430042\n",
      "86  9.037353  9.035540  9.206369  8.872452  8.902112  9.121579  8.951753  8.999279  8.935931  9.098806  91.030283\n",
      "87  8.848923  8.732931  8.702888  8.893801  9.208832  9.037322  9.070411  8.768327  9.084833  9.052135  90.238789\n",
      "88  8.877696  9.076040  9.053410  8.875372  9.136378  8.910713  8.749692  9.300680  9.104567  8.889939  89.740958\n",
      "89  8.718668  9.122117  9.177926  8.888905  9.369341  9.038818  9.288753  9.175472  8.885260  8.865675  89.803650\n",
      "90  8.815353  9.111958  9.016457  8.872523  9.116786  9.214726  8.983570  8.955807  8.995129  8.994889        NaN\n",
      "91  8.729663  9.216156  9.213096  9.237803  8.928142  8.794697  9.223459  9.005377  9.428454  9.234546  89.962778\n",
      "92  8.804825  9.166784  8.896542  9.284101  9.118131  9.026594  9.068545  9.041677  9.345509  9.108720  90.727630\n",
      "93  9.210728  9.091836  9.281869  8.885851  9.221741  8.859976  9.091351  8.591653  9.087265  8.925877  90.051946\n",
      "94  8.810120  8.985967  9.459780  8.833529  9.164096  9.239009  9.113953  8.950565  9.007601  9.154340  90.732640\n",
      "95  9.526476  8.667808  8.927432  9.094283  9.101455  8.695363  9.089542  8.863603  9.024006  8.430291  89.919283\n",
      "96  9.098664  9.085924  8.910899  8.889555  9.213335  8.888216  9.128545  8.799676  9.122704  9.229753  90.078635\n",
      "97  9.036967  9.041538  9.290677  9.126586  9.233859  9.075442  9.265831  8.943780  8.795441  8.652057  88.001799\n",
      "98  8.828328  9.054316  9.315914  9.040585  9.276432  9.313105  9.039304  9.359537  8.948525  8.927512  90.916328\n",
      "99  9.140062  8.744650  8.895428  8.696851  9.129742  8.986850  9.141801  9.128169  8.666283  8.776066  90.346488\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 11\n",
      "    ['F0', 'F1', 'F2', 'F3', 'F4']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 100 x 11\n",
      "Missings: 20 (1.8%)\n",
      "Parametros: min_friends=2, max_friends=5\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 80/100 (80.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 20 → 0 missings\n",
      "             20 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 20 → 0 (20 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 20 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.12s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- RESULTADO IMPUTAÇÃO ---\n",
      "          F0        F1        F2        F3        F4        F5        F6        F7        F8        F9     Target\n",
      "0   1.099343  0.788458  0.985598  0.953083  0.787539  1.082556  1.011642  1.043292  0.949486  1.061460  10.088647\n",
      "1   0.972347  1.164509  1.200707  0.716926  1.094718  1.164412  0.771406  1.009114  0.750443  1.162572   9.102746\n",
      "2   1.129538  0.755831  1.072327  0.915871  0.816115  1.379359  1.071557  0.869680  1.326482  1.125926  10.075805\n",
      "3   1.304606  1.041773  0.870976  0.931457  1.309987  0.950922  1.112157  1.428789  0.713972  0.834201   9.322838\n",
      "4   0.953169  0.608066  1.072279  0.839545  0.843349  0.849253  1.216610  1.126784  0.911991  0.887964   9.749378\n",
      "5   0.953173  0.734363  1.307607  0.967743  0.935588  0.822097  1.210760  0.594971  1.026148  1.149459   9.852943\n",
      "6   1.315843  1.039372  0.992835  1.080810  1.162703  0.836838  0.724466  1.037291  1.288255  1.122074   9.174503\n",
      "7   1.153487  1.147693  1.312929  1.377237  0.753827  0.984580  0.812435  0.867643  0.712828  0.995820   9.678614\n",
      "8   0.906105  1.034274  0.476051  1.034916  1.045492  1.068230  1.103007  1.170487  1.232633  1.023465  10.412931\n",
      "9   1.108512  0.976870  1.164381  1.051510  1.261429  1.055338  1.102757  0.841496  1.002047  1.255533   9.436275\n",
      "10  0.907316  0.939779  1.017409  0.985111  0.678503  1.165437  1.103010  0.977053  0.803698  0.881686  10.055321\n",
      "11  0.906854  0.704296  0.940199  0.616246  1.036927  1.002600  1.770546  1.100997  1.092421  1.109419  10.243687\n",
      "12  1.048392  0.856031  1.018352  0.994697  1.051977  1.290707  1.114178  1.173151  1.039812  0.959561   9.855793\n",
      "13  0.617344  0.907872  0.602486  1.012046  1.156365  0.947069  1.227113  0.759941  0.879957  0.956464   9.493057\n",
      "14  0.655016  1.211424  0.956066  1.492648  0.752610  1.544034  1.190800  0.933100  1.013960  1.219755   9.528962\n",
      "15  0.887542  1.068724  1.071423  0.961528  0.735909  1.125133  1.130278  0.905011  0.922937  1.165083  10.232050\n",
      "16  0.797434  0.647392  1.295579  1.060309  1.104388  0.828568  0.936946  0.869334  1.022703  1.162702   8.551916\n",
      "17  1.062849  1.064817  0.896346  0.993058  1.059397  0.785822  1.151794  1.353091  1.132426  1.261096   8.592536\n",
      "18  0.818395  0.922984  0.838301  0.766264  1.050099  1.096494  0.845435  1.080996  1.317203  1.004201   9.874001\n",
      "19  0.717539  0.864616  0.899649  1.228565  1.069290  0.955307  0.952636  0.747823  0.752437  1.136391   9.786553\n",
      "20  1.293130  1.122335  1.183080  1.150387  0.863995  1.142800  0.902927  1.183572  1.426607  0.937947  10.310908\n",
      "21  0.954845  1.206200  1.065750  1.158206  1.046451  1.094648  1.016375  1.424431  0.609582  1.064833  11.475356\n",
      "22  1.013506  1.186256  0.894048  0.818123  1.058614  0.985434  1.462932  1.206493  0.969643  0.973971   9.656162\n",
      "23  0.715050  0.832156  1.102653  1.280559  0.857130  0.830641  0.626547  0.696126  1.117663  1.019399   9.840061\n",
      "24  0.891123  0.938158  1.019416  0.719630  1.373155  0.697031  1.137252  0.903153  1.056198  1.119031   9.980984\n",
      "25  1.022185  1.066253  1.193729  1.117371  1.094767  0.910697  0.677457  1.253382  0.875460  0.836356   8.997471\n",
      "26  0.769801  1.195109  0.859589  1.438091  0.761739  1.171280  0.905614  0.858466  0.958376  1.418477   9.981487\n",
      "27  1.075140  0.904165  0.934468  0.801893  1.131311  1.042819  1.217790  1.088764  0.901400  0.798797   9.711341\n",
      "28  0.879872  0.962868  0.921578  0.886740  0.805064  0.750852  1.012856  1.154927  0.882127  0.757162  10.322719\n",
      "29  0.941661  0.778733  0.707297  1.019930  1.157417  1.034636  0.784451  0.814614  1.169920  1.231622   9.172769\n",
      "30  0.879659  0.760759  1.059224  0.899305  1.231719  1.077063  0.856939  0.988095  1.071403  1.158333   9.240215\n",
      "31  1.370456  1.162505  1.052211  0.689867  0.835864  0.823229  1.135920  0.351747  0.861418  1.124824   9.852117\n",
      "32  0.997301  1.271248  1.001023  1.013713  1.192675  1.030745  0.853927  0.795122  1.179920  1.125669   9.891240\n",
      "33  5.080342  4.657373  4.648252  4.860055  5.107782  5.051945  5.415080  5.207508  4.974843  4.885268  49.053300\n",
      "34  5.138029  5.270774  4.763348  5.042796  4.792551  4.819137  5.174225  4.897997  5.011145  4.890628  50.593101\n",
      "35  4.919756  4.977092  4.592154  4.977534  4.961932  5.127718  4.934795  4.946025  5.218838  4.993449  49.690454\n",
      "36  5.044818  5.247563  4.946119  4.955806  4.824876  4.667696  5.240243  4.804247  4.661507  4.891315  50.326133\n",
      "37  5.002518  4.681114  5.143508  5.122833  4.723440  4.986784  4.918385  4.911141  5.305910  4.857431  48.748886\n",
      "38  5.019535  4.880125  5.300471  5.151502  5.185236  4.757797  4.592375  5.075460  4.968398  5.021286  50.924027\n",
      "39  4.845398  5.001049  5.014819  4.893900  5.381883  4.869633  4.798383  5.151398  4.914624  4.949005  49.787955\n",
      "40  5.004902  5.009396  5.325723  4.884836  4.720286  5.009480  4.625842  4.815567  4.797579  5.300799  49.477277\n",
      "41  5.099600  4.909987  4.723980  4.944990  5.112594  4.827917  4.929697  5.173921  4.669029  4.469806  51.049009\n",
      "42  5.290229  5.124570  4.659324  4.539616  4.869871  4.923089  5.003684  5.271128  5.164634  5.218301  49.295656\n",
      "43  5.191854  4.786476  4.988890  4.696962  4.902575  5.201259  5.335287  5.082687  5.014664  5.249217  48.591539\n",
      "44  5.430636  4.971524  5.076813  5.273375  4.881521  4.884622  5.065385  5.375359  4.742008  4.585322  49.917526\n",
      "45  4.846530  5.024059  4.993461  5.328994  4.827202  5.167138  4.956180  4.845242  4.740984  4.931462  49.903085\n",
      "46  5.174464  5.102888  4.586512  4.950193  5.009704  4.774059  5.165881  4.751069  4.932843  4.925712  48.719571\n",
      "47  5.036668  5.142323  4.982176  5.115311  4.833810  5.105961  4.557773  4.644256  5.333804  4.718498  51.754794\n",
      "48  5.437961  4.775072  4.739106  5.062250  5.054091  5.288314  5.047123  5.299209  4.948082  4.844437  47.918071\n",
      "49  4.838340  4.693177  5.133935  5.615776  4.989952  4.505671  5.154173  5.130873  4.699371  4.777885  51.696456\n",
      "50  4.832056  5.255535  5.073320  5.223915  4.952210  4.840621  4.704283  4.988883  4.950851  5.350454  50.211017\n",
      "51  4.880121  5.066463  4.812024  4.974416  4.818487  5.115414  5.228751  5.055994  4.945455  5.187136  49.903287\n",
      "52  4.575221  4.850303  4.897227  4.808892  4.884646  4.959391  5.067699  4.774902  4.460623  5.254311  49.455081\n",
      "53  4.894849  5.310230  4.788157  4.678711  5.151078  5.074229  4.916942  5.489150  4.989141  5.144334  49.232620\n",
      "54  4.848173  5.023135  4.987464  5.040693  5.100183  4.879203  5.126556  5.025844  4.953813  4.774190  49.962365\n",
      "55  5.030079  5.235859  5.191028  4.848730  4.804489  5.017318  5.454139  5.021879  5.139241  4.895096  51.103302\n",
      "56  5.068351  5.013504  4.802855  4.715549  5.019866  4.968865  5.036373  5.145153  5.369791  5.097875  50.114228\n",
      "57  5.375234  5.412150  5.100809  4.870685  5.150277  5.233556  5.049644  5.096202  5.225313  4.755574  50.150302\n",
      "58  5.190085  5.351068  4.893948  4.783690  4.666119  5.050884  4.908128  5.044777  4.946222  5.142600  49.636388\n",
      "59  4.884619  4.950207  4.841425  5.337428  5.108672  5.067521  4.830031  4.841905  4.778695  4.951935  49.943054\n",
      "60  4.820317  5.194314  4.978594  5.176328  4.867475  4.917625  5.166067  5.094294  5.514672  4.925036  50.307802\n",
      "61  5.098384  5.129075  4.792952  4.998405  5.114120  4.902479  4.828783  5.376405  5.011844  5.142192  48.289832\n",
      "62  4.735953  5.273726  4.889270  5.295989  4.847348  4.913488  5.014313  5.269084  5.002786  5.088853  48.651815\n",
      "63  5.366292  4.807015  4.760424  5.015474  4.639024  5.078890  4.904469  5.318637  4.995175  4.927807  50.743264\n",
      "64  5.235888  5.137210  5.392945  4.827743  4.674492  4.915803  5.095796  4.897757  5.039617  5.231866  50.170865\n",
      "65  4.906165  5.211685  5.007053  5.304625  5.009617  5.057955  5.066732  4.802079  4.971128  4.783787  49.816017\n",
      "66  9.003687  8.884872  8.783789  8.915963  9.309501  8.966576  8.888960  8.982053  8.885764  9.079845  88.705319\n",
      "67  9.069516  9.024402  9.210631  8.943643  9.359176  9.029343  9.376231  9.288023  9.114517  9.129439  91.160827\n",
      "68  8.892048  9.512017  8.992089  8.731110  8.877442  9.241302  8.710397  8.864722  9.279871  8.903363  89.532299\n",
      "69  8.844339  8.980788  9.136300  8.816270  8.922460  8.836613  8.560239  9.360188  9.184927  9.314797  90.346504\n",
      "70  9.039169  9.229855  9.005664  8.799172  9.057173  9.073735  9.088003  8.991968  9.011926  8.754847  90.035738\n",
      "71  8.804325  8.859365  9.005951  8.846440  9.066891  8.921332  8.899589  8.713845  8.870613  8.707125  90.477041\n",
      "72  9.081651  8.993002  9.187657  8.993063  9.131709  9.005749  8.795753  9.025621  9.139645  9.044890  90.076822\n",
      "73  8.659483  9.354160  8.896791  9.046843  9.402041  9.255690  9.141671  8.863790  9.078697  9.209420  90.372258\n",
      "74  9.205831  8.874607  9.019224  9.310100  8.964611  9.038220  9.048760  9.168129  9.179039  9.336786  90.996267\n",
      "75  9.094519  9.362490  8.907545  8.800329  8.840341  9.009287  8.887184  8.869475  9.127034  8.908223  89.506243\n",
      "76  9.051206  9.141550  8.913101  9.196864  8.724136  8.728029  8.743939  8.910763  9.209911  9.215736  90.053267\n",
      "77  9.196538  8.887507  8.938166  8.957202  8.853814  9.149251  9.174491  8.622092  8.892953  8.992298  90.690794\n",
      "78  9.333095  9.126482  9.044427  8.990107  8.993375  9.129097  9.130040  8.909539  9.263479  8.965475  91.500760\n",
      "79  9.202874  9.194511  8.904250  9.134964  9.358912  9.432651  8.980165  8.515224  9.039520  9.176732  90.850222\n",
      "80  8.631825  9.124362  9.251151  8.775456  8.896478  8.938444  9.369327  8.683219  9.415052  9.130465  90.350698\n",
      "81  8.744085  8.685955  8.821079  9.076482  9.044758  9.043830  8.785983  9.152083  8.862162  8.684722  89.650742\n",
      "82  8.875036  8.854573  8.962626  9.033290  8.996715  9.049877  8.694895  9.157160  9.347193  9.295308  89.678365\n",
      "83  9.005218  8.950496  8.912054  9.098490  9.237679  9.315491  8.861618  9.085092  9.039582  9.276018  89.831863\n",
      "84  9.103532  8.985113  9.289396  9.057834  9.505386  8.980941  8.990883  8.806605  8.869716  8.874887  90.381935\n",
      "85  8.854851  9.124134  9.039311  9.491060  8.893826  9.055804  9.048668  8.990458  8.903223  9.079161  90.430042\n",
      "86  9.037353  9.035540  9.206369  8.872452  8.902112  9.121579  8.951753  8.999279  8.935931  9.098806  91.030283\n",
      "87  8.848923  8.732931  8.702888  8.893801  9.208832  9.037322  9.070411  8.768327  9.084833  9.052135  90.238789\n",
      "88  8.877696  9.076040  9.053410  8.875372  9.136378  8.910713  8.749692  9.300680  9.104567  8.889939  89.740958\n",
      "89  8.718668  9.122117  9.177926  8.888905  9.369341  9.038818  9.288753  9.175472  8.885260  8.865675  89.803650\n",
      "90  8.815353  9.111958  9.016457  8.872523  9.116786  9.214726  8.983570  8.955807  8.995129  8.994889  90.198040\n",
      "91  8.729663  9.216156  9.213096  9.237803  8.928142  8.794697  9.223459  9.005377  9.428454  9.234546  89.962778\n",
      "92  8.804825  9.166784  8.896542  9.284101  9.118131  9.026594  9.068545  9.041677  9.345509  9.108720  90.727630\n",
      "93  9.210728  9.091836  9.281869  8.885851  9.221741  8.859976  9.091351  8.591653  9.087265  8.925877  90.051946\n",
      "94  8.810120  8.985967  9.459780  8.833529  9.164096  9.239009  9.113953  8.950565  9.007601  9.154340  90.732640\n",
      "95  9.526476  8.667808  8.927432  9.094283  9.101455  8.695363  9.089542  8.863603  9.024006  8.430291  89.919283\n",
      "96  9.098664  9.085924  8.910899  8.889555  9.213335  8.888216  9.128545  8.799676  9.122704  9.229753  90.078635\n",
      "97  9.036967  9.041538  9.290677  9.126586  9.233859  9.075442  9.265831  8.943780  8.795441  8.652057  88.001799\n",
      "98  8.828328  9.054316  9.315914  9.040585  9.276432  9.313105  9.039304  9.359537  8.948525  8.927512  90.916328\n",
      "99  9.140062  8.744650  8.895428  8.696851  9.129742  8.986850  9.141801  9.128169  8.666283  8.776066  90.346488\n",
      "\n",
      "--- VERIFICAÇÃO DE ERROS ---\n",
      "  ✗ Linha 83, Col 'Target': imputado=89.83, real=92.08, erro=2.24\n",
      "  ✗ Linha 53, Col 'Target': imputado=49.23, real=50.40, erro=1.17\n",
      "  ✓ Linha 70, Col 'Target': imputado=90.04, real=89.95, erro=0.08\n",
      "  ✓ Linha 45, Col 'Target': imputado=49.90, real=50.61, erro=0.70\n",
      "  ✗ Linha 44, Col 'Target': imputado=49.92, real=48.44, erro=1.47\n",
      "  ✓ Linha 39, Col 'Target': imputado=49.79, real=49.82, erro=0.03\n",
      "  ✗ Linha 22, Col 'Target': imputado=9.66, real=10.86, erro=1.20\n",
      "  ✓ Linha 80, Col 'Target': imputado=90.35, real=89.65, erro=0.70\n",
      "  ✓ Linha 10, Col 'Target': imputado=10.06, real=9.18, erro=0.88\n",
      "  ✓ Linha 0, Col 'Target': imputado=10.09, real=9.99, erro=0.10\n",
      "  ✓ Linha 18, Col 'Target': imputado=9.87, real=9.28, erro=0.59\n",
      "  ✗ Linha 30, Col 'Target': imputado=9.24, real=10.52, erro=1.28\n",
      "  ✗ Linha 73, Col 'Target': imputado=90.37, real=88.72, erro=1.66\n",
      "  ✗ Linha 33, Col 'Target': imputado=49.05, real=50.62, erro=1.56\n",
      "  ✓ Linha 90, Col 'Target': imputado=90.20, real=89.93, erro=0.27\n",
      "  ✗ Linha 4, Col 'Target': imputado=9.75, real=10.98, erro=1.23\n",
      "  ✗ Linha 76, Col 'Target': imputado=90.05, real=88.44, erro=1.61\n",
      "  ✗ Linha 77, Col 'Target': imputado=90.69, real=89.57, erro=1.12\n",
      "  ✓ Linha 12, Col 'Target': imputado=9.86, real=10.24, erro=0.39\n",
      "  ✗ Linha 31, Col 'Target': imputado=9.85, real=11.53, erro=1.68\n",
      "\n",
      "MAE total: 0.9980\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO DETALHADO para linha 83, coluna 'Target'\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO: Linha 83, Coluna 'Target'\n",
      "======================================================================\n",
      "\n",
      "Dados da linha 83:\n",
      "F0        9.005218\n",
      "F1        8.950496\n",
      "F2        8.912054\n",
      "F3        9.098490\n",
      "F4        9.237679\n",
      "F5        9.315491\n",
      "F6        8.861618\n",
      "F7        9.085092\n",
      "F8        9.039582\n",
      "F9        9.276018\n",
      "Target         NaN\n",
      "\n",
      "Valor REAL (ground truth): 92.07674798356084\n",
      "\n",
      "Features disponíveis (10): ['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9']\n",
      "Features em falta (0): []\n",
      "\n",
      "--- PESOS MI para prever 'Target' ---\n",
      "  ✓ F0: MI=1.0183, peso=0.1118\n",
      "  ✓ F6: MI=0.9784, peso=0.1074\n",
      "  ✓ F7: MI=0.9548, peso=0.1049\n",
      "  ✓ F9: MI=0.9519, peso=0.1045\n",
      "  ✓ F1: MI=0.9341, peso=0.1026\n",
      "  ✓ F8: MI=0.8836, peso=0.0970\n",
      "  ✓ F5: MI=0.8618, peso=0.0946\n",
      "  ✓ F4: MI=0.8520, peso=0.0936\n",
      "  ✓ F3: MI=0.8393, peso=0.0922\n",
      "  ✓ F2: MI=0.8316, peso=0.0913\n",
      "\n",
      "--- DONORS POTENCIAIS (80 linhas com target preenchido) ---\n",
      "\n",
      "--- RANGE FACTORS ---\n",
      "  F0: 0.3682\n",
      "  F1: 0.3716\n",
      "  F2: 0.3672\n",
      "  F3: 0.3690\n",
      "  F4: 0.3762\n",
      "  F5: 0.3765\n",
      "  F6: 0.3739\n",
      "  F7: 0.3632\n",
      "  F8: 0.3749\n",
      "  F9: 0.3799\n",
      "\n",
      "--- TOP 10 DONORS (por distância) ---\n",
      "  1. Linha 66: dist=0.0148, overlap=10/10, target=88.71\n",
      "  2. Linha 72: dist=0.0154, overlap=10/10, target=90.08\n",
      "  3. Linha 82: dist=0.0160, overlap=10/10, target=89.68\n",
      "  4. Linha 74: dist=0.0169, overlap=10/10, target=91.00\n",
      "  5. Linha 86: dist=0.0171, overlap=10/10, target=91.03\n",
      "  6. Linha 92: dist=0.0189, overlap=10/10, target=90.73\n",
      "  7. Linha 96: dist=0.0196, overlap=10/10, target=90.08\n",
      "  8. Linha 87: dist=0.0202, overlap=10/10, target=90.24\n",
      "  9. Linha 98: dist=0.0205, overlap=10/10, target=90.92\n",
      "  10. Linha 85: dist=0.0210, overlap=10/10, target=90.43\n",
      "\n",
      "--- ADAPTIVE K ---\n",
      "  density_trust: 0.9842 (mean_dist=0.0160)\n",
      "  consistency_trust: 0.9904\n",
      "  k escolhido: 4 (range [2, 5])\n",
      "\n",
      "--- VIZINHOS FINAIS (k=4) ---\n",
      "  1. Linha 66: dist=0.0148, target=88.71\n",
      "  2. Linha 72: dist=0.0154, target=90.08\n",
      "  3. Linha 82: dist=0.0160, target=89.68\n",
      "  4. Linha 74: dist=0.0169, target=91.00\n",
      "\n",
      "  Pesos IDW: [0.26519685 0.25600462 0.24588472 0.2329138 ]\n",
      "\n",
      "--- RESULTADO ---\n",
      "  Valor imputado: 89.8293\n",
      "  Valor real: 92.0767\n",
      "  Erro absoluto: 2.2475\n",
      "  Status: ✗ MAU\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "MAE para 20% missing: 0.9980\n",
      "✓ TESTE 1.3 PASSOU: MAE=0.9980 < 5.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "# 3 clusters\n",
    "n_per_cluster = 33\n",
    "\n",
    "def make_cluster(center, target_center, n, n_features=10):\n",
    "    data = {f'F{i}': np.random.normal(center, 0.2, n) for i in range(n_features)}\n",
    "    data['Target'] = np.random.normal(target_center, 1.0, n)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "cluster1 = make_cluster(1.0, 10.0, n_per_cluster)\n",
    "cluster2 = make_cluster(5.0, 50.0, n_per_cluster)\n",
    "cluster3 = make_cluster(9.0, 90.0, n_per_cluster + 1)  # +1 para dar 100\n",
    "\n",
    "data_1_3 = pd.concat([cluster1, cluster2, cluster3], ignore_index=True)\n",
    "\n",
    "# 20% missings aleatórios no Target\n",
    "np.random.seed(42)\n",
    "missing_rows = np.random.choice(100, 20, replace=False)\n",
    "missing_indices_1_3 = [(row, 'Target') for row in missing_rows]\n",
    "\n",
    "result, imputer, mae = run_test_with_diagnostics(\n",
    "    data_1_3,\n",
    "    missing_indices=missing_indices_1_3,\n",
    "    target_col='Target',\n",
    "    test_name=\"1.3 - Dataset maior (100x11, 20% missing)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nMAE para 20% missing: {mae:.4f}\")\n",
    "assert mae < 5.0, f\"FALHOU: MAE {mae} muito alto\"\n",
    "print(f\"✓ TESTE 1.3 PASSOU: MAE={mae:.4f} < 5.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste 1.4: Dataset maior com 40% missing (verificar colapso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# TESTE: 1.4 - Dataset maior (100x11, 40% missing)\n",
      "######################################################################\n",
      "\n",
      "Dataset: 100 linhas x 11 colunas\n",
      "Missings introduzidos: 40\n",
      "PDS: True\n",
      "\n",
      "--- DADOS COMPLETOS (ground truth) ---\n",
      "          F0        F1        F2        F3        F4        F5        F6        F7        F8        F9     Target\n",
      "0   1.099343  0.788458  0.985598  0.953083  0.787539  1.082556  1.011642  1.043292  0.949486  1.061460   9.987753\n",
      "1   0.972347  1.164509  1.200707  0.716926  1.094718  1.164412  0.771406  1.009114  0.750443  1.162572   9.102746\n",
      "2   1.129538  0.755831  1.072327  0.915871  0.816115  1.379359  1.071557  0.869680  1.326482  1.125926  10.075805\n",
      "3   1.304606  1.041773  0.870976  0.931457  1.309987  0.950922  1.112157  1.428789  0.713972  0.834201   9.322838\n",
      "4   0.953169  0.608066  1.072279  0.839545  0.843349  0.849253  1.216610  1.126784  0.911991  0.887964  10.975120\n",
      "5   0.953173  0.734363  1.307607  0.967743  0.935588  0.822097  1.210760  0.594971  1.026148  1.149459   9.852943\n",
      "6   1.315843  1.039372  0.992835  1.080810  1.162703  0.836838  0.724466  1.037291  1.288255  1.122074   9.174503\n",
      "7   1.153487  1.147693  1.312929  1.377237  0.753827  0.984580  0.812435  0.867643  0.712828  0.995820   9.678614\n",
      "8   0.906105  1.034274  0.476051  1.034916  1.045492  1.068230  1.103007  1.170487  1.232633  1.023465  10.412931\n",
      "9   1.108512  0.976870  1.164381  1.051510  1.261429  1.055338  1.102757  0.841496  1.002047  1.255533   9.436275\n",
      "10  0.907316  0.939779  1.017409  0.985111  0.678503  1.165437  1.103010  0.977053  0.803698  0.881686   9.177780\n",
      "11  0.906854  0.704296  0.940199  0.616246  1.036927  1.002600  1.770546  1.100997  1.092421  1.109419  10.243687\n",
      "12  1.048392  0.856031  1.018352  0.994697  1.051977  1.290707  1.114178  1.173151  1.039812  0.959561  10.244967\n",
      "13  0.617344  0.907872  0.602486  1.012046  1.156365  0.947069  1.227113  0.759941  0.879957  0.956464   9.493057\n",
      "14  0.655016  1.211424  0.956066  1.492648  0.752610  1.544034  1.190800  0.933100  1.013960  1.219755   9.528962\n",
      "15  0.887542  1.068724  1.071423  0.961528  0.735909  1.125133  1.130278  0.905011  0.922937  1.165083  10.232050\n",
      "16  0.797434  0.647392  1.295579  1.060309  1.104388  0.828568  0.936946  0.869334  1.022703  1.162702   8.551916\n",
      "17  1.062849  1.064817  0.896346  0.993058  1.059397  0.785822  1.151794  1.353091  1.132426  1.261096   8.592536\n",
      "18  0.818395  0.922984  0.838301  0.766264  1.050099  1.096494  0.845435  1.080996  1.317203  1.004201   9.281556\n",
      "19  0.717539  0.864616  0.899649  1.228565  1.069290  0.955307  0.952636  0.747823  0.752437  1.136391   9.786553\n",
      "20  1.293130  1.122335  1.183080  1.150387  0.863995  1.142800  0.902927  1.183572  1.426607  0.937947  10.310908\n",
      "21  0.954845  1.206200  1.065750  1.158206  1.046451  1.094648  1.016375  1.424431  0.609582  1.064833  11.475356\n",
      "22  1.013506  1.186256  0.894048  0.818123  1.058614  0.985434  1.462932  1.206493  0.969643  0.973971  10.857660\n",
      "23  0.715050  0.832156  1.102653  1.280559  0.857130  0.830641  0.626547  0.696126  1.117663  1.019399   9.840061\n",
      "24  0.891123  0.938158  1.019416  0.719630  1.373155  0.697031  1.137252  0.903153  1.056198  1.119031   9.980984\n",
      "25  1.022185  1.066253  1.193729  1.117371  1.094767  0.910697  0.677457  1.253382  0.875460  0.836356   8.997471\n",
      "26  0.769801  1.195109  0.859589  1.438091  0.761739  1.171280  0.905614  0.858466  0.958376  1.418477   9.981487\n",
      "27  1.075140  0.904165  0.934468  0.801893  1.131311  1.042819  1.217790  1.088764  0.901400  0.798797   9.711341\n",
      "28  0.879872  0.962868  0.921578  0.886740  0.805064  0.750852  1.012856  1.154927  0.882127  0.757162  10.322719\n",
      "29  0.941661  0.778733  0.707297  1.019930  1.157417  1.034636  0.784451  0.814614  1.169920  1.231622   9.172769\n",
      "30  0.879659  0.760759  1.059224  0.899305  1.231719  1.077063  0.856939  0.988095  1.071403  1.158333  10.519347\n",
      "31  1.370456  1.162505  1.052211  0.689867  0.835864  0.823229  1.135920  0.351747  0.861418  1.124824  11.532739\n",
      "32  0.997301  1.271248  1.001023  1.013713  1.192675  1.030745  0.853927  0.795122  1.179920  1.125669   9.891240\n",
      "33  5.080342  4.657373  4.648252  4.860055  5.107782  5.051945  5.415080  5.207508  4.974843  4.885268  50.615936\n",
      "34  5.138029  5.270774  4.763348  5.042796  4.792551  4.819137  5.174225  4.897997  5.011145  4.890628  50.593101\n",
      "35  4.919756  4.977092  4.592154  4.977534  4.961932  5.127718  4.934795  4.946025  5.218838  4.993449  49.690454\n",
      "36  5.044818  5.247563  4.946119  4.955806  4.824876  4.667696  5.240243  4.804247  4.661507  4.891315  50.326133\n",
      "37  5.002518  4.681114  5.143508  5.122833  4.723440  4.986784  4.918385  4.911141  5.305910  4.857431  48.748886\n",
      "38  5.019535  4.880125  5.300471  5.151502  5.185236  4.757797  4.592375  5.075460  4.968398  5.021286  50.924027\n",
      "39  4.845398  5.001049  5.014819  4.893900  5.381883  4.869633  4.798383  5.151398  4.914624  4.949005  49.815098\n",
      "40  5.004902  5.009396  5.325723  4.884836  4.720286  5.009480  4.625842  4.815567  4.797579  5.300799  49.477277\n",
      "41  5.099600  4.909987  4.723980  4.944990  5.112594  4.827917  4.929697  5.173921  4.669029  4.469806  51.049009\n",
      "42  5.290229  5.124570  4.659324  4.539616  4.869871  4.923089  5.003684  5.271128  5.164634  5.218301  49.295656\n",
      "43  5.191854  4.786476  4.988890  4.696962  4.902575  5.201259  5.335287  5.082687  5.014664  5.249217  48.591539\n",
      "44  5.430636  4.971524  5.076813  5.273375  4.881521  4.884622  5.065385  5.375359  4.742008  4.585322  48.443371\n",
      "45  4.846530  5.024059  4.993461  5.328994  4.827202  5.167138  4.956180  4.845242  4.740984  4.931462  50.606010\n",
      "46  5.174464  5.102888  4.586512  4.950193  5.009704  4.774059  5.165881  4.751069  4.932843  4.925712  48.719571\n",
      "47  5.036668  5.142323  4.982176  5.115311  4.833810  5.105961  4.557773  4.644256  5.333804  4.718498  51.754794\n",
      "48  5.437961  4.775072  4.739106  5.062250  5.054091  5.288314  5.047123  5.299209  4.948082  4.844437  47.918071\n",
      "49  4.838340  4.693177  5.133935  5.615776  4.989952  4.505671  5.154173  5.130873  4.699371  4.777885  51.696456\n",
      "50  4.832056  5.255535  5.073320  5.223915  4.952210  4.840621  4.704283  4.988883  4.950851  5.350454  50.211017\n",
      "51  4.880121  5.066463  4.812024  4.974416  4.818487  5.115414  5.228751  5.055994  4.945455  5.187136  49.903287\n",
      "52  4.575221  4.850303  4.897227  4.808892  4.884646  4.959391  5.067699  4.774902  4.460623  5.254311  49.455081\n",
      "53  4.894849  5.310230  4.788157  4.678711  5.151078  5.074229  4.916942  5.489150  4.989141  5.144334  50.399136\n",
      "54  4.848173  5.023135  4.987464  5.040693  5.100183  4.879203  5.126556  5.025844  4.953813  4.774190  49.962365\n",
      "55  5.030079  5.235859  5.191028  4.848730  4.804489  5.017318  5.454139  5.021879  5.139241  4.895096  51.103302\n",
      "56  5.068351  5.013504  4.802855  4.715549  5.019866  4.968865  5.036373  5.145153  5.369791  5.097875  50.114228\n",
      "57  5.375234  5.412150  5.100809  4.870685  5.150277  5.233556  5.049644  5.096202  5.225313  4.755574  50.150302\n",
      "58  5.190085  5.351068  4.893948  4.783690  4.666119  5.050884  4.908128  5.044777  4.946222  5.142600  49.636388\n",
      "59  4.884619  4.950207  4.841425  5.337428  5.108672  5.067521  4.830031  4.841905  4.778695  4.951935  49.943054\n",
      "60  4.820317  5.194314  4.978594  5.176328  4.867475  4.917625  5.166067  5.094294  5.514672  4.925036  50.307802\n",
      "61  5.098384  5.129075  4.792952  4.998405  5.114120  4.902479  4.828783  5.376405  5.011844  5.142192  48.289832\n",
      "62  4.735953  5.273726  4.889270  5.295989  4.847348  4.913488  5.014313  5.269084  5.002786  5.088853  48.651815\n",
      "63  5.366292  4.807015  4.760424  5.015474  4.639024  5.078890  4.904469  5.318637  4.995175  4.927807  50.743264\n",
      "64  5.235888  5.137210  5.392945  4.827743  4.674492  4.915803  5.095796  4.897757  5.039617  5.231866  50.170865\n",
      "65  4.906165  5.211685  5.007053  5.304625  5.009617  5.057955  5.066732  4.802079  4.971128  4.783787  49.816017\n",
      "66  9.003687  8.884872  8.783789  8.915963  9.309501  8.966576  8.888960  8.982053  8.885764  9.079845  88.705319\n",
      "67  9.069516  9.024402  9.210631  8.943643  9.359176  9.029343  9.376231  9.288023  9.114517  9.129439  91.160827\n",
      "68  8.892048  9.512017  8.992089  8.731110  8.877442  9.241302  8.710397  8.864722  9.279871  8.903363  89.532299\n",
      "69  8.844339  8.980788  9.136300  8.816270  8.922460  8.836613  8.560239  9.360188  9.184927  9.314797  90.346504\n",
      "70  9.039169  9.229855  9.005664  8.799172  9.057173  9.073735  9.088003  8.991968  9.011926  8.754847  89.953079\n",
      "71  8.804325  8.859365  9.005951  8.846440  9.066891  8.921332  8.899589  8.713845  8.870613  8.707125  90.477041\n",
      "72  9.081651  8.993002  9.187657  8.993063  9.131709  9.005749  8.795753  9.025621  9.139645  9.044890  90.076822\n",
      "73  8.659483  9.354160  8.896791  9.046843  9.402041  9.255690  9.141671  8.863790  9.078697  9.209420  88.717008\n",
      "74  9.205831  8.874607  9.019224  9.310100  8.964611  9.038220  9.048760  9.168129  9.179039  9.336786  90.996267\n",
      "75  9.094519  9.362490  8.907545  8.800329  8.840341  9.009287  8.887184  8.869475  9.127034  8.908223  89.506243\n",
      "76  9.051206  9.141550  8.913101  9.196864  8.724136  8.728029  8.743939  8.910763  9.209911  9.215736  88.443418\n",
      "77  9.196538  8.887507  8.938166  8.957202  8.853814  9.149251  9.174491  8.622092  8.892953  8.992298  89.571885\n",
      "78  9.333095  9.126482  9.044427  8.990107  8.993375  9.129097  9.130040  8.909539  9.263479  8.965475  91.500760\n",
      "79  9.202874  9.194511  8.904250  9.134964  9.358912  9.432651  8.980165  8.515224  9.039520  9.176732  90.850222\n",
      "80  8.631825  9.124362  9.251151  8.775456  8.896478  8.938444  9.369327  8.683219  9.415052  9.130465  89.651348\n",
      "81  8.744085  8.685955  8.821079  9.076482  9.044758  9.043830  8.785983  9.152083  8.862162  8.684722  89.650742\n",
      "82  8.875036  8.854573  8.962626  9.033290  8.996715  9.049877  8.694895  9.157160  9.347193  9.295308  89.678365\n",
      "83  9.005218  8.950496  8.912054  9.098490  9.237679  9.315491  8.861618  9.085092  9.039582  9.276018  92.076748\n",
      "84  9.103532  8.985113  9.289396  9.057834  9.505386  8.980941  8.990883  8.806605  8.869716  8.874887  90.381935\n",
      "85  8.854851  9.124134  9.039311  9.491060  8.893826  9.055804  9.048668  8.990458  8.903223  9.079161  90.430042\n",
      "86  9.037353  9.035540  9.206369  8.872452  8.902112  9.121579  8.951753  8.999279  8.935931  9.098806  91.030283\n",
      "87  8.848923  8.732931  8.702888  8.893801  9.208832  9.037322  9.070411  8.768327  9.084833  9.052135  90.238789\n",
      "88  8.877696  9.076040  9.053410  8.875372  9.136378  8.910713  8.749692  9.300680  9.104567  8.889939  89.740958\n",
      "89  8.718668  9.122117  9.177926  8.888905  9.369341  9.038818  9.288753  9.175472  8.885260  8.865675  89.803650\n",
      "90  8.815353  9.111958  9.016457  8.872523  9.116786  9.214726  8.983570  8.955807  8.995129  8.994889  89.928399\n",
      "91  8.729663  9.216156  9.213096  9.237803  8.928142  8.794697  9.223459  9.005377  9.428454  9.234546  89.962778\n",
      "92  8.804825  9.166784  8.896542  9.284101  9.118131  9.026594  9.068545  9.041677  9.345509  9.108720  90.727630\n",
      "93  9.210728  9.091836  9.281869  8.885851  9.221741  8.859976  9.091351  8.591653  9.087265  8.925877  90.051946\n",
      "94  8.810120  8.985967  9.459780  8.833529  9.164096  9.239009  9.113953  8.950565  9.007601  9.154340  90.732640\n",
      "95  9.526476  8.667808  8.927432  9.094283  9.101455  8.695363  9.089542  8.863603  9.024006  8.430291  89.919283\n",
      "96  9.098664  9.085924  8.910899  8.889555  9.213335  8.888216  9.128545  8.799676  9.122704  9.229753  90.078635\n",
      "97  9.036967  9.041538  9.290677  9.126586  9.233859  9.075442  9.265831  8.943780  8.795441  8.652057  88.001799\n",
      "98  8.828328  9.054316  9.315914  9.040585  9.276432  9.313105  9.039304  9.359537  8.948525  8.927512  90.916328\n",
      "99  9.140062  8.744650  8.895428  8.696851  9.129742  8.986850  9.141801  9.128169  8.666283  8.776066  90.346488\n",
      "\n",
      "--- DADOS COM MISSINGS ---\n",
      "          F0        F1        F2        F3        F4        F5        F6        F7        F8        F9     Target\n",
      "0   1.099343  0.788458  0.985598  0.953083  0.787539  1.082556  1.011642  1.043292  0.949486  1.061460        NaN\n",
      "1   0.972347  1.164509  1.200707  0.716926  1.094718  1.164412  0.771406  1.009114  0.750443  1.162572   9.102746\n",
      "2   1.129538  0.755831  1.072327  0.915871  0.816115  1.379359  1.071557  0.869680  1.326482  1.125926  10.075805\n",
      "3   1.304606  1.041773  0.870976  0.931457  1.309987  0.950922  1.112157  1.428789  0.713972  0.834201   9.322838\n",
      "4   0.953169  0.608066  1.072279  0.839545  0.843349  0.849253  1.216610  1.126784  0.911991  0.887964        NaN\n",
      "5   0.953173  0.734363  1.307607  0.967743  0.935588  0.822097  1.210760  0.594971  1.026148  1.149459        NaN\n",
      "6   1.315843  1.039372  0.992835  1.080810  1.162703  0.836838  0.724466  1.037291  1.288255  1.122074   9.174503\n",
      "7   1.153487  1.147693  1.312929  1.377237  0.753827  0.984580  0.812435  0.867643  0.712828  0.995820   9.678614\n",
      "8   0.906105  1.034274  0.476051  1.034916  1.045492  1.068230  1.103007  1.170487  1.232633  1.023465  10.412931\n",
      "9   1.108512  0.976870  1.164381  1.051510  1.261429  1.055338  1.102757  0.841496  1.002047  1.255533        NaN\n",
      "10  0.907316  0.939779  1.017409  0.985111  0.678503  1.165437  1.103010  0.977053  0.803698  0.881686        NaN\n",
      "11  0.906854  0.704296  0.940199  0.616246  1.036927  1.002600  1.770546  1.100997  1.092421  1.109419        NaN\n",
      "12  1.048392  0.856031  1.018352  0.994697  1.051977  1.290707  1.114178  1.173151  1.039812  0.959561        NaN\n",
      "13  0.617344  0.907872  0.602486  1.012046  1.156365  0.947069  1.227113  0.759941  0.879957  0.956464   9.493057\n",
      "14  0.655016  1.211424  0.956066  1.492648  0.752610  1.544034  1.190800  0.933100  1.013960  1.219755   9.528962\n",
      "15  0.887542  1.068724  1.071423  0.961528  0.735909  1.125133  1.130278  0.905011  0.922937  1.165083        NaN\n",
      "16  0.797434  0.647392  1.295579  1.060309  1.104388  0.828568  0.936946  0.869334  1.022703  1.162702        NaN\n",
      "17  1.062849  1.064817  0.896346  0.993058  1.059397  0.785822  1.151794  1.353091  1.132426  1.261096   8.592536\n",
      "18  0.818395  0.922984  0.838301  0.766264  1.050099  1.096494  0.845435  1.080996  1.317203  1.004201        NaN\n",
      "19  0.717539  0.864616  0.899649  1.228565  1.069290  0.955307  0.952636  0.747823  0.752437  1.136391   9.786553\n",
      "20  1.293130  1.122335  1.183080  1.150387  0.863995  1.142800  0.902927  1.183572  1.426607  0.937947  10.310908\n",
      "21  0.954845  1.206200  1.065750  1.158206  1.046451  1.094648  1.016375  1.424431  0.609582  1.064833  11.475356\n",
      "22  1.013506  1.186256  0.894048  0.818123  1.058614  0.985434  1.462932  1.206493  0.969643  0.973971        NaN\n",
      "23  0.715050  0.832156  1.102653  1.280559  0.857130  0.830641  0.626547  0.696126  1.117663  1.019399   9.840061\n",
      "24  0.891123  0.938158  1.019416  0.719630  1.373155  0.697031  1.137252  0.903153  1.056198  1.119031   9.980984\n",
      "25  1.022185  1.066253  1.193729  1.117371  1.094767  0.910697  0.677457  1.253382  0.875460  0.836356   8.997471\n",
      "26  0.769801  1.195109  0.859589  1.438091  0.761739  1.171280  0.905614  0.858466  0.958376  1.418477        NaN\n",
      "27  1.075140  0.904165  0.934468  0.801893  1.131311  1.042819  1.217790  1.088764  0.901400  0.798797   9.711341\n",
      "28  0.879872  0.962868  0.921578  0.886740  0.805064  0.750852  1.012856  1.154927  0.882127  0.757162        NaN\n",
      "29  0.941661  0.778733  0.707297  1.019930  1.157417  1.034636  0.784451  0.814614  1.169920  1.231622   9.172769\n",
      "30  0.879659  0.760759  1.059224  0.899305  1.231719  1.077063  0.856939  0.988095  1.071403  1.158333        NaN\n",
      "31  1.370456  1.162505  1.052211  0.689867  0.835864  0.823229  1.135920  0.351747  0.861418  1.124824        NaN\n",
      "32  0.997301  1.271248  1.001023  1.013713  1.192675  1.030745  0.853927  0.795122  1.179920  1.125669   9.891240\n",
      "33  5.080342  4.657373  4.648252  4.860055  5.107782  5.051945  5.415080  5.207508  4.974843  4.885268        NaN\n",
      "34  5.138029  5.270774  4.763348  5.042796  4.792551  4.819137  5.174225  4.897997  5.011145  4.890628  50.593101\n",
      "35  4.919756  4.977092  4.592154  4.977534  4.961932  5.127718  4.934795  4.946025  5.218838  4.993449        NaN\n",
      "36  5.044818  5.247563  4.946119  4.955806  4.824876  4.667696  5.240243  4.804247  4.661507  4.891315  50.326133\n",
      "37  5.002518  4.681114  5.143508  5.122833  4.723440  4.986784  4.918385  4.911141  5.305910  4.857431  48.748886\n",
      "38  5.019535  4.880125  5.300471  5.151502  5.185236  4.757797  4.592375  5.075460  4.968398  5.021286  50.924027\n",
      "39  4.845398  5.001049  5.014819  4.893900  5.381883  4.869633  4.798383  5.151398  4.914624  4.949005        NaN\n",
      "40  5.004902  5.009396  5.325723  4.884836  4.720286  5.009480  4.625842  4.815567  4.797579  5.300799        NaN\n",
      "41  5.099600  4.909987  4.723980  4.944990  5.112594  4.827917  4.929697  5.173921  4.669029  4.469806  51.049009\n",
      "42  5.290229  5.124570  4.659324  4.539616  4.869871  4.923089  5.003684  5.271128  5.164634  5.218301        NaN\n",
      "43  5.191854  4.786476  4.988890  4.696962  4.902575  5.201259  5.335287  5.082687  5.014664  5.249217  48.591539\n",
      "44  5.430636  4.971524  5.076813  5.273375  4.881521  4.884622  5.065385  5.375359  4.742008  4.585322        NaN\n",
      "45  4.846530  5.024059  4.993461  5.328994  4.827202  5.167138  4.956180  4.845242  4.740984  4.931462        NaN\n",
      "46  5.174464  5.102888  4.586512  4.950193  5.009704  4.774059  5.165881  4.751069  4.932843  4.925712  48.719571\n",
      "47  5.036668  5.142323  4.982176  5.115311  4.833810  5.105961  4.557773  4.644256  5.333804  4.718498        NaN\n",
      "48  5.437961  4.775072  4.739106  5.062250  5.054091  5.288314  5.047123  5.299209  4.948082  4.844437  47.918071\n",
      "49  4.838340  4.693177  5.133935  5.615776  4.989952  4.505671  5.154173  5.130873  4.699371  4.777885  51.696456\n",
      "50  4.832056  5.255535  5.073320  5.223915  4.952210  4.840621  4.704283  4.988883  4.950851  5.350454  50.211017\n",
      "51  4.880121  5.066463  4.812024  4.974416  4.818487  5.115414  5.228751  5.055994  4.945455  5.187136  49.903287\n",
      "52  4.575221  4.850303  4.897227  4.808892  4.884646  4.959391  5.067699  4.774902  4.460623  5.254311  49.455081\n",
      "53  4.894849  5.310230  4.788157  4.678711  5.151078  5.074229  4.916942  5.489150  4.989141  5.144334        NaN\n",
      "54  4.848173  5.023135  4.987464  5.040693  5.100183  4.879203  5.126556  5.025844  4.953813  4.774190  49.962365\n",
      "55  5.030079  5.235859  5.191028  4.848730  4.804489  5.017318  5.454139  5.021879  5.139241  4.895096        NaN\n",
      "56  5.068351  5.013504  4.802855  4.715549  5.019866  4.968865  5.036373  5.145153  5.369791  5.097875  50.114228\n",
      "57  5.375234  5.412150  5.100809  4.870685  5.150277  5.233556  5.049644  5.096202  5.225313  4.755574  50.150302\n",
      "58  5.190085  5.351068  4.893948  4.783690  4.666119  5.050884  4.908128  5.044777  4.946222  5.142600  49.636388\n",
      "59  4.884619  4.950207  4.841425  5.337428  5.108672  5.067521  4.830031  4.841905  4.778695  4.951935  49.943054\n",
      "60  4.820317  5.194314  4.978594  5.176328  4.867475  4.917625  5.166067  5.094294  5.514672  4.925036  50.307802\n",
      "61  5.098384  5.129075  4.792952  4.998405  5.114120  4.902479  4.828783  5.376405  5.011844  5.142192  48.289832\n",
      "62  4.735953  5.273726  4.889270  5.295989  4.847348  4.913488  5.014313  5.269084  5.002786  5.088853  48.651815\n",
      "63  5.366292  4.807015  4.760424  5.015474  4.639024  5.078890  4.904469  5.318637  4.995175  4.927807  50.743264\n",
      "64  5.235888  5.137210  5.392945  4.827743  4.674492  4.915803  5.095796  4.897757  5.039617  5.231866  50.170865\n",
      "65  4.906165  5.211685  5.007053  5.304625  5.009617  5.057955  5.066732  4.802079  4.971128  4.783787        NaN\n",
      "66  9.003687  8.884872  8.783789  8.915963  9.309501  8.966576  8.888960  8.982053  8.885764  9.079845        NaN\n",
      "67  9.069516  9.024402  9.210631  8.943643  9.359176  9.029343  9.376231  9.288023  9.114517  9.129439  91.160827\n",
      "68  8.892048  9.512017  8.992089  8.731110  8.877442  9.241302  8.710397  8.864722  9.279871  8.903363  89.532299\n",
      "69  8.844339  8.980788  9.136300  8.816270  8.922460  8.836613  8.560239  9.360188  9.184927  9.314797        NaN\n",
      "70  9.039169  9.229855  9.005664  8.799172  9.057173  9.073735  9.088003  8.991968  9.011926  8.754847        NaN\n",
      "71  8.804325  8.859365  9.005951  8.846440  9.066891  8.921332  8.899589  8.713845  8.870613  8.707125  90.477041\n",
      "72  9.081651  8.993002  9.187657  8.993063  9.131709  9.005749  8.795753  9.025621  9.139645  9.044890        NaN\n",
      "73  8.659483  9.354160  8.896791  9.046843  9.402041  9.255690  9.141671  8.863790  9.078697  9.209420        NaN\n",
      "74  9.205831  8.874607  9.019224  9.310100  8.964611  9.038220  9.048760  9.168129  9.179039  9.336786  90.996267\n",
      "75  9.094519  9.362490  8.907545  8.800329  8.840341  9.009287  8.887184  8.869475  9.127034  8.908223  89.506243\n",
      "76  9.051206  9.141550  8.913101  9.196864  8.724136  8.728029  8.743939  8.910763  9.209911  9.215736        NaN\n",
      "77  9.196538  8.887507  8.938166  8.957202  8.853814  9.149251  9.174491  8.622092  8.892953  8.992298        NaN\n",
      "78  9.333095  9.126482  9.044427  8.990107  8.993375  9.129097  9.130040  8.909539  9.263479  8.965475  91.500760\n",
      "79  9.202874  9.194511  8.904250  9.134964  9.358912  9.432651  8.980165  8.515224  9.039520  9.176732  90.850222\n",
      "80  8.631825  9.124362  9.251151  8.775456  8.896478  8.938444  9.369327  8.683219  9.415052  9.130465        NaN\n",
      "81  8.744085  8.685955  8.821079  9.076482  9.044758  9.043830  8.785983  9.152083  8.862162  8.684722  89.650742\n",
      "82  8.875036  8.854573  8.962626  9.033290  8.996715  9.049877  8.694895  9.157160  9.347193  9.295308  89.678365\n",
      "83  9.005218  8.950496  8.912054  9.098490  9.237679  9.315491  8.861618  9.085092  9.039582  9.276018        NaN\n",
      "84  9.103532  8.985113  9.289396  9.057834  9.505386  8.980941  8.990883  8.806605  8.869716  8.874887  90.381935\n",
      "85  8.854851  9.124134  9.039311  9.491060  8.893826  9.055804  9.048668  8.990458  8.903223  9.079161        NaN\n",
      "86  9.037353  9.035540  9.206369  8.872452  8.902112  9.121579  8.951753  8.999279  8.935931  9.098806  91.030283\n",
      "87  8.848923  8.732931  8.702888  8.893801  9.208832  9.037322  9.070411  8.768327  9.084833  9.052135  90.238789\n",
      "88  8.877696  9.076040  9.053410  8.875372  9.136378  8.910713  8.749692  9.300680  9.104567  8.889939        NaN\n",
      "89  8.718668  9.122117  9.177926  8.888905  9.369341  9.038818  9.288753  9.175472  8.885260  8.865675  89.803650\n",
      "90  8.815353  9.111958  9.016457  8.872523  9.116786  9.214726  8.983570  8.955807  8.995129  8.994889        NaN\n",
      "91  8.729663  9.216156  9.213096  9.237803  8.928142  8.794697  9.223459  9.005377  9.428454  9.234546  89.962778\n",
      "92  8.804825  9.166784  8.896542  9.284101  9.118131  9.026594  9.068545  9.041677  9.345509  9.108720  90.727630\n",
      "93  9.210728  9.091836  9.281869  8.885851  9.221741  8.859976  9.091351  8.591653  9.087265  8.925877        NaN\n",
      "94  8.810120  8.985967  9.459780  8.833529  9.164096  9.239009  9.113953  8.950565  9.007601  9.154340  90.732640\n",
      "95  9.526476  8.667808  8.927432  9.094283  9.101455  8.695363  9.089542  8.863603  9.024006  8.430291  89.919283\n",
      "96  9.098664  9.085924  8.910899  8.889555  9.213335  8.888216  9.128545  8.799676  9.122704  9.229753        NaN\n",
      "97  9.036967  9.041538  9.290677  9.126586  9.233859  9.075442  9.265831  8.943780  8.795441  8.652057  88.001799\n",
      "98  8.828328  9.054316  9.315914  9.040585  9.276432  9.313105  9.039304  9.359537  8.948525  8.927512  90.916328\n",
      "99  9.140062  8.744650  8.895428  8.696851  9.129742  8.986850  9.141801  9.128169  8.666283  8.776066  90.346488\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 11\n",
      "    ['F0', 'F1', 'F2', 'F3', 'F4']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 100 x 11\n",
      "Missings: 40 (3.6%)\n",
      "Parametros: min_friends=2, max_friends=5\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 60/100 (60.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 40 → 0 missings\n",
      "             40 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 40 → 0 (40 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 40 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.16s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- RESULTADO IMPUTAÇÃO ---\n",
      "          F0        F1        F2        F3        F4        F5        F6        F7        F8        F9     Target\n",
      "0   1.099343  0.788458  0.985598  0.953083  0.787539  1.082556  1.011642  1.043292  0.949486  1.061460   9.445785\n",
      "1   0.972347  1.164509  1.200707  0.716926  1.094718  1.164412  0.771406  1.009114  0.750443  1.162572   9.102746\n",
      "2   1.129538  0.755831  1.072327  0.915871  0.816115  1.379359  1.071557  0.869680  1.326482  1.125926  10.075805\n",
      "3   1.304606  1.041773  0.870976  0.931457  1.309987  0.950922  1.112157  1.428789  0.713972  0.834201   9.322838\n",
      "4   0.953169  0.608066  1.072279  0.839545  0.843349  0.849253  1.216610  1.126784  0.911991  0.887964   9.601417\n",
      "5   0.953173  0.734363  1.307607  0.967743  0.935588  0.822097  1.210760  0.594971  1.026148  1.149459   9.919448\n",
      "6   1.315843  1.039372  0.992835  1.080810  1.162703  0.836838  0.724466  1.037291  1.288255  1.122074   9.174503\n",
      "7   1.153487  1.147693  1.312929  1.377237  0.753827  0.984580  0.812435  0.867643  0.712828  0.995820   9.678614\n",
      "8   0.906105  1.034274  0.476051  1.034916  1.045492  1.068230  1.103007  1.170487  1.232633  1.023465  10.412931\n",
      "9   1.108512  0.976870  1.164381  1.051510  1.261429  1.055338  1.102757  0.841496  1.002047  1.255533   9.569654\n",
      "10  0.907316  0.939779  1.017409  0.985111  0.678503  1.165437  1.103010  0.977053  0.803698  0.881686   9.806278\n",
      "11  0.906854  0.704296  0.940199  0.616246  1.036927  1.002600  1.770546  1.100997  1.092421  1.109419   9.465985\n",
      "12  1.048392  0.856031  1.018352  0.994697  1.051977  1.290707  1.114178  1.173151  1.039812  0.959561  10.077143\n",
      "13  0.617344  0.907872  0.602486  1.012046  1.156365  0.947069  1.227113  0.759941  0.879957  0.956464   9.493057\n",
      "14  0.655016  1.211424  0.956066  1.492648  0.752610  1.544034  1.190800  0.933100  1.013960  1.219755   9.528962\n",
      "15  0.887542  1.068724  1.071423  0.961528  0.735909  1.125133  1.130278  0.905011  0.922937  1.165083   9.709363\n",
      "16  0.797434  0.647392  1.295579  1.060309  1.104388  0.828568  0.936946  0.869334  1.022703  1.162702   9.708711\n",
      "17  1.062849  1.064817  0.896346  0.993058  1.059397  0.785822  1.151794  1.353091  1.132426  1.261096   8.592536\n",
      "18  0.818395  0.922984  0.838301  0.766264  1.050099  1.096494  0.845435  1.080996  1.317203  1.004201   9.794718\n",
      "19  0.717539  0.864616  0.899649  1.228565  1.069290  0.955307  0.952636  0.747823  0.752437  1.136391   9.786553\n",
      "20  1.293130  1.122335  1.183080  1.150387  0.863995  1.142800  0.902927  1.183572  1.426607  0.937947  10.310908\n",
      "21  0.954845  1.206200  1.065750  1.158206  1.046451  1.094648  1.016375  1.424431  0.609582  1.064833  11.475356\n",
      "22  1.013506  1.186256  0.894048  0.818123  1.058614  0.985434  1.462932  1.206493  0.969643  0.973971   9.493413\n",
      "23  0.715050  0.832156  1.102653  1.280559  0.857130  0.830641  0.626547  0.696126  1.117663  1.019399   9.840061\n",
      "24  0.891123  0.938158  1.019416  0.719630  1.373155  0.697031  1.137252  0.903153  1.056198  1.119031   9.980984\n",
      "25  1.022185  1.066253  1.193729  1.117371  1.094767  0.910697  0.677457  1.253382  0.875460  0.836356   8.997471\n",
      "26  0.769801  1.195109  0.859589  1.438091  0.761739  1.171280  0.905614  0.858466  0.958376  1.418477   9.740846\n",
      "27  1.075140  0.904165  0.934468  0.801893  1.131311  1.042819  1.217790  1.088764  0.901400  0.798797   9.711341\n",
      "28  0.879872  0.962868  0.921578  0.886740  0.805064  0.750852  1.012856  1.154927  0.882127  0.757162   9.425755\n",
      "29  0.941661  0.778733  0.707297  1.019930  1.157417  1.034636  0.784451  0.814614  1.169920  1.231622   9.172769\n",
      "30  0.879659  0.760759  1.059224  0.899305  1.231719  1.077063  0.856939  0.988095  1.071403  1.158333   9.514471\n",
      "31  1.370456  1.162505  1.052211  0.689867  0.835864  0.823229  1.135920  0.351747  0.861418  1.124824   9.677569\n",
      "32  0.997301  1.271248  1.001023  1.013713  1.192675  1.030745  0.853927  0.795122  1.179920  1.125669   9.891240\n",
      "33  5.080342  4.657373  4.648252  4.860055  5.107782  5.051945  5.415080  5.207508  4.974843  4.885268  49.048432\n",
      "34  5.138029  5.270774  4.763348  5.042796  4.792551  4.819137  5.174225  4.897997  5.011145  4.890628  50.593101\n",
      "35  4.919756  4.977092  4.592154  4.977534  4.961932  5.127718  4.934795  4.946025  5.218838  4.993449  49.708191\n",
      "36  5.044818  5.247563  4.946119  4.955806  4.824876  4.667696  5.240243  4.804247  4.661507  4.891315  50.326133\n",
      "37  5.002518  4.681114  5.143508  5.122833  4.723440  4.986784  4.918385  4.911141  5.305910  4.857431  48.748886\n",
      "38  5.019535  4.880125  5.300471  5.151502  5.185236  4.757797  4.592375  5.075460  4.968398  5.021286  50.924027\n",
      "39  4.845398  5.001049  5.014819  4.893900  5.381883  4.869633  4.798383  5.151398  4.914624  4.949005  49.787791\n",
      "40  5.004902  5.009396  5.325723  4.884836  4.720286  5.009480  4.625842  4.815567  4.797579  5.300799  50.232047\n",
      "41  5.099600  4.909987  4.723980  4.944990  5.112594  4.827917  4.929697  5.173921  4.669029  4.469806  51.049009\n",
      "42  5.290229  5.124570  4.659324  4.539616  4.869871  4.923089  5.003684  5.271128  5.164634  5.218301  49.258654\n",
      "43  5.191854  4.786476  4.988890  4.696962  4.902575  5.201259  5.335287  5.082687  5.014664  5.249217  48.591539\n",
      "44  5.430636  4.971524  5.076813  5.273375  4.881521  4.884622  5.065385  5.375359  4.742008  4.585322  49.924827\n",
      "45  4.846530  5.024059  4.993461  5.328994  4.827202  5.167138  4.956180  4.845242  4.740984  4.931462  49.679693\n",
      "46  5.174464  5.102888  4.586512  4.950193  5.009704  4.774059  5.165881  4.751069  4.932843  4.925712  48.719571\n",
      "47  5.036668  5.142323  4.982176  5.115311  4.833810  5.105961  4.557773  4.644256  5.333804  4.718498  49.838679\n",
      "48  5.437961  4.775072  4.739106  5.062250  5.054091  5.288314  5.047123  5.299209  4.948082  4.844437  47.918071\n",
      "49  4.838340  4.693177  5.133935  5.615776  4.989952  4.505671  5.154173  5.130873  4.699371  4.777885  51.696456\n",
      "50  4.832056  5.255535  5.073320  5.223915  4.952210  4.840621  4.704283  4.988883  4.950851  5.350454  50.211017\n",
      "51  4.880121  5.066463  4.812024  4.974416  4.818487  5.115414  5.228751  5.055994  4.945455  5.187136  49.903287\n",
      "52  4.575221  4.850303  4.897227  4.808892  4.884646  4.959391  5.067699  4.774902  4.460623  5.254311  49.455081\n",
      "53  4.894849  5.310230  4.788157  4.678711  5.151078  5.074229  4.916942  5.489150  4.989141  5.144334  49.361529\n",
      "54  4.848173  5.023135  4.987464  5.040693  5.100183  4.879203  5.126556  5.025844  4.953813  4.774190  49.962365\n",
      "55  5.030079  5.235859  5.191028  4.848730  4.804489  5.017318  5.454139  5.021879  5.139241  4.895096  50.162221\n",
      "56  5.068351  5.013504  4.802855  4.715549  5.019866  4.968865  5.036373  5.145153  5.369791  5.097875  50.114228\n",
      "57  5.375234  5.412150  5.100809  4.870685  5.150277  5.233556  5.049644  5.096202  5.225313  4.755574  50.150302\n",
      "58  5.190085  5.351068  4.893948  4.783690  4.666119  5.050884  4.908128  5.044777  4.946222  5.142600  49.636388\n",
      "59  4.884619  4.950207  4.841425  5.337428  5.108672  5.067521  4.830031  4.841905  4.778695  4.951935  49.943054\n",
      "60  4.820317  5.194314  4.978594  5.176328  4.867475  4.917625  5.166067  5.094294  5.514672  4.925036  50.307802\n",
      "61  5.098384  5.129075  4.792952  4.998405  5.114120  4.902479  4.828783  5.376405  5.011844  5.142192  48.289832\n",
      "62  4.735953  5.273726  4.889270  5.295989  4.847348  4.913488  5.014313  5.269084  5.002786  5.088853  48.651815\n",
      "63  5.366292  4.807015  4.760424  5.015474  4.639024  5.078890  4.904469  5.318637  4.995175  4.927807  50.743264\n",
      "64  5.235888  5.137210  5.392945  4.827743  4.674492  4.915803  5.095796  4.897757  5.039617  5.231866  50.170865\n",
      "65  4.906165  5.211685  5.007053  5.304625  5.009617  5.057955  5.066732  4.802079  4.971128  4.783787  49.840180\n",
      "66  9.003687  8.884872  8.783789  8.915963  9.309501  8.966576  8.888960  8.982053  8.885764  9.079845  90.496038\n",
      "67  9.069516  9.024402  9.210631  8.943643  9.359176  9.029343  9.376231  9.288023  9.114517  9.129439  91.160827\n",
      "68  8.892048  9.512017  8.992089  8.731110  8.877442  9.241302  8.710397  8.864722  9.279871  8.903363  89.532299\n",
      "69  8.844339  8.980788  9.136300  8.816270  8.922460  8.836613  8.560239  9.360188  9.184927  9.314797  90.472582\n",
      "70  9.039169  9.229855  9.005664  8.799172  9.057173  9.073735  9.088003  8.991968  9.011926  8.754847  90.035621\n",
      "71  8.804325  8.859365  9.005951  8.846440  9.066891  8.921332  8.899589  8.713845  8.870613  8.707125  90.477041\n",
      "72  9.081651  8.993002  9.187657  8.993063  9.131709  9.005749  8.795753  9.025621  9.139645  9.044890  90.680975\n",
      "73  8.659483  9.354160  8.896791  9.046843  9.402041  9.255690  9.141671  8.863790  9.078697  9.209420  90.530844\n",
      "74  9.205831  8.874607  9.019224  9.310100  8.964611  9.038220  9.048760  9.168129  9.179039  9.336786  90.996267\n",
      "75  9.094519  9.362490  8.907545  8.800329  8.840341  9.009287  8.887184  8.869475  9.127034  8.908223  89.506243\n",
      "76  9.051206  9.141550  8.913101  9.196864  8.724136  8.728029  8.743939  8.910763  9.209911  9.215736  90.213995\n",
      "77  9.196538  8.887507  8.938166  8.957202  8.853814  9.149251  9.174491  8.622092  8.892953  8.992298  90.839312\n",
      "78  9.333095  9.126482  9.044427  8.990107  8.993375  9.129097  9.130040  8.909539  9.263479  8.965475  91.500760\n",
      "79  9.202874  9.194511  8.904250  9.134964  9.358912  9.432651  8.980165  8.515224  9.039520  9.176732  90.850222\n",
      "80  8.631825  9.124362  9.251151  8.775456  8.896478  8.938444  9.369327  8.683219  9.415052  9.130465  90.563750\n",
      "81  8.744085  8.685955  8.821079  9.076482  9.044758  9.043830  8.785983  9.152083  8.862162  8.684722  89.650742\n",
      "82  8.875036  8.854573  8.962626  9.033290  8.996715  9.049877  8.694895  9.157160  9.347193  9.295308  89.678365\n",
      "83  9.005218  8.950496  8.912054  9.098490  9.237679  9.315491  8.861618  9.085092  9.039582  9.276018  90.588659\n",
      "84  9.103532  8.985113  9.289396  9.057834  9.505386  8.980941  8.990883  8.806605  8.869716  8.874887  90.381935\n",
      "85  8.854851  9.124134  9.039311  9.491060  8.893826  9.055804  9.048668  8.990458  8.903223  9.079161  90.695883\n",
      "86  9.037353  9.035540  9.206369  8.872452  8.902112  9.121579  8.951753  8.999279  8.935931  9.098806  91.030283\n",
      "87  8.848923  8.732931  8.702888  8.893801  9.208832  9.037322  9.070411  8.768327  9.084833  9.052135  90.238789\n",
      "88  8.877696  9.076040  9.053410  8.875372  9.136378  8.910713  8.749692  9.300680  9.104567  8.889939  90.333048\n",
      "89  8.718668  9.122117  9.177926  8.888905  9.369341  9.038818  9.288753  9.175472  8.885260  8.865675  89.803650\n",
      "90  8.815353  9.111958  9.016457  8.872523  9.116786  9.214726  8.983570  8.955807  8.995129  8.994889  90.345226\n",
      "91  8.729663  9.216156  9.213096  9.237803  8.928142  8.794697  9.223459  9.005377  9.428454  9.234546  89.962778\n",
      "92  8.804825  9.166784  8.896542  9.284101  9.118131  9.026594  9.068545  9.041677  9.345509  9.108720  90.727630\n",
      "93  9.210728  9.091836  9.281869  8.885851  9.221741  8.859976  9.091351  8.591653  9.087265  8.925877  90.290335\n",
      "94  8.810120  8.985967  9.459780  8.833529  9.164096  9.239009  9.113953  8.950565  9.007601  9.154340  90.732640\n",
      "95  9.526476  8.667808  8.927432  9.094283  9.101455  8.695363  9.089542  8.863603  9.024006  8.430291  89.919283\n",
      "96  9.098664  9.085924  8.910899  8.889555  9.213335  8.888216  9.128545  8.799676  9.122704  9.229753  90.876820\n",
      "97  9.036967  9.041538  9.290677  9.126586  9.233859  9.075442  9.265831  8.943780  8.795441  8.652057  88.001799\n",
      "98  8.828328  9.054316  9.315914  9.040585  9.276432  9.313105  9.039304  9.359537  8.948525  8.927512  90.916328\n",
      "99  9.140062  8.744650  8.895428  8.696851  9.129742  8.986850  9.141801  9.128169  8.666283  8.776066  90.346488\n",
      "\n",
      "--- VERIFICAÇÃO DE ERROS ---\n",
      "  ✗ Linha 83, Col 'Target': imputado=90.59, real=92.08, erro=1.49\n",
      "  ✗ Linha 53, Col 'Target': imputado=49.36, real=50.40, erro=1.04\n",
      "  ✓ Linha 70, Col 'Target': imputado=90.04, real=89.95, erro=0.08\n",
      "  ✓ Linha 45, Col 'Target': imputado=49.68, real=50.61, erro=0.93\n",
      "  ✗ Linha 44, Col 'Target': imputado=49.92, real=48.44, erro=1.48\n",
      "  ✓ Linha 39, Col 'Target': imputado=49.79, real=49.82, erro=0.03\n",
      "  ✗ Linha 22, Col 'Target': imputado=9.49, real=10.86, erro=1.36\n",
      "  ✓ Linha 80, Col 'Target': imputado=90.56, real=89.65, erro=0.91\n",
      "  ✓ Linha 10, Col 'Target': imputado=9.81, real=9.18, erro=0.63\n",
      "  ✓ Linha 0, Col 'Target': imputado=9.45, real=9.99, erro=0.54\n",
      "  ✓ Linha 18, Col 'Target': imputado=9.79, real=9.28, erro=0.51\n",
      "  ✗ Linha 30, Col 'Target': imputado=9.51, real=10.52, erro=1.00\n",
      "  ✗ Linha 73, Col 'Target': imputado=90.53, real=88.72, erro=1.81\n",
      "  ✗ Linha 33, Col 'Target': imputado=49.05, real=50.62, erro=1.57\n",
      "  ✓ Linha 90, Col 'Target': imputado=90.35, real=89.93, erro=0.42\n",
      "  ✗ Linha 4, Col 'Target': imputado=9.60, real=10.98, erro=1.37\n",
      "  ✗ Linha 76, Col 'Target': imputado=90.21, real=88.44, erro=1.77\n",
      "  ✗ Linha 77, Col 'Target': imputado=90.84, real=89.57, erro=1.27\n",
      "  ✓ Linha 12, Col 'Target': imputado=10.08, real=10.24, erro=0.17\n",
      "  ✗ Linha 31, Col 'Target': imputado=9.68, real=11.53, erro=1.86\n",
      "  ✓ Linha 55, Col 'Target': imputado=50.16, real=51.10, erro=0.94\n",
      "  ✓ Linha 88, Col 'Target': imputado=90.33, real=89.74, erro=0.59\n",
      "  ✓ Linha 26, Col 'Target': imputado=9.74, real=9.98, erro=0.24\n",
      "  ✓ Linha 42, Col 'Target': imputado=49.26, real=49.30, erro=0.04\n",
      "  ✓ Linha 69, Col 'Target': imputado=90.47, real=90.35, erro=0.13\n",
      "  ✓ Linha 15, Col 'Target': imputado=9.71, real=10.23, erro=0.52\n",
      "  ✓ Linha 40, Col 'Target': imputado=50.23, real=49.48, erro=0.75\n",
      "  ✓ Linha 96, Col 'Target': imputado=90.88, real=90.08, erro=0.80\n",
      "  ✓ Linha 9, Col 'Target': imputado=9.57, real=9.44, erro=0.13\n",
      "  ✓ Linha 72, Col 'Target': imputado=90.68, real=90.08, erro=0.60\n",
      "  ✓ Linha 11, Col 'Target': imputado=9.47, real=10.24, erro=0.78\n",
      "  ✗ Linha 47, Col 'Target': imputado=49.84, real=51.75, erro=1.92\n",
      "  ✓ Linha 85, Col 'Target': imputado=90.70, real=90.43, erro=0.27\n",
      "  ✓ Linha 28, Col 'Target': imputado=9.43, real=10.32, erro=0.90\n",
      "  ✓ Linha 93, Col 'Target': imputado=90.29, real=90.05, erro=0.24\n",
      "  ✓ Linha 5, Col 'Target': imputado=9.92, real=9.85, erro=0.07\n",
      "  ✗ Linha 66, Col 'Target': imputado=90.50, real=88.71, erro=1.79\n",
      "  ✓ Linha 65, Col 'Target': imputado=49.84, real=49.82, erro=0.02\n",
      "  ✓ Linha 35, Col 'Target': imputado=49.71, real=49.69, erro=0.02\n",
      "  ✗ Linha 16, Col 'Target': imputado=9.71, real=8.55, erro=1.16\n",
      "\n",
      "MAE total: 0.8036\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO DETALHADO para linha 83, coluna 'Target'\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO: Linha 83, Coluna 'Target'\n",
      "======================================================================\n",
      "\n",
      "Dados da linha 83:\n",
      "F0        9.005218\n",
      "F1        8.950496\n",
      "F2        8.912054\n",
      "F3        9.098490\n",
      "F4        9.237679\n",
      "F5        9.315491\n",
      "F6        8.861618\n",
      "F7        9.085092\n",
      "F8        9.039582\n",
      "F9        9.276018\n",
      "Target         NaN\n",
      "\n",
      "Valor REAL (ground truth): 92.07674798356084\n",
      "\n",
      "Features disponíveis (10): ['F0', 'F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9']\n",
      "Features em falta (0): []\n",
      "\n",
      "--- PESOS MI para prever 'Target' ---\n",
      "  ✓ F9: MI=0.7315, peso=0.1096\n",
      "  ✓ F1: MI=0.7067, peso=0.1059\n",
      "  ✓ F0: MI=0.7001, peso=0.1049\n",
      "  ✓ F7: MI=0.6761, peso=0.1013\n",
      "  ✓ F6: MI=0.6719, peso=0.1007\n",
      "  ✓ F5: MI=0.6567, peso=0.0984\n",
      "  ✓ F8: MI=0.6558, peso=0.0983\n",
      "  ✓ F2: MI=0.6301, peso=0.0944\n",
      "  ✓ F4: MI=0.6261, peso=0.0938\n",
      "  ✓ F3: MI=0.6193, peso=0.0928\n",
      "\n",
      "--- DONORS POTENCIAIS (60 linhas com target preenchido) ---\n",
      "\n",
      "--- RANGE FACTORS ---\n",
      "  F0: 0.3682\n",
      "  F1: 0.3716\n",
      "  F2: 0.3672\n",
      "  F3: 0.3690\n",
      "  F4: 0.3762\n",
      "  F5: 0.3765\n",
      "  F6: 0.3739\n",
      "  F7: 0.3632\n",
      "  F8: 0.3749\n",
      "  F9: 0.3799\n",
      "\n",
      "--- TOP 10 DONORS (por distância) ---\n",
      "  1. Linha 82: dist=0.0160, overlap=10/10, target=89.68\n",
      "  2. Linha 74: dist=0.0168, overlap=10/10, target=91.00\n",
      "  3. Linha 86: dist=0.0174, overlap=10/10, target=91.03\n",
      "  4. Linha 92: dist=0.0190, overlap=10/10, target=90.73\n",
      "  5. Linha 87: dist=0.0202, overlap=10/10, target=90.24\n",
      "  6. Linha 98: dist=0.0207, overlap=10/10, target=90.92\n",
      "  7. Linha 94: dist=0.0211, overlap=10/10, target=90.73\n",
      "  8. Linha 79: dist=0.0215, overlap=10/10, target=90.85\n",
      "  9. Linha 78: dist=0.0223, overlap=10/10, target=91.50\n",
      "  10. Linha 67: dist=0.0225, overlap=10/10, target=91.16\n",
      "\n",
      "--- ADAPTIVE K ---\n",
      "  density_trust: 0.9824 (mean_dist=0.0179)\n",
      "  consistency_trust: 0.9944\n",
      "  k escolhido: 4 (range [2, 5])\n",
      "\n",
      "--- VIZINHOS FINAIS (k=4) ---\n",
      "  1. Linha 82: dist=0.0160, target=89.68\n",
      "  2. Linha 74: dist=0.0168, target=91.00\n",
      "  3. Linha 86: dist=0.0174, target=91.03\n",
      "  4. Linha 92: dist=0.0190, target=90.73\n",
      "\n",
      "  Pesos IDW: [0.2687925  0.25668196 0.24727474 0.2272508 ]\n",
      "\n",
      "--- RESULTADO ---\n",
      "  Valor imputado: 90.5894\n",
      "  Valor real: 92.0767\n",
      "  Erro absoluto: 1.4874\n",
      "  Status: ✗ MAU\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "MAE para 40% missing: 0.8036\n",
      "Comparação: MAE 20%=0.8036 vs MAE 40%=0.8036\n",
      "\n",
      "✓ Fase 1 resolveu tudo\n"
     ]
    }
   ],
   "source": [
    "# Mesmo dataset, mas com 40% missings\n",
    "np.random.seed(42)\n",
    "missing_rows_40 = np.random.choice(100, 40, replace=False)\n",
    "missing_indices_1_4 = [(row, 'Target') for row in missing_rows_40]\n",
    "\n",
    "result, imputer, mae = run_test_with_diagnostics(\n",
    "    data_1_3,  # Reutilizar dataset\n",
    "    missing_indices=missing_indices_1_4,\n",
    "    target_col='Target',\n",
    "    test_name=\"1.4 - Dataset maior (100x11, 40% missing)\"\n",
    ")\n",
    "\n",
    "print(f\"\\nMAE para 40% missing: {mae:.4f}\")\n",
    "print(f\"Comparação: MAE 20%={mae:.4f} vs MAE 40%={mae:.4f}\")\n",
    "\n",
    "# Verificar se a Fase 2 foi activada\n",
    "if imputer.execution_stats.get('phase2_activated', False):\n",
    "    print(f\"\\n⚠️  FASE 2 ACTIVADA com {imputer.execution_stats['phase2_cycles']} ciclos\")\n",
    "else:\n",
    "    print(f\"\\n✓ Fase 1 resolveu tudo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 2: Correlação Forte vs Fraca\n",
    "\n",
    "**Objectivo**: Verificar se os pesos MI reflectem correctamente as correlações reais.\n",
    "\n",
    "Criamos um dataset onde:\n",
    "- Coluna A tem correlação forte (0.95) com Target\n",
    "- Coluna B tem correlação fraca (~0) com Target  \n",
    "- Coluna C tem correlação média (0.5) com Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTE 2: Correlação Forte vs Fraca\n",
      "======================================================================\n",
      "\n",
      "Correlações reais com Target:\n",
      "  A: 0.9884 (esperado ~0.95)\n",
      "  B: 0.0778 (esperado ~0.00)\n",
      "  C: 0.6696 (esperado ~0.50)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "n = 100\n",
    "\n",
    "# Target base\n",
    "target = np.linspace(0, 100, n)\n",
    "\n",
    "# A: correlação forte com Target (r ~ 0.95)\n",
    "A = target + np.random.normal(0, 5, n)\n",
    "\n",
    "# B: correlação fraca com Target (r ~ 0)\n",
    "B = np.random.uniform(0, 100, n)\n",
    "\n",
    "# C: correlação média com Target (r ~ 0.5)\n",
    "C = 0.5 * target + 0.5 * np.random.uniform(0, 100, n)\n",
    "\n",
    "data_2 = pd.DataFrame({\n",
    "    'A': A,\n",
    "    'B': B,\n",
    "    'C': C,\n",
    "    'Target': target\n",
    "})\n",
    "\n",
    "# Verificar correlações reais\n",
    "from scipy.stats import pearsonr\n",
    "corr_A = pearsonr(data_2['A'], data_2['Target'])[0]\n",
    "corr_B = pearsonr(data_2['B'], data_2['Target'])[0]\n",
    "corr_C = pearsonr(data_2['C'], data_2['Target'])[0]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTE 2: Correlação Forte vs Fraca\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nCorrelações reais com Target:\")\n",
    "print(f\"  A: {corr_A:.4f} (esperado ~0.95)\")\n",
    "print(f\"  B: {corr_B:.4f} (esperado ~0.00)\")\n",
    "print(f\"  C: {corr_C:.4f} (esperado ~0.50)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "# TESTE: 2 - Correlação Forte vs Fraca\n",
      "######################################################################\n",
      "\n",
      "Dataset: 100 linhas x 4 colunas\n",
      "Missings introduzidos: 20\n",
      "PDS: True\n",
      "\n",
      "--- DADOS COMPLETOS (ground truth) ---\n",
      "            A          B          C      Target\n",
      "0    2.483571  41.741100  39.740565    0.000000\n",
      "1    0.318780  22.210781  25.636905    1.010101\n",
      "2    5.258645  11.986537  29.855295    2.020202\n",
      "3   10.645452  33.761517  26.141036    3.030303\n",
      "4    2.869637  94.290970  11.782351    4.040404\n",
      "5    3.879820  32.320293  38.647858    5.050505\n",
      "6   13.956670  51.879062  17.068921    6.060606\n",
      "7   10.907881  70.301896   4.751152    7.070707\n",
      "8    5.733436  36.362960  36.314019    8.080808\n",
      "9   11.803709  97.178208  13.400989    9.090909\n",
      "10   7.783922  96.244729  52.073434   10.101010\n",
      "11   8.782462  25.178230  53.251984   11.111111\n",
      "12  13.331023  49.724851  51.803826   12.121212\n",
      "13   3.564912  30.087831  25.073592   13.131313\n",
      "14   5.516825  28.484049   7.843538   14.141414\n",
      "15  12.340078   3.688695  53.991686   15.151515\n",
      "16  11.097461  60.956433  29.490015   16.161616\n",
      "17  18.742954  50.267902  56.918600   17.171717\n",
      "18  13.641698   5.147875  57.271908   18.181818\n",
      "19  12.130401  27.864646  52.246432   19.191919\n",
      "20  27.530264  90.826589  24.823455   20.202020\n",
      "21  20.083240  23.956189  29.860947   21.212121\n",
      "22  22.559863  14.489487  53.667945   22.222222\n",
      "23  16.108582  48.945276  27.462262   23.232323\n",
      "24  21.520511  98.565045  20.595849   24.242424\n",
      "25  25.807138  24.205527  40.466326   25.252525\n",
      "26  20.507658  67.213555  59.939052   26.262626\n",
      "27  29.151217  76.161962  48.437853   27.272727\n",
      "28  25.279635  23.763754  42.644473   28.282828\n",
      "29  27.834461  72.821635  19.505289   29.292929\n",
      "30  27.294497  36.778313  45.901876   30.303030\n",
      "31  40.574522  63.230583  65.159258   31.313131\n",
      "32  32.255746  63.352971  23.165817   32.323232\n",
      "33  28.044779  53.577468  42.583149   33.333333\n",
      "34  38.456159   9.028977  61.040371   34.343434\n",
      "35  29.249317  83.530250  54.715199   35.353535\n",
      "36  37.407954  32.078006  53.032605   36.363636\n",
      "37  27.575387  18.651851  53.811073   37.373737\n",
      "38  31.742908   4.077514  37.166477   38.383838\n",
      "39  40.378246  59.089294  34.376562   39.393939\n",
      "40  44.096373  67.756436  60.670078   40.404040\n",
      "41  42.270983   1.658783  61.212740   41.414141\n",
      "42  41.846001  51.209306  64.565737   42.424242\n",
      "43  41.928825  22.649578  67.379199   43.434343\n",
      "44  37.051834  64.517279  47.789342   44.444444\n",
      "45  41.855324  17.436643  47.803087   45.454545\n",
      "46  44.161453  69.093774  63.147082   46.464646\n",
      "47  52.760359  38.673535  56.235570   47.474747\n",
      "48  50.202940  93.672999  59.340768   48.484848\n",
      "49  40.679749  13.752094  64.537108   49.494949\n",
      "50  52.125470  34.106635  69.752792   50.505051\n",
      "51  49.589740  11.347352  42.657334   51.515152\n",
      "52  49.140643  92.469362  45.041774   52.525253\n",
      "53  56.593735  87.733935  31.466774   53.535354\n",
      "54  59.700452  25.794163  56.186734   54.545455\n",
      "55  60.211956  65.998405  29.574891   55.555556\n",
      "56  52.369569  81.722220  51.562729   56.565657\n",
      "57  56.029696  55.520081  55.920111   57.575758\n",
      "58  60.242176  52.965058  43.619992   58.585859\n",
      "59  64.473685  24.185229  59.339643   59.595960\n",
      "60  58.210189   9.310277  31.828043   60.606061\n",
      "61  60.687867  89.721576  32.675490   61.616162\n",
      "62  57.094588  90.041806  72.443159   62.626263\n",
      "63  57.655331  63.310146  49.827714   63.636364\n",
      "64  68.709094  33.902979  38.676258   64.646465\n",
      "65  72.437766  34.920957  58.940446   65.656566\n",
      "66  66.306616  72.595568  71.833011   66.666667\n",
      "67  72.694432  89.711026  44.629435   67.676768\n",
      "68  70.495049  88.708642  65.487958   68.686869\n",
      "69  66.471371  77.987555  39.115858   69.696970\n",
      "70  72.514049  64.203165  37.937621   70.707071\n",
      "71  79.407355   8.413996  62.426317   71.717172\n",
      "72  72.548143  16.162871  63.395392   72.727273\n",
      "73  81.560592  89.855419  68.740182   73.737374\n",
      "74  61.648749  60.642906  73.678304   74.747475\n",
      "75  79.867088   0.919705  86.671392   75.757576\n",
      "76  77.202912  10.147154  64.198856   76.767677\n",
      "77  76.282741  66.350177  55.036713   77.777778\n",
      "78  79.246683   0.506158  79.153249   78.787879\n",
      "79  69.860135  16.080805  53.440602   79.797980\n",
      "80  79.709721  54.873379  62.352611   80.808081\n",
      "81  83.603745  69.189520  44.831910   81.818182\n",
      "82  90.217753  65.196126  42.681679   82.828283\n",
      "83  81.247033  22.426931  90.051613   83.838384\n",
      "84  80.806017  71.217922  84.223248   84.848485\n",
      "85  83.349801  23.724909  77.728003   85.858586\n",
      "86  91.445697  32.539970  63.881991   86.868687\n",
      "87  89.522543  74.649141  52.604110   87.878788\n",
      "88  86.240088  64.963290  52.266297   88.888889\n",
      "89  92.465327  84.922341  57.461640   89.898990\n",
      "90  91.394479  65.761289  72.915879   90.909091\n",
      "91  96.762417  56.830860  81.689392   91.919192\n",
      "92  89.419027   9.367477  79.474515   92.929293\n",
      "93  92.301083  36.771580  60.966392   93.939394\n",
      "94  92.988954  26.520237  95.218012   94.949495\n",
      "95  88.642021  24.398964  84.874644   95.959596\n",
      "96  98.450298  97.301055  76.202551   96.969697\n",
      "97  99.285074  39.309772  79.575936   97.979798\n",
      "98  99.015466  89.204656  70.474953   98.989899\n",
      "99  98.827064  63.113863  62.386549  100.000000\n",
      "\n",
      "--- DADOS COM MISSINGS ---\n",
      "            A          B          C      Target\n",
      "0    2.483571  41.741100  39.740565         NaN\n",
      "1    0.318780  22.210781  25.636905    1.010101\n",
      "2    5.258645  11.986537  29.855295    2.020202\n",
      "3   10.645452  33.761517  26.141036    3.030303\n",
      "4    2.869637  94.290970  11.782351         NaN\n",
      "5    3.879820  32.320293  38.647858    5.050505\n",
      "6   13.956670  51.879062  17.068921    6.060606\n",
      "7   10.907881  70.301896   4.751152    7.070707\n",
      "8    5.733436  36.362960  36.314019    8.080808\n",
      "9   11.803709  97.178208  13.400989    9.090909\n",
      "10   7.783922  96.244729  52.073434         NaN\n",
      "11   8.782462  25.178230  53.251984   11.111111\n",
      "12  13.331023  49.724851  51.803826         NaN\n",
      "13   3.564912  30.087831  25.073592   13.131313\n",
      "14   5.516825  28.484049   7.843538   14.141414\n",
      "15  12.340078   3.688695  53.991686   15.151515\n",
      "16  11.097461  60.956433  29.490015   16.161616\n",
      "17  18.742954  50.267902  56.918600   17.171717\n",
      "18  13.641698   5.147875  57.271908         NaN\n",
      "19  12.130401  27.864646  52.246432   19.191919\n",
      "20  27.530264  90.826589  24.823455   20.202020\n",
      "21  20.083240  23.956189  29.860947   21.212121\n",
      "22  22.559863  14.489487  53.667945         NaN\n",
      "23  16.108582  48.945276  27.462262   23.232323\n",
      "24  21.520511  98.565045  20.595849   24.242424\n",
      "25  25.807138  24.205527  40.466326   25.252525\n",
      "26  20.507658  67.213555  59.939052   26.262626\n",
      "27  29.151217  76.161962  48.437853   27.272727\n",
      "28  25.279635  23.763754  42.644473   28.282828\n",
      "29  27.834461  72.821635  19.505289   29.292929\n",
      "30  27.294497  36.778313  45.901876         NaN\n",
      "31  40.574522  63.230583  65.159258         NaN\n",
      "32  32.255746  63.352971  23.165817   32.323232\n",
      "33  28.044779  53.577468  42.583149         NaN\n",
      "34  38.456159   9.028977  61.040371   34.343434\n",
      "35  29.249317  83.530250  54.715199   35.353535\n",
      "36  37.407954  32.078006  53.032605   36.363636\n",
      "37  27.575387  18.651851  53.811073   37.373737\n",
      "38  31.742908   4.077514  37.166477   38.383838\n",
      "39  40.378246  59.089294  34.376562         NaN\n",
      "40  44.096373  67.756436  60.670078   40.404040\n",
      "41  42.270983   1.658783  61.212740   41.414141\n",
      "42  41.846001  51.209306  64.565737   42.424242\n",
      "43  41.928825  22.649578  67.379199   43.434343\n",
      "44  37.051834  64.517279  47.789342         NaN\n",
      "45  41.855324  17.436643  47.803087         NaN\n",
      "46  44.161453  69.093774  63.147082   46.464646\n",
      "47  52.760359  38.673535  56.235570   47.474747\n",
      "48  50.202940  93.672999  59.340768   48.484848\n",
      "49  40.679749  13.752094  64.537108   49.494949\n",
      "50  52.125470  34.106635  69.752792   50.505051\n",
      "51  49.589740  11.347352  42.657334   51.515152\n",
      "52  49.140643  92.469362  45.041774   52.525253\n",
      "53  56.593735  87.733935  31.466774         NaN\n",
      "54  59.700452  25.794163  56.186734   54.545455\n",
      "55  60.211956  65.998405  29.574891   55.555556\n",
      "56  52.369569  81.722220  51.562729   56.565657\n",
      "57  56.029696  55.520081  55.920111   57.575758\n",
      "58  60.242176  52.965058  43.619992   58.585859\n",
      "59  64.473685  24.185229  59.339643   59.595960\n",
      "60  58.210189   9.310277  31.828043   60.606061\n",
      "61  60.687867  89.721576  32.675490   61.616162\n",
      "62  57.094588  90.041806  72.443159   62.626263\n",
      "63  57.655331  63.310146  49.827714   63.636364\n",
      "64  68.709094  33.902979  38.676258   64.646465\n",
      "65  72.437766  34.920957  58.940446   65.656566\n",
      "66  66.306616  72.595568  71.833011   66.666667\n",
      "67  72.694432  89.711026  44.629435   67.676768\n",
      "68  70.495049  88.708642  65.487958   68.686869\n",
      "69  66.471371  77.987555  39.115858   69.696970\n",
      "70  72.514049  64.203165  37.937621         NaN\n",
      "71  79.407355   8.413996  62.426317   71.717172\n",
      "72  72.548143  16.162871  63.395392   72.727273\n",
      "73  81.560592  89.855419  68.740182         NaN\n",
      "74  61.648749  60.642906  73.678304   74.747475\n",
      "75  79.867088   0.919705  86.671392   75.757576\n",
      "76  77.202912  10.147154  64.198856         NaN\n",
      "77  76.282741  66.350177  55.036713         NaN\n",
      "78  79.246683   0.506158  79.153249   78.787879\n",
      "79  69.860135  16.080805  53.440602   79.797980\n",
      "80  79.709721  54.873379  62.352611         NaN\n",
      "81  83.603745  69.189520  44.831910   81.818182\n",
      "82  90.217753  65.196126  42.681679   82.828283\n",
      "83  81.247033  22.426931  90.051613         NaN\n",
      "84  80.806017  71.217922  84.223248   84.848485\n",
      "85  83.349801  23.724909  77.728003   85.858586\n",
      "86  91.445697  32.539970  63.881991   86.868687\n",
      "87  89.522543  74.649141  52.604110   87.878788\n",
      "88  86.240088  64.963290  52.266297   88.888889\n",
      "89  92.465327  84.922341  57.461640   89.898990\n",
      "90  91.394479  65.761289  72.915879         NaN\n",
      "91  96.762417  56.830860  81.689392   91.919192\n",
      "92  89.419027   9.367477  79.474515   92.929293\n",
      "93  92.301083  36.771580  60.966392   93.939394\n",
      "94  92.988954  26.520237  95.218012   94.949495\n",
      "95  88.642021  24.398964  84.874644   95.959596\n",
      "96  98.450298  97.301055  76.202551   96.969697\n",
      "97  99.285074  39.309772  79.575936   97.979798\n",
      "98  99.015466  89.204656  70.474953   98.989899\n",
      "99  98.827064  63.113863  62.386549  100.000000\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 4\n",
      "    ['A', 'B', 'C', 'Target']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 100 x 4\n",
      "Missings: 20 (5.0%)\n",
      "Parametros: min_friends=2, max_friends=5\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 80/100 (80.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 20 → 0 missings\n",
      "             20 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 20 → 0 (20 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 20 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.03s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- RESULTADO IMPUTAÇÃO ---\n",
      "            A          B          C      Target\n",
      "0    2.483571  41.741100  39.740565    4.997443\n",
      "1    0.318780  22.210781  25.636905    1.010101\n",
      "2    5.258645  11.986537  29.855295    2.020202\n",
      "3   10.645452  33.761517  26.141036    3.030303\n",
      "4    2.869637  94.290970  11.782351   11.722956\n",
      "5    3.879820  32.320293  38.647858    5.050505\n",
      "6   13.956670  51.879062  17.068921    6.060606\n",
      "7   10.907881  70.301896   4.751152    7.070707\n",
      "8    5.733436  36.362960  36.314019    8.080808\n",
      "9   11.803709  97.178208  13.400989    9.090909\n",
      "10   7.783922  96.244729  52.073434   12.718113\n",
      "11   8.782462  25.178230  53.251984   11.111111\n",
      "12  13.331023  49.724851  51.803826   16.717915\n",
      "13   3.564912  30.087831  25.073592   13.131313\n",
      "14   5.516825  28.484049   7.843538   14.141414\n",
      "15  12.340078   3.688695  53.991686   15.151515\n",
      "16  11.097461  60.956433  29.490015   16.161616\n",
      "17  18.742954  50.267902  56.918600   17.171717\n",
      "18  13.641698   5.147875  57.271908   15.874725\n",
      "19  12.130401  27.864646  52.246432   19.191919\n",
      "20  27.530264  90.826589  24.823455   20.202020\n",
      "21  20.083240  23.956189  29.860947   21.212121\n",
      "22  22.559863  14.489487  53.667945   28.205110\n",
      "23  16.108582  48.945276  27.462262   23.232323\n",
      "24  21.520511  98.565045  20.595849   24.242424\n",
      "25  25.807138  24.205527  40.466326   25.252525\n",
      "26  20.507658  67.213555  59.939052   26.262626\n",
      "27  29.151217  76.161962  48.437853   27.272727\n",
      "28  25.279635  23.763754  42.644473   28.282828\n",
      "29  27.834461  72.821635  19.505289   29.292929\n",
      "30  27.294497  36.778313  45.901876   28.727166\n",
      "31  40.574522  63.230583  65.159258   46.660170\n",
      "32  32.255746  63.352971  23.165817   32.323232\n",
      "33  28.044779  53.577468  42.583149   28.750115\n",
      "34  38.456159   9.028977  61.040371   34.343434\n",
      "35  29.249317  83.530250  54.715199   35.353535\n",
      "36  37.407954  32.078006  53.032605   36.363636\n",
      "37  27.575387  18.651851  53.811073   37.373737\n",
      "38  31.742908   4.077514  37.166477   38.383838\n",
      "39  40.378246  59.089294  34.376562   43.377130\n",
      "40  44.096373  67.756436  60.670078   40.404040\n",
      "41  42.270983   1.658783  61.212740   41.414141\n",
      "42  41.846001  51.209306  64.565737   42.424242\n",
      "43  41.928825  22.649578  67.379199   43.434343\n",
      "44  37.051834  64.517279  47.789342   34.686442\n",
      "45  41.855324  17.436643  47.803087   44.552964\n",
      "46  44.161453  69.093774  63.147082   46.464646\n",
      "47  52.760359  38.673535  56.235570   47.474747\n",
      "48  50.202940  93.672999  59.340768   48.484848\n",
      "49  40.679749  13.752094  64.537108   49.494949\n",
      "50  52.125470  34.106635  69.752792   50.505051\n",
      "51  49.589740  11.347352  42.657334   51.515152\n",
      "52  49.140643  92.469362  45.041774   52.525253\n",
      "53  56.593735  87.733935  31.466774   59.548106\n",
      "54  59.700452  25.794163  56.186734   54.545455\n",
      "55  60.211956  65.998405  29.574891   55.555556\n",
      "56  52.369569  81.722220  51.562729   56.565657\n",
      "57  56.029696  55.520081  55.920111   57.575758\n",
      "58  60.242176  52.965058  43.619992   58.585859\n",
      "59  64.473685  24.185229  59.339643   59.595960\n",
      "60  58.210189   9.310277  31.828043   60.606061\n",
      "61  60.687867  89.721576  32.675490   61.616162\n",
      "62  57.094588  90.041806  72.443159   62.626263\n",
      "63  57.655331  63.310146  49.827714   63.636364\n",
      "64  68.709094  33.902979  38.676258   64.646465\n",
      "65  72.437766  34.920957  58.940446   65.656566\n",
      "66  66.306616  72.595568  71.833011   66.666667\n",
      "67  72.694432  89.711026  44.629435   67.676768\n",
      "68  70.495049  88.708642  65.487958   68.686869\n",
      "69  66.471371  77.987555  39.115858   69.696970\n",
      "70  72.514049  64.203165  37.937621   68.545652\n",
      "71  79.407355   8.413996  62.426317   71.717172\n",
      "72  72.548143  16.162871  63.395392   72.727273\n",
      "73  81.560592  89.855419  68.740182   77.133569\n",
      "74  61.648749  60.642906  73.678304   74.747475\n",
      "75  79.867088   0.919705  86.671392   75.757576\n",
      "76  77.202912  10.147154  64.198856   70.373039\n",
      "77  76.282741  66.350177  55.036713   71.862583\n",
      "78  79.246683   0.506158  79.153249   78.787879\n",
      "79  69.860135  16.080805  53.440602   79.797980\n",
      "80  79.709721  54.873379  62.352611   71.449822\n",
      "81  83.603745  69.189520  44.831910   81.818182\n",
      "82  90.217753  65.196126  42.681679   82.828283\n",
      "83  81.247033  22.426931  90.051613   81.647232\n",
      "84  80.806017  71.217922  84.223248   84.848485\n",
      "85  83.349801  23.724909  77.728003   85.858586\n",
      "86  91.445697  32.539970  63.881991   86.868687\n",
      "87  89.522543  74.649141  52.604110   87.878788\n",
      "88  86.240088  64.963290  52.266297   88.888889\n",
      "89  92.465327  84.922341  57.461640   89.898990\n",
      "90  91.394479  65.761289  72.915879   93.501316\n",
      "91  96.762417  56.830860  81.689392   91.919192\n",
      "92  89.419027   9.367477  79.474515   92.929293\n",
      "93  92.301083  36.771580  60.966392   93.939394\n",
      "94  92.988954  26.520237  95.218012   94.949495\n",
      "95  88.642021  24.398964  84.874644   95.959596\n",
      "96  98.450298  97.301055  76.202551   96.969697\n",
      "97  99.285074  39.309772  79.575936   97.979798\n",
      "98  99.015466  89.204656  70.474953   98.989899\n",
      "99  98.827064  63.113863  62.386549  100.000000\n",
      "\n",
      "--- VERIFICAÇÃO DE ERROS ---\n",
      "  ✗ Linha 83, Col 'Target': imputado=81.65, real=83.84, erro=2.19\n",
      "  ✗ Linha 53, Col 'Target': imputado=59.55, real=53.54, erro=6.01\n",
      "  ✗ Linha 70, Col 'Target': imputado=68.55, real=70.71, erro=2.16\n",
      "  ✓ Linha 45, Col 'Target': imputado=44.55, real=45.45, erro=0.90\n",
      "  ✗ Linha 44, Col 'Target': imputado=34.69, real=44.44, erro=9.76\n",
      "  ✗ Linha 39, Col 'Target': imputado=43.38, real=39.39, erro=3.98\n",
      "  ✗ Linha 22, Col 'Target': imputado=28.21, real=22.22, erro=5.98\n",
      "  ✗ Linha 80, Col 'Target': imputado=71.45, real=80.81, erro=9.36\n",
      "  ✗ Linha 10, Col 'Target': imputado=12.72, real=10.10, erro=2.62\n",
      "  ✗ Linha 0, Col 'Target': imputado=5.00, real=0.00, erro=5.00\n",
      "  ✗ Linha 18, Col 'Target': imputado=15.87, real=18.18, erro=2.31\n",
      "  ✗ Linha 30, Col 'Target': imputado=28.73, real=30.30, erro=1.58\n",
      "  ✗ Linha 73, Col 'Target': imputado=77.13, real=73.74, erro=3.40\n",
      "  ✗ Linha 33, Col 'Target': imputado=28.75, real=33.33, erro=4.58\n",
      "  ✗ Linha 90, Col 'Target': imputado=93.50, real=90.91, erro=2.59\n",
      "  ✗ Linha 4, Col 'Target': imputado=11.72, real=4.04, erro=7.68\n",
      "  ✗ Linha 76, Col 'Target': imputado=70.37, real=76.77, erro=6.39\n",
      "  ✗ Linha 77, Col 'Target': imputado=71.86, real=77.78, erro=5.92\n",
      "  ✗ Linha 12, Col 'Target': imputado=16.72, real=12.12, erro=4.60\n",
      "  ✗ Linha 31, Col 'Target': imputado=46.66, real=31.31, erro=15.35\n",
      "\n",
      "MAE total: 5.1177\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO DETALHADO para linha 83, coluna 'Target'\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO: Linha 83, Coluna 'Target'\n",
      "======================================================================\n",
      "\n",
      "Dados da linha 83:\n",
      "A         81.247033\n",
      "B         22.426931\n",
      "C         90.051613\n",
      "Target          NaN\n",
      "\n",
      "Valor REAL (ground truth): 83.83838383838385\n",
      "\n",
      "Features disponíveis (3): ['A', 'B', 'C']\n",
      "Features em falta (0): []\n",
      "\n",
      "--- PESOS MI para prever 'Target' ---\n",
      "  ✓ A: MI=1.3861, peso=0.8330\n",
      "  ✓ C: MI=0.2779, peso=0.1670\n",
      "  ✓ B: MI=0.0000, peso=0.0000\n",
      "\n",
      "--- DONORS POTENCIAIS (80 linhas com target preenchido) ---\n",
      "\n",
      "--- RANGE FACTORS ---\n",
      "  A: 0.3001\n",
      "  B: 0.2924\n",
      "  C: 0.2114\n",
      "\n",
      "--- TOP 10 DONORS (por distância) ---\n",
      "  1. Linha 75: dist=0.0487, overlap=3/3, target=75.76\n",
      "  2. Linha 84: dist=0.0524, overlap=3/3, target=84.85\n",
      "  3. Linha 78: dist=0.1105, overlap=3/3, target=78.79\n",
      "  4. Linha 85: dist=0.1227, overlap=3/3, target=85.86\n",
      "  5. Linha 95: dist=0.2122, overlap=3/3, target=95.96\n",
      "  6. Linha 71: dist=0.2467, overlap=3/3, target=71.72\n",
      "  7. Linha 92: dist=0.2471, overlap=3/3, target=92.93\n",
      "  8. Linha 94: dist=0.3324, overlap=3/3, target=94.95\n",
      "  9. Linha 72: dist=0.3372, overlap=3/3, target=72.73\n",
      "  10. Linha 88: dist=0.3585, overlap=3/3, target=88.89\n",
      "\n",
      "--- ADAPTIVE K ---\n",
      "  density_trust: 0.9015 (mean_dist=0.1093)\n",
      "  consistency_trust: 0.9237\n",
      "  k escolhido: 4 (range [2, 5])\n",
      "\n",
      "--- VIZINHOS FINAIS (k=4) ---\n",
      "  1. Linha 75: dist=0.0487, target=75.76\n",
      "  2. Linha 84: dist=0.0524, target=84.85\n",
      "  3. Linha 78: dist=0.1105, target=78.79\n",
      "  4. Linha 85: dist=0.1227, target=85.86\n",
      "\n",
      "  Pesos IDW: [0.36149934 0.33587714 0.15925499 0.14336853]\n",
      "\n",
      "--- RESULTADO ---\n",
      "  Valor imputado: 80.7418\n",
      "  Valor real: 83.8384\n",
      "  Erro absoluto: 3.0966\n",
      "  Status: ✗ MAU\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "--- VERIFICAÇÃO DOS PESOS MI ---\n",
      "MI(A, Target) = 1.3861\n",
      "MI(B, Target) = 0.0000\n",
      "MI(C, Target) = 0.2779\n",
      "\n",
      "Pesos normalizados:\n",
      "  w(A) = 0.8330 (esperado > 0.5)\n",
      "  w(B) = 0.0000 (esperado < 0.1)\n",
      "  w(C) = 0.1670 (esperado ~0.3)\n",
      "\n",
      "✓ TESTE 2 PASSOU: pesos MI reflectem correlações (A > C > B)\n"
     ]
    }
   ],
   "source": [
    "# Introduzir alguns missings e executar\n",
    "np.random.seed(42)\n",
    "missing_rows = np.random.choice(100, 20, replace=False)\n",
    "missing_indices_2 = [(row, 'Target') for row in missing_rows]\n",
    "\n",
    "result, imputer, mae = run_test_with_diagnostics(\n",
    "    data_2,\n",
    "    missing_indices=missing_indices_2,\n",
    "    target_col='Target',\n",
    "    test_name=\"2 - Correlação Forte vs Fraca\"\n",
    ")\n",
    "\n",
    "# Verificar pesos MI\n",
    "print(f\"\\n--- VERIFICAÇÃO DOS PESOS MI ---\")\n",
    "mi_A = imputer.mi_matrix.loc['A', 'Target']\n",
    "mi_B = imputer.mi_matrix.loc['B', 'Target']\n",
    "mi_C = imputer.mi_matrix.loc['C', 'Target']\n",
    "\n",
    "print(f\"MI(A, Target) = {mi_A:.4f}\")\n",
    "print(f\"MI(B, Target) = {mi_B:.4f}\")\n",
    "print(f\"MI(C, Target) = {mi_C:.4f}\")\n",
    "\n",
    "# Pesos normalizados\n",
    "total_mi = mi_A + mi_B + mi_C\n",
    "w_A = mi_A / total_mi\n",
    "w_B = mi_B / total_mi\n",
    "w_C = mi_C / total_mi\n",
    "\n",
    "print(f\"\\nPesos normalizados:\")\n",
    "print(f\"  w(A) = {w_A:.4f} (esperado > 0.5)\")\n",
    "print(f\"  w(B) = {w_B:.4f} (esperado < 0.1)\")\n",
    "print(f\"  w(C) = {w_C:.4f} (esperado ~0.3)\")\n",
    "\n",
    "# Verificações\n",
    "assert w_A > w_C > w_B, f\"FALHOU: ordem dos pesos deveria ser A > C > B, mas foi A={w_A:.4f}, B={w_B:.4f}, C={w_C:.4f}\"\n",
    "print(f\"\\n✓ TESTE 2 PASSOU: pesos MI reflectem correlações (A > C > B)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 3: Fase 2 Forçada\n",
    "\n",
    "**Objectivo**: Criar uma situação onde a Fase 1 não consegue imputar e verificar se a Fase 2 é activada correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTE 3: Fase 2 Forçada\n",
      "======================================================================\n",
      "\n",
      "Dataset com overlap mínimo entre linhas:\n",
      "     A    B    C    D  Target\n",
      "0  1.0  NaN  NaN  NaN    10.0\n",
      "1  NaN  2.0  NaN  NaN    20.0\n",
      "2  NaN  NaN  3.0  NaN    30.0\n",
      "3  NaN  NaN  NaN  4.0    40.0\n",
      "4  1.0  2.0  3.0  4.0    25.0\n",
      "5  1.1  2.1  3.1  4.1    26.0\n",
      "6  1.2  2.2  3.2  4.2    27.0\n",
      "\n",
      "Linhas 0-3: cada uma só tem 1 feature preenchida (overlap mínimo)\n",
      "Linhas 4-6: completas (podem ser donors)\n"
     ]
    }
   ],
   "source": [
    "# Dataset onde cada linha tem missings em colunas diferentes\n",
    "# Apenas uma linha está completa\n",
    "data_3 = pd.DataFrame({\n",
    "    'A': [1.0, np.nan, np.nan, np.nan, 1.0, 1.1, 1.2],\n",
    "    'B': [np.nan, 2.0, np.nan, np.nan, 2.0, 2.1, 2.2],\n",
    "    'C': [np.nan, np.nan, 3.0, np.nan, 3.0, 3.1, 3.2],\n",
    "    'D': [np.nan, np.nan, np.nan, 4.0, 4.0, 4.1, 4.2],\n",
    "    'Target': [10.0, 20.0, 30.0, 40.0, 25.0, 26.0, 27.0]  # Todos preenchidos\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTE 3: Fase 2 Forçada\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset com overlap mínimo entre linhas:\")\n",
    "print(data_3.to_string())\n",
    "print(f\"\\nLinhas 0-3: cada uma só tem 1 feature preenchida (overlap mínimo)\")\n",
    "print(f\"Linhas 4-6: completas (podem ser donors)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adicionando missing na linha 0, coluna B\n",
      "Valor real: nan\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 5\n",
      "    ['A', 'B', 'C', 'D', 'Target']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 7 x 5\n",
      "Missings: 12 (34.3%)\n",
      "Parametros: min_friends=2, max_friends=15\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 3/7 (42.9%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 12 → 0 missings\n",
      "             12 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 12 → 0 (12 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 12 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.04s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "Resultado:\n",
      "          A         B         C         D  Target\n",
      "0  1.000000  2.081470  3.081470  4.081470    10.0\n",
      "1  1.053485  2.000000  3.053485  4.053485    20.0\n",
      "2  1.055318  2.055318  3.000000  4.055318    30.0\n",
      "3  1.084651  2.084651  3.084651  4.000000    40.0\n",
      "4  1.000000  2.000000  3.000000  4.000000    25.0\n",
      "5  1.100000  2.100000  3.100000  4.100000    26.0\n",
      "6  1.200000  2.200000  3.200000  4.200000    27.0\n"
     ]
    }
   ],
   "source": [
    "# Tentar imputar a linha 0 que só tem A preenchido\n",
    "data_3_test = data_3.copy()\n",
    "true_value = data_3_test.loc[0, 'B']\n",
    "data_3_test.loc[0, 'B'] = np.nan  # Adicionar mais um missing\n",
    "\n",
    "print(f\"\\nAdicionando missing na linha 0, coluna B\")\n",
    "print(f\"Valor real: {true_value}\")\n",
    "\n",
    "imputer = ISCAkCore(verbose=True, use_pds=True, min_friends=2)\n",
    "result = imputer.impute(data_3_test, interactive=False)\n",
    "\n",
    "print(f\"\\n--- ESTATÍSTICAS DE EXECUÇÃO ---\")\n",
    "stats = imputer.execution_stats\n",
    "print(f\"  Fase 2 activada: {stats.get('phase2_activated', 'N/A')}\")\n",
    "print(f\"  Fase 2 ciclos: {stats.get('phase2_cycles', 'N/A')}\")\n",
    "print(f\"  Fase 2 imputados: {stats.get('phase2_imputed', 'N/A')}\")\n",
    "\n",
    "print(f\"\\nResultado:\")\n",
    "print(result.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 4: PDS vs Clássico\n",
    "\n",
    "**Objectivo**: Comparar o comportamento com e sem PDS (Partial Distance Strategy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTE 4: PDS vs Clássico\n",
      "======================================================================\n",
      "\n",
      "Dataset:\n",
      "     A    B    C    D    E  Target\n",
      "0  1.0  1.0  1.0  NaN  NaN    10.0\n",
      "1  NaN  NaN  1.0  1.0  1.0    10.0\n",
      "2  1.0  1.0  1.0  1.0  1.0    10.0\n",
      "3  5.0  5.0  5.0  5.0  5.0    50.0\n",
      "4  1.1  1.1  1.1  1.1  NaN     NaN\n",
      "\n",
      "Linha 0: overlap 3/5 com linha 4 (A, B, C)\n",
      "Linha 1: overlap 2/5 com linha 4 (C, D)\n",
      "Linha 2: overlap 4/5 com linha 4 (A, B, C, D) - MELHOR\n",
      "Linha 3: overlap 4/5 com linha 4, mas distante\n"
     ]
    }
   ],
   "source": [
    "# Dataset onde alguns donors têm overlap parcial\n",
    "data_4 = pd.DataFrame({\n",
    "    'A': [1.0, np.nan, 1.0, 5.0, 1.1],\n",
    "    'B': [1.0, np.nan, 1.0, 5.0, 1.1],\n",
    "    'C': [1.0, 1.0, 1.0, 5.0, 1.1],\n",
    "    'D': [np.nan, 1.0, 1.0, 5.0, 1.1],\n",
    "    'E': [np.nan, 1.0, 1.0, 5.0, np.nan],  # Linha 4 terá missing aqui\n",
    "    'Target': [10.0, 10.0, 10.0, 50.0, np.nan]  # Linha 4 terá missing\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTE 4: PDS vs Clássico\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset:\")\n",
    "print(data_4.to_string())\n",
    "print(f\"\\nLinha 0: overlap 3/5 com linha 4 (A, B, C)\")\n",
    "print(f\"Linha 1: overlap 2/5 com linha 4 (C, D)\")\n",
    "print(f\"Linha 2: overlap 4/5 com linha 4 (A, B, C, D) - MELHOR\")\n",
    "print(f\"Linha 3: overlap 4/5 com linha 4, mas distante\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== COM PDS ==============================\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 6\n",
      "    ['A', 'B', 'C', 'D', 'E']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 5 x 6\n",
      "Missings: 6 (20.0%)\n",
      "Parametros: min_friends=2, max_friends=15\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 2/5 (40.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 6 → 0 missings\n",
      "             6 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 6 → 0 (6 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 6 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.05s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Valor imputado COM PDS: 10.3419\n",
      "\n",
      "============================== SEM PDS ==============================\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 6\n",
      "    ['A', 'B', 'C', 'D', 'E']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 5 x 6\n",
      "Missings: 6 (20.0%)\n",
      "Parametros: min_friends=2, max_friends=15\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): False\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 2/5 (40.0%)\n",
      "Estratégia: ISCA-k clássico\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 6 → 0 missings\n",
      "             6 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k: 6 → 0 (6 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 6 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.06s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Valor imputado SEM PDS: 11.0000\n",
      "\n",
      "--- COMPARAÇÃO ---\n",
      "  COM PDS: 10.3419\n",
      "  SEM PDS: 11.0000\n",
      "  Esperado: ~10.0\n"
     ]
    }
   ],
   "source": [
    "# Guardar valor real\n",
    "true_target = 10.5  # Deveria ser ~10 baseado no cluster\n",
    "\n",
    "# Teste COM PDS\n",
    "print(f\"\\n{'='*30} COM PDS {'='*30}\")\n",
    "imputer_pds = ISCAkCore(verbose=True, use_pds=True, min_friends=2)\n",
    "result_pds = imputer_pds.impute(data_4.copy(), interactive=False)\n",
    "val_pds = result_pds.loc[4, 'Target']\n",
    "print(f\"\\nValor imputado COM PDS: {val_pds:.4f}\")\n",
    "\n",
    "# Teste SEM PDS\n",
    "print(f\"\\n{'='*30} SEM PDS {'='*30}\")\n",
    "imputer_no_pds = ISCAkCore(verbose=True, use_pds=False, min_friends=2)\n",
    "result_no_pds = imputer_no_pds.impute(data_4.copy(), interactive=False)\n",
    "val_no_pds = result_no_pds.loc[4, 'Target']\n",
    "print(f\"\\nValor imputado SEM PDS: {val_no_pds:.4f}\")\n",
    "\n",
    "print(f\"\\n--- COMPARAÇÃO ---\")\n",
    "print(f\"  COM PDS: {val_pds:.4f}\")\n",
    "print(f\"  SEM PDS: {val_no_pds:.4f}\")\n",
    "print(f\"  Esperado: ~10.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 5: Dados Mistos (Numérico + Categórico)\n",
    "\n",
    "**Objectivo**: Verificar se a combinação de distâncias numéricas e categóricas está correcta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTE 5: Dados Mistos\n",
      "======================================================================\n",
      "\n",
      "Dataset com numéricos e categóricos:\n",
      "   Num1   Num2 Cat1 Cat2  Target\n",
      "0  1.00  10.00    A    X   100.0\n",
      "1  1.10  10.10    A    X   101.0\n",
      "2  1.20  10.20    A    X   102.0\n",
      "3  5.00  50.00    B    Y   500.0\n",
      "4  5.10  50.10    B    Y   501.0\n",
      "5  5.20  50.20    B    Y   502.0\n",
      "6  1.05  10.05    A    X   100.5\n",
      "\n",
      "Cluster 1 (linhas 0-2, 6): Num~1, Cat=A/X, Target~100\n",
      "Cluster 2 (linhas 3-5): Num~5, Cat=B/Y, Target~500\n"
     ]
    }
   ],
   "source": [
    "# Dataset misto com clusters baseados em numérico E categórico\n",
    "data_5 = pd.DataFrame({\n",
    "    'Num1': [1.0, 1.1, 1.2, 5.0, 5.1, 5.2, 1.05],\n",
    "    'Num2': [10.0, 10.1, 10.2, 50.0, 50.1, 50.2, 10.05],\n",
    "    'Cat1': ['A', 'A', 'A', 'B', 'B', 'B', 'A'],\n",
    "    'Cat2': ['X', 'X', 'X', 'Y', 'Y', 'Y', 'X'],\n",
    "    'Target': [100.0, 101.0, 102.0, 500.0, 501.0, 502.0, 100.5]  # Linha 6 será missing\n",
    "})\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTE 5: Dados Mistos\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset com numéricos e categóricos:\")\n",
    "print(data_5.to_string())\n",
    "print(f\"\\nCluster 1 (linhas 0-2, 6): Num~1, Cat=A/X, Target~100\")\n",
    "print(f\"Cluster 2 (linhas 3-5): Num~5, Cat=B/Y, Target~500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TESTE 5.1: Missing numérico ==============================\n",
      "\n",
      "######################################################################\n",
      "# TESTE: 5.1 - Dados Mistos (missing numérico)\n",
      "######################################################################\n",
      "\n",
      "Dataset: 7 linhas x 5 colunas\n",
      "Missings introduzidos: 1\n",
      "PDS: True\n",
      "\n",
      "--- DADOS COMPLETOS (ground truth) ---\n",
      "   Num1   Num2 Cat1 Cat2  Target\n",
      "0  1.00  10.00    A    X   100.0\n",
      "1  1.10  10.10    A    X   101.0\n",
      "2  1.20  10.20    A    X   102.0\n",
      "3  5.00  50.00    B    Y   500.0\n",
      "4  5.10  50.10    B    Y   501.0\n",
      "5  5.20  50.20    B    Y   502.0\n",
      "6  1.05  10.05    A    X   100.5\n",
      "\n",
      "--- DADOS COM MISSINGS ---\n",
      "   Num1   Num2 Cat1 Cat2  Target\n",
      "0  1.00  10.00    A    X   100.0\n",
      "1  1.10  10.10    A    X   101.0\n",
      "2  1.20  10.20    A    X   102.0\n",
      "3  5.00  50.00    B    Y   500.0\n",
      "4  5.10  50.10    B    Y   501.0\n",
      "5  5.20  50.20    B    Y   502.0\n",
      "6  1.05  10.05    A    X     NaN\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 3\n",
      "    ['Num1', 'Num2', 'Target']\n",
      "  Binarias: 0\n",
      "  Nominais: 2\n",
      "    ['Cat1', 'Cat2']\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 7 x 5\n",
      "Missings: 1 (2.9%)\n",
      "Parametros: min_friends=2, max_friends=5\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Tipo dados: Misto\n",
      "  Numericas: 3\n",
      "  Binarias: 0\n",
      "  Nominais: 2\n",
      "  Ordinais: 0\n",
      "\n",
      "Linhas 100% completas: 6/7 (85.7%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 1 → 0 missings\n",
      "             1 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 1 → 0 (1 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 1 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.07s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "--- RESULTADO IMPUTAÇÃO ---\n",
      "   Num1   Num2 Cat1 Cat2      Target\n",
      "0  1.00  10.00    A    X  100.000000\n",
      "1  1.10  10.10    A    X  101.000000\n",
      "2  1.20  10.20    A    X  102.000000\n",
      "3  5.00  50.00    B    Y  500.000000\n",
      "4  5.10  50.10    B    Y  501.000000\n",
      "5  5.20  50.20    B    Y  502.000000\n",
      "6  1.05  10.05    A    X  100.714323\n",
      "\n",
      "--- VERIFICAÇÃO DE ERROS ---\n",
      "  ✓ Linha 6, Col 'Target': imputado=100.71, real=100.50, erro=0.21\n",
      "\n",
      "MAE total: 0.2143\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO DETALHADO para linha 6, coluna 'Target'\n",
      "\n",
      "======================================================================\n",
      "DIAGNÓSTICO: Linha 6, Coluna 'Target'\n",
      "======================================================================\n",
      "\n",
      "Dados da linha 6:\n",
      "Num1       1.05\n",
      "Num2      10.05\n",
      "Cat1          A\n",
      "Cat2          X\n",
      "Target      NaN\n",
      "\n",
      "Valor REAL (ground truth): 100.5\n",
      "\n",
      "Features disponíveis (4): ['Num1', 'Num2', 'Cat1', 'Cat2']\n",
      "Features em falta (0): []\n",
      "\n",
      "--- PESOS MI para prever 'Target' ---\n",
      "  ✓ Num1: MI=0.0000, peso=0.2500\n",
      "  ✓ Num2: MI=0.0000, peso=0.2500\n",
      "  ✓ Cat1: MI=0.0000, peso=0.2500\n",
      "  ✓ Cat2: MI=0.0000, peso=0.2500\n",
      "\n",
      "--- DONORS POTENCIAIS (6 linhas com target preenchido) ---\n",
      "\n",
      "--- RANGE FACTORS ---\n",
      "  Num1: 0.4731\n",
      "  Num2: 0.4926\n",
      "  Cat1: 1.0000\n",
      "  Cat2: 1.0000\n",
      "\n",
      "--- TOP 10 DONORS (por distância) ---\n",
      "  1. Linha 0: dist=0.0063, overlap=4/4, target=100.00\n",
      "  2. Linha 1: dist=0.0063, overlap=4/4, target=101.00\n",
      "  3. Linha 2: dist=0.0190, overlap=4/4, target=102.00\n",
      "  4. Linha 3: dist=0.7914, overlap=4/4, target=500.00\n",
      "  5. Linha 4: dist=0.8002, overlap=4/4, target=501.00\n",
      "  6. Linha 5: dist=0.8090, overlap=4/4, target=502.00\n",
      "\n",
      "--- ADAPTIVE K ---\n",
      "  density_trust: 0.7549 (mean_dist=0.3246)\n",
      "  consistency_trust: 0.5713\n",
      "  k escolhido: 3 (range [2, 5])\n",
      "\n",
      "--- VIZINHOS FINAIS (k=3) ---\n",
      "  1. Linha 0: dist=0.0063, target=100.00\n",
      "  2. Linha 1: dist=0.0063, target=101.00\n",
      "  3. Linha 2: dist=0.0190, target=102.00\n",
      "\n",
      "  Pesos IDW: [0.42856497 0.42856497 0.14287005]\n",
      "\n",
      "--- RESULTADO ---\n",
      "  Valor imputado: 100.7143\n",
      "  Valor real: 100.5000\n",
      "  Erro absoluto: 0.2143\n",
      "  Status: ✓ BOM\n",
      "\n",
      "--- ESTATÍSTICAS DE EXECUÇÃO ---\n",
      "  Fase 2 activada: False\n",
      "  Fase 2 ciclos: 0\n",
      "  Fase 2 imputados: 0\n",
      "\n",
      "✓ TESTE 5.1 PASSOU: valor imputado 100.71 está no cluster correcto\n"
     ]
    }
   ],
   "source": [
    "# Teste 5.1: Missing no Target (numérico)\n",
    "print(f\"\\n{'='*30} TESTE 5.1: Missing numérico {'='*30}\")\n",
    "result, imputer, mae = run_test_with_diagnostics(\n",
    "    data_5,\n",
    "    missing_indices=[(6, 'Target')],\n",
    "    target_col='Target',\n",
    "    test_name=\"5.1 - Dados Mistos (missing numérico)\"\n",
    ")\n",
    "\n",
    "val = result.loc[6, 'Target']\n",
    "assert 90 <= val <= 110, f\"FALHOU: {val} deveria estar em [90, 110]\"\n",
    "print(f\"\\n✓ TESTE 5.1 PASSOU: valor imputado {val:.2f} está no cluster correcto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== TESTE 5.2: Missing categórico ==============================\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 3\n",
      "    ['Num1', 'Num2', 'Target']\n",
      "  Binarias: 0\n",
      "  Nominais: 2\n",
      "    ['Cat1', 'Cat2']\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 7 x 5\n",
      "Missings: 1 (2.9%)\n",
      "Parametros: min_friends=2, max_friends=15\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Tipo dados: Misto\n",
      "  Numericas: 3\n",
      "  Binarias: 0\n",
      "  Nominais: 2\n",
      "  Ordinais: 0\n",
      "\n",
      "Linhas 100% completas: 6/7 (85.7%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 1 → 0 missings\n",
      "             1 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 1 → 0 (1 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 1 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 0.03s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Valor real: A\n",
      "Valor imputado: A\n",
      "\n",
      "Mapeamento nominal: {'forward': {'A': 0, 'B': 1}, 'reverse': {0: 'A', 1: 'B'}, 'n_categories': 2}\n"
     ]
    }
   ],
   "source": [
    "# Teste 5.2: Missing no Cat1 (categórico)\n",
    "print(f\"\\n{'='*30} TESTE 5.2: Missing categórico {'='*30}\")\n",
    "\n",
    "data_5_cat = data_5.copy()\n",
    "true_cat = data_5_cat.loc[6, 'Cat1']\n",
    "data_5_cat.loc[6, 'Cat1'] = np.nan\n",
    "\n",
    "imputer = ISCAkCore(verbose=True, use_pds=True, min_friends=2)\n",
    "result = imputer.impute(data_5_cat, interactive=False)\n",
    "\n",
    "val_cat = result.loc[6, 'Cat1']\n",
    "print(f\"\\nValor real: {true_cat}\")\n",
    "print(f\"Valor imputado: {val_cat}\")\n",
    "\n",
    "# Nota: o valor pode estar codificado, precisamos decodificar\n",
    "print(f\"\\nMapeamento nominal: {imputer.mixed_handler.nominal_mappings.get('Cat1', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 6: Simulação de Colapso (como SONAR 40%)\n",
    "\n",
    "**Objectivo**: Tentar reproduzir o colapso que vimos no SONAR a 40% missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTE 6: Simulação de Colapso (tipo SONAR)\n",
      "======================================================================\n",
      "\n",
      "Dataset: 200 linhas x 61 colunas\n",
      "3 clusters com targets ~10, ~50, ~90\n"
     ]
    }
   ],
   "source": [
    "# Criar dataset similar ao SONAR (muitas features)\n",
    "np.random.seed(42)\n",
    "n_samples = 200\n",
    "n_features = 60\n",
    "\n",
    "# 3 clusters\n",
    "def make_sonar_like_cluster(center, target_center, n):\n",
    "    data = {f'F{i}': np.random.normal(center, 0.2, n) for i in range(n_features)}\n",
    "    data['Target'] = np.random.normal(target_center, 2.0, n)\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "c1 = make_sonar_like_cluster(0.2, 10, 66)\n",
    "c2 = make_sonar_like_cluster(0.5, 50, 67)\n",
    "c3 = make_sonar_like_cluster(0.8, 90, 67)\n",
    "\n",
    "data_6 = pd.concat([c1, c2, c3], ignore_index=True)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"TESTE 6: Simulação de Colapso (tipo SONAR)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nDataset: {data_6.shape[0]} linhas x {data_6.shape[1]} colunas\")\n",
    "print(f\"3 clusters com targets ~10, ~50, ~90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== 20% MISSING ==============================\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 61\n",
      "    ['F0', 'F1', 'F2', 'F3', 'F4']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 200 x 61\n",
      "Missings: 40 (0.3%)\n",
      "Parametros: min_friends=3, max_friends=15\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 160/200 (80.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 40 → 0 missings\n",
      "             40 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 40 → 0 (40 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 40 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 3.57s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "MAE 20%: 1.9630\n",
      "Fase 2 activada: False\n"
     ]
    }
   ],
   "source": [
    "# Teste com 20% missing\n",
    "print(f\"\\n{'='*30} 20% MISSING {'='*30}\")\n",
    "np.random.seed(42)\n",
    "missing_20 = np.random.choice(200, 40, replace=False)\n",
    "missing_indices_20 = [(row, 'Target') for row in missing_20]\n",
    "\n",
    "data_6_20 = data_6.copy()\n",
    "true_vals_20 = {row: data_6.loc[row, 'Target'] for row in missing_20}\n",
    "for row in missing_20:\n",
    "    data_6_20.loc[row, 'Target'] = np.nan\n",
    "\n",
    "imputer_20 = ISCAkCore(verbose=True, use_pds=True)\n",
    "result_20 = imputer_20.impute(data_6_20, interactive=False)\n",
    "\n",
    "# Calcular MAE\n",
    "errors_20 = [abs(result_20.loc[row, 'Target'] - true_vals_20[row]) for row in missing_20]\n",
    "mae_20 = np.mean(errors_20)\n",
    "print(f\"\\nMAE 20%: {mae_20:.4f}\")\n",
    "print(f\"Fase 2 activada: {imputer_20.execution_stats.get('phase2_activated', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== 40% MISSING ==============================\n",
      "\\nCLASSIFICACAO DE VARIAVEIS:\n",
      "  Numericas: 61\n",
      "    ['F0', 'F1', 'F2', 'F3', 'F4']\n",
      "  Binarias: 0\n",
      "  Nominais: 0\n",
      "  Ordinais: 0\n",
      "\n",
      "======================================================================\n",
      "      ISCA-k: Information-theoretic Smart Collaborative Approach      \n",
      "======================================================================\n",
      "\n",
      "Dataset: 200 x 61\n",
      "Missings: 80 (0.7%)\n",
      "Parametros: min_friends=3, max_friends=15\n",
      "MI neighbors: 3\n",
      "Adaptive k alpha: 0.5\n",
      "Fast mode: False\n",
      "FCM clustering: False\n",
      "PDS (partial donors): True\n",
      "  Overlap: adaptativo (maximiza por valor)\n",
      "Max cycles: 3\n",
      "\n",
      "Linhas 100% completas: 120/200 (60.0%)\n",
      "Estratégia: ISCA-k+PDS primeiro, fallback se necessário\n",
      "\n",
      "======================================================================\n",
      "FASE 1: ISCA-k + PDS\n",
      "======================================================================\n",
      "  [1/3] Calculando Informacao Mutua...\n",
      "  [2/3] Ordenando colunas por facilidade...\n",
      "  [3/3] Imputando colunas...\n",
      "\n",
      "  Resultado: 80 → 0 missings\n",
      "             80 imputados (100.0%)\n",
      "\n",
      "======================================================================\n",
      "RESULTADO FINAL\n",
      "======================================================================\n",
      "\n",
      "Fases:\n",
      "  ISCA-k + PDS: 80 → 0 (80 imputados, 100.0%)\n",
      "\n",
      "✅ Fase 1 resolveu tudo (Fase 2 não necessária)\n",
      "\n",
      "Total: 80 → 0 missings\n",
      "Status: SUCESSO - Dataset 100% completo\n",
      "Taxa de imputação: 100.0%\n",
      "Tempo total: 4.47s\n",
      "======================================================================\n",
      "\n",
      "\n",
      "MAE 40%: 1.7161\n",
      "Fase 2 activada: False\n"
     ]
    }
   ],
   "source": [
    "# Teste com 40% missing\n",
    "print(f\"\\n{'='*30} 40% MISSING {'='*30}\")\n",
    "np.random.seed(42)\n",
    "missing_40 = np.random.choice(200, 80, replace=False)\n",
    "missing_indices_40 = [(row, 'Target') for row in missing_40]\n",
    "\n",
    "data_6_40 = data_6.copy()\n",
    "true_vals_40 = {row: data_6.loc[row, 'Target'] for row in missing_40}\n",
    "for row in missing_40:\n",
    "    data_6_40.loc[row, 'Target'] = np.nan\n",
    "\n",
    "imputer_40 = ISCAkCore(verbose=True, use_pds=True)\n",
    "result_40 = imputer_40.impute(data_6_40, interactive=False)\n",
    "\n",
    "# Calcular MAE\n",
    "errors_40 = [abs(result_40.loc[row, 'Target'] - true_vals_40[row]) for row in missing_40]\n",
    "mae_40 = np.mean(errors_40)\n",
    "print(f\"\\nMAE 40%: {mae_40:.4f}\")\n",
    "print(f\"Fase 2 activada: {imputer_40.execution_stats.get('phase2_activated', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== COMPARAÇÃO ==============================\n",
      "MAE 20% missing: 1.9630\n",
      "MAE 40% missing: 1.7161\n",
      "Degradação: -12.6%\n",
      "\n",
      "✓ Degradação dentro do esperado\n"
     ]
    }
   ],
   "source": [
    "# Comparação\n",
    "print(f\"\\n{'='*30} COMPARAÇÃO {'='*30}\")\n",
    "print(f\"MAE 20% missing: {mae_20:.4f}\")\n",
    "print(f\"MAE 40% missing: {mae_40:.4f}\")\n",
    "print(f\"Degradação: {((mae_40 - mae_20) / mae_20 * 100):.1f}%\")\n",
    "\n",
    "if mae_40 > mae_20 * 3:\n",
    "    print(f\"\\n⚠️  COLAPSO DETECTADO: MAE triplicou de 20% para 40%\")\n",
    "else:\n",
    "    print(f\"\\n✓ Degradação dentro do esperado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Teste 7: Adaptive K\n",
    "\n",
    "**Objectivo**: Verificar se o adaptive k escolhe valores apropriados em diferentes cenários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "TESTE 7: Adaptive K\n",
      "======================================================================\n",
      "\n",
      "--- Cenário 7.1: Vizinhos Consistentes ---\n",
      "  Targets dos vizinhos: [10.  10.1 10.2  9.9 10.  10.1  9.8 10.2 10.  10.1]\n",
      "  Std dos targets: 0.1200\n",
      "  k escolhido: 8\n",
      "  Esperado: k ALTO (vizinhos concordam, seguro usar mais)\n",
      "\n",
      "--- Cenário 7.2: Vizinhos Inconsistentes ---\n",
      "  Targets dos vizinhos: [ 10.  50.   5. 100.  20.  80.  15.  90.  30.  70.]\n",
      "  Std dos targets: 33.8526\n",
      "  k escolhido: 7\n",
      "  Esperado: k BAIXO (vizinhos discordam, usar menos)\n",
      "\n",
      "✓ TESTE 7 PASSOU: k_consistent (8) > k_inconsistent (7)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TESTE 7: Adaptive K\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Cenário 7.1: Vizinhos CONSISTENTES (todos com target similar)\n",
    "print(f\"\\n--- Cenário 7.1: Vizinhos Consistentes ---\")\n",
    "distances_consistent = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "values_consistent = np.array([10.0, 10.1, 10.2, 9.9, 10.0, 10.1, 9.8, 10.2, 10.0, 10.1])\n",
    "\n",
    "k_consistent = adaptive_k_hybrid(distances_consistent, values_consistent, min_k=3, max_k=10, alpha=0.5)\n",
    "print(f\"  Targets dos vizinhos: {values_consistent}\")\n",
    "print(f\"  Std dos targets: {np.std(values_consistent):.4f}\")\n",
    "print(f\"  k escolhido: {k_consistent}\")\n",
    "print(f\"  Esperado: k ALTO (vizinhos concordam, seguro usar mais)\")\n",
    "\n",
    "# Cenário 7.2: Vizinhos INCONSISTENTES (targets muito diferentes)\n",
    "print(f\"\\n--- Cenário 7.2: Vizinhos Inconsistentes ---\")\n",
    "distances_inconsistent = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "values_inconsistent = np.array([10.0, 50.0, 5.0, 100.0, 20.0, 80.0, 15.0, 90.0, 30.0, 70.0])\n",
    "\n",
    "k_inconsistent = adaptive_k_hybrid(distances_inconsistent, values_inconsistent, min_k=3, max_k=10, alpha=0.5)\n",
    "print(f\"  Targets dos vizinhos: {values_inconsistent}\")\n",
    "print(f\"  Std dos targets: {np.std(values_inconsistent):.4f}\")\n",
    "print(f\"  k escolhido: {k_inconsistent}\")\n",
    "print(f\"  Esperado: k BAIXO (vizinhos discordam, usar menos)\")\n",
    "\n",
    "# Verificação\n",
    "assert k_consistent > k_inconsistent, f\"FALHOU: k_consistent ({k_consistent}) deveria ser > k_inconsistent ({k_inconsistent})\"\n",
    "print(f\"\\n✓ TESTE 7 PASSOU: k_consistent ({k_consistent}) > k_inconsistent ({k_inconsistent})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Resumo dos Testes\n",
    "\n",
    "Execute esta célula no final para ver um resumo de todos os testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RESUMO DOS TESTES DIAGNÓSTICOS\n",
      "======================================================================\n",
      "\n",
      "Execute cada teste individualmente e verifique:\n",
      "\n",
      "1. VIZINHOS ÓBVIOS\n",
      "   - Os vizinhos seleccionados são do cluster correcto?\n",
      "   - O valor imputado está no range esperado?\n",
      "   - Há degradação excessiva com mais missings?\n",
      "\n",
      "2. CORRELAÇÃO FORTE vs FRACA\n",
      "   - Os pesos MI reflectem as correlações reais?\n",
      "   - A ordem é A > C > B?\n",
      "\n",
      "3. FASE 2 FORÇADA\n",
      "   - A Fase 2 é activada quando necessário?\n",
      "   - Quantos ciclos são necessários?\n",
      "\n",
      "4. PDS vs CLÁSSICO\n",
      "   - O PDS melhora ou piora os resultados?\n",
      "   - A escala está correcta?\n",
      "\n",
      "5. DADOS MISTOS\n",
      "   - Distâncias numéricas e categóricas estão calibradas?\n",
      "   - A votação categórica funciona?\n",
      "\n",
      "6. COLAPSO 40%\n",
      "   - Há colapso súbito entre 20% e 40%?\n",
      "   - A Fase 2 está a ser usada excessivamente?\n",
      "\n",
      "7. ADAPTIVE K\n",
      "   - k varia conforme esperado?\n",
      "   - Vizinhos consistentes → k alto?\n",
      "   - Vizinhos inconsistentes → k baixo?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"RESUMO DOS TESTES DIAGNÓSTICOS\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\"\"\n",
    "Execute cada teste individualmente e verifique:\n",
    "\n",
    "1. VIZINHOS ÓBVIOS\n",
    "   - Os vizinhos seleccionados são do cluster correcto?\n",
    "   - O valor imputado está no range esperado?\n",
    "   - Há degradação excessiva com mais missings?\n",
    "\n",
    "2. CORRELAÇÃO FORTE vs FRACA\n",
    "   - Os pesos MI reflectem as correlações reais?\n",
    "   - A ordem é A > C > B?\n",
    "\n",
    "3. FASE 2 FORÇADA\n",
    "   - A Fase 2 é activada quando necessário?\n",
    "   - Quantos ciclos são necessários?\n",
    "\n",
    "4. PDS vs CLÁSSICO\n",
    "   - O PDS melhora ou piora os resultados?\n",
    "   - A escala está correcta?\n",
    "\n",
    "5. DADOS MISTOS\n",
    "   - Distâncias numéricas e categóricas estão calibradas?\n",
    "   - A votação categórica funciona?\n",
    "\n",
    "6. COLAPSO 40%\n",
    "   - Há colapso súbito entre 20% e 40%?\n",
    "   - A Fase 2 está a ser usada excessivamente?\n",
    "\n",
    "7. ADAPTIVE K\n",
    "   - k varia conforme esperado?\n",
    "   - Vizinhos consistentes → k alto?\n",
    "   - Vizinhos inconsistentes → k baixo?\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
